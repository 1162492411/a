<search><entry><title>MyBatis常见面试题</title><url>https://www.zyg-tech.me/post/mybatis%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/</url><categories><category>面试题</category><category>框架</category><category>MyBatis</category></categories><tags><tag>面试题</tag><tag>框架</tag><tag>MyBatis</tag></tags><content type="html"> .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } MyBatis有哪些主要组件
1）SqlSessionFactory：负责sqlSession的创建、销毁 2）SqlSession ： 负责提供给用户可以操作的api，如insert(),insertBatch()等 3）Executor ： 负责执行对数据库的操作 4）StatementHandler ：Executor将工作委托给StatementHandler执行 .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } Mybatis的工作流程
# 和$的区别
接口如何绑定
MyBatis的一级缓存和二级缓存</content></entry><entry><title>Java常见面试题</title><url>https://www.zyg-tech.me/post/java%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/</url><categories><category>面试题</category><category>Java</category></categories><tags><tag>面试题</tag><tag>Java</tag><tag>Java基础</tag></tags><content type="html"> .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } 基础篇 Object都有哪些方法，各自作用是什么
对象相等的相关方法：equals()、hashcode(); 对象的基本方法 ： toString()、getClass()、clone()、finalize() 锁相关方法 : wait()、nofity()、notifyAll() .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } Java有哪些修饰符/作用域
private、default、protected、public .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } 数据结构篇 HashMap底层实现
1.7及以前是数组+链表，1.8以后是数组+链表+红黑树 .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } HashMap的put如何实现
.spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } HashMap扩容策略在1.7和1.8有什么区别
.spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } HashMap是否是线程安全的，扩容时的锁在什么情况下会出现
.spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } 如何实现线程安全的HashMap
.spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } IO篇 IO、BIO、NIO，阻塞与非阻塞的区别
锁篇 可重入锁是什么，synchronized是不是可重入锁
.spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } wait和sleep的区别
.spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } nofity和nofityAll的区别
.spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } 公平锁和非公平锁的区别，为什么公平锁效率低于非公平锁
同步队列器AQS思想，以及基于AQS实现的lock
并发篇 ConcurrentHashMap为什么比HashMap安全又高效(jdk7分段锁，jdk8cas)
线程篇 线程和进程的区别
.spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } 线程的实现方式有哪些
1）继承Thread类2）实现Runnable接口再调用start方法 .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } 如何实现线程安全，各个实现方法有什么区别
.spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } volatile关键字的使用
线程有哪几种状态 .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } JDK自带的有哪几种线程池
.spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } 如何设计一个线程池
.spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } 线程池的参数有哪些，各自作用是什么
JVM篇 JVM分为哪几块，其中哪几块是线程共享的，每一块存储什么
.spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } 内存溢出和内存泄露的区别
.spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } 如何判断哪些对象需要被GC
.spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } GC的方法
.spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } MinGC与FullGC各自指什么
.spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } HotSpot的GC算法以及7种垃圾回收期
.spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } 类加载的过程
.spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } 如何排查线上出现的JVM问题
设计模式篇</content></entry><entry><title>Spring常见面试题</title><url>https://www.zyg-tech.me/post/spring%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/</url><categories><category>面试题</category><category>Spring</category></categories><tags><tag>面试题</tag><tag>Spring</tag></tags><content type="html"> .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } IOC Spring如何解决setter方式的循环依赖
singletonFactories ： 单例对象工厂的cache； earlySingletonObjects ：提前暴光的单例对象的Cache； singletonObjects：单例对象的cache； 1. 实例化a，先把beanName放到singletonsCurrentlyInCreation中，然后调用无参构造方法实例化bean,然后构造一个singletonFactory对象放到singletonFactories中，暴露给其它可能的依赖; 2. 最后装配属性时，发现需要注入b,那么就开始构造b,构造b的流程和上一步一致 .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } Spring中Bean的生命周期
@Autowired和@Resources注解的异同
1.autowired默认按类型查找对象，resources默认按照名称查找对象 2.autowired是spirng提供的注解，resouces是j2ee提供的注解，但是二者都是jsr标准下的注解 3.两个注解都可以用在字段上 .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } 同样的接口存在多个实现时如何指定某一个实现
1.@Qualifer 2.@Primary .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } 创建IOC容器的过程
以最原始的XmlBeanFactory为例讲解, 1.创建Ioc配置文件的抽象资源，这个抽象资源包含了BeanDefinition的定义信息 ； 2.创建一个BeanFactory，这里使用了DefaultListableBeanFactory ； 3.创建一个载入BeanDefinition的读取器，这里使用XmlBeanDefinitionReader来载入XML文件形式的BeanDefinition ； 4.然后将上面定位好的Resource，通过一个回调配置给BeanFactory ； 5.从定位好的资源位置读入配置信息，具体的解析过程由XmlBeanDefinitionReader完成 ； 6.完成整个载入和注册Bean定义之后，需要的Ioc容器就初步建立起来了 .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } Spring bean的初始化顺序
1. Constructor; 2. @PostConstruct; 3. InitializingBean; 4. init-method .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } AOP aop的底层实现
动态代理有哪些实现方式，有什么区别
事务 Spring事务底层如何实现
Spring事务的七个传播级别，默认是哪个
.spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } 拷贝 什么是浅拷贝和深拷贝，有什么区别 常用的实体拷贝有哪几种方式，各自是如何实现的 Spring的BeanUtils拷贝存在哪些细节问题</content></entry><entry><title>Linux常见面试题</title><url>https://www.zyg-tech.me/post/linux%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/</url><categories><category>Linux</category><category>面试题</category></categories><tags><tag>Linux</tag><tag>面试题</tag></tags><content type="html"> 如何查看系统内存
如何清除系统内存
select和epoll的区别
如何查看系统负载
cpu的load值不同时，cpu有哪几种模式(空闲，轻度负载，高负载这个吗)
Linux，查找磁盘上最大的文件的命令</content></entry><entry><title>数据库常见面试题</title><url>https://www.zyg-tech.me/post/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/</url><categories><category>数据库</category><category>面试题</category></categories><tags><tag>MySQL</tag><tag>面试题</tag></tags><content type="html"> 基础篇 数据库的ACID
MySQL默认的隔离级别
每个隔离级别是如何解决
数据库如何实现 rollback 的
一条sql的执行流程
一条sql的解析流程
MySQL有哪些Join算法
select(*)、select(1)、select(列名)有什么区别
count()包括了所有的列，相当于行数，在统计结果的时候，不会忽略列值为NULL count(1)包括了忽略所有列，用1代表代码行，在统计结果的时候，不会忽略列值为NULL count(列名)只包括列名那一列，在统计结果的时候，会忽略列值为空（这里的空不是只空字符串或者0，而是表示null）的计数，即某个字段值为NULL时，不统计。 列名为主键，count(列名)会比count(1)快 。 列名不为主键，count(1)会比count(列名)快。 如果表多个列并且没有主键，则 count（1） 的执行效率优于 count（） 。 如果有主键，则 select count（主键）的执行效率是最优的。 如果表只有一个字段，则 select count（*）最优。
索引篇 数据库的索引原理
非聚簇索引和聚簇索引
从底层解释最左匹配原则
索引什么时候失效
锁篇 MySQL中有哪些锁
高可用篇 MySQL的主从复制有哪几种模式</content></entry><entry><title>Redis常见面试题</title><url>https://www.zyg-tech.me/post/redis%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/</url><categories><category>Redis</category><category>NoSQL</category><category>数据库</category></categories><tags><tag>Redis</tag><tag>中间件</tag><tag>NoSQL</tag><tag>数据库</tag></tags><content type="html"> 原理篇 如何理解Redis的通讯协议resp协议
.spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } 如何理解Redis的cluster bus的gossip协议
1）用于节点间进行高效的数据交换，占用更少的网络带宽和处理时间； 2）gossip 协议包含多种消息，包含 ping、pong、meet、fail 等等； 3）ping ： 每个节点都会频繁给其它节点发送 ping，其中包含自己的状态还有自己维护的集群元数据，互相通过 ping 交换元数据； 4）meet ： 某个节点发送 meet 给新加入的节点，让新节点加入集群中； 5）pong ： 返回meet和ping； 6）fail ： 节点停止后发送fail告知其他节点； .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } 为什么早期版本Redis是单线程的
Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽 .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } Redis为什么速度快
1）绝大部分操作为基于内存的操作 2）数据结构和对数据的操作简单 3）采用单线程减少上下文切换和竞争，不需要考虑锁的问题 4）使用多路I/O复用模型，非阻塞IO，多个网络连接使用同一个线程 1）通过队列将访问串形化，减少传统关系型数据的串行控制开销 .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } Redis的主从复制原理是什么
从节点连接主节点，向主节点发起同步请求，接收主节点的rdb文件 .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } Redis如何划分内存
1）used_memory ：Redis分配器分配的内存总量； 2）used_memory_rss ：进程占据操作系统的内存； 3）mem_fragmentation_ratio ： 内存碎片率，used_memory_rss / used_memory； 4）mem_allocator ： 使用的内存分配器 .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } Redis的存储细节
.spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } Redis如何实现渐进式hash进行扩容
1）申请旧hash两倍的内存空间，使得原有的字典同时持有旧hash表和新hash表 2）维护一个标志变量rehashindex用于记录进度 3）访问字典时将旧hash表中位于rehashindex这个桶中的key全部转移到新hash表中 4）全部转移完时修改记录进度rehashindex .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } Redis事务的CAS
.spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } string如何扩容
小于1m时每次加倍扩容，大于1m时每次增加1m，最大为512m .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } redis的文件事件处理器都包含哪些部分
1）多个 socket用来完成请求的接收与响应信息的发送 2）IO 多路复用程序 3）文件事件分派器用来协调调度 4）事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）用来真正干活 .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } 基础篇 Redis都有哪些基础的数据结构，他们各自的底层是如何实现的，对应的使用场景是什么
1）String ： 类似Java的动态数组，在内部预先分配一定空间，场景为存储键值对； 2）Hash ： 类似Java的HashMap，数据+链表结构，发生 hash 碰撞时将会把元素追加到链表上，场景为存储购物车信息或者对象； 3）List ： 类似Java的LinkedList，插入与删除数据的复杂度为O(1),数据量少时为一块内存连续的ziplist，数据量多时采用有前后指针的quicklist，redis3.2以后是ziplist+quicklist，场景为点赞列表、评论列表； 4）Set ： 类似Java的HashSet，键无序且唯一，value为null，场景为好友、关注、粉丝、感兴趣的人集合； 5）SortedSet ：有序集合，内部实现为ziplist或者skiplist，场景为排行榜 .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } Redis有哪些高级的数据结构，对应的使用场景是什么
1)BitMaps : 位图,面向bit进行操作,每个bit位为一个值,极度节省空间,经典使用场景是用户的每日签到记录 2)HyperLogLog : 基数统计,基数是数据集去重后元素个数,经典使用场景是统计用户UV 3)GEO : 处理地理位置 .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } Redis如何做到数据持久化，这些方式各自有什么优缺点
RDB保存快照，AOF保存执行命令的记录并合并命令； 1) RDB有两种方式：同步save模式和异步bgsave模式，同步save模式可以保证数据一致性； save会导致redis阻塞，bgsave在大数据量时fork会引起抖动，导致短暂时间内redis响应变慢，且fork需要一定的内存开销； rdb文件默认每次rdb时进行替换并压缩； rdb优点：文件紧凑，体积小，适合全量备份与复制，且加载rdb文件的速度比加载aof文件的速度快 rdb缺点：无法秒级别持久化，老版本redis无法兼容新版本的rdb 2) aof是目前主流的持久数据的方式，aof每次都会将写命令保存到缓冲区然后追加输出到aof文件中， .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } ​ 5. Redis慢查询如何开启
设置slowlog-log-slower-than属性来配置慢查询时间的阈值，设置slowlog-max-len属性来配置存储多少条慢查询命令 .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } Redis的默认内存为多大
32位机器默认3个G，64位机器默认不限制 .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } Redis的淘汰策略有哪些
1）noeviction ： 不删除 2）allkeys-lru ： 从所有key中删除最近最少使用的key 3）volatile-lru ： 从设置了过期时间的key中删除最近最少使用的key 4）allkeys-random ： 从所有key中随机删除 5）volatile-random ： 从设置了过期时间的key中随机删除 6）volatile-ttl ： 从设置了过期时间的key中删除剩余时间最短的 7）allkeys-lfu ：淘汰访问频率最低的key 8）volatile-lfu ：只淘汰访问频率最低的过期key .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } Redis的删除策略有哪些，这些删除策略各自有什么优缺点
1）定时删除 ： 在设置键的过期时间的同时，创建一个定时任务，当键达到过期时间时，立即执行对键的删除操作，优点是对内存友好可以即时释放，缺点是对cpu不友好可能大量key同时删除； 2）定期删除 ： 每隔一定时间删除过期的键，优点是对cpu友好，缺点是对内存不友好； 3）惰性删除 ： 放任键过期不管，但在每次获取键时，判断是否过期，若过期再删除，优点是对cpu友好，缺点是对内存不友好 .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } Redis的Pipeline如何理解
将多个命令一次性发送并执行，节省网络消耗，虽然命令执行时可能被其他命令穿插 .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } Redis如何设置过期时间
1）expire key milliseconds在指定毫秒后过期； 2）expire key seconds在指定秒后过期； 3）expire at key timestamp 在指定的时间戳（秒级别）后过期； 4）expire at key millisecondsTimestamp 在指定的时间戳（毫秒）后过期 .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } Redis支持哪些集群模式
1）主从复制模式；2）Sentinel哨兵模式；3）cluster模式 .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } Redis的事务是否支持回滚
Redis的事务有哪些相关命令
Redis有哪些常用的缓存更新策略
实战篇 Redis有哪些常用场景
1）缓存 2）Session共享 3）简单的消息队列 .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } 如何理解缓存穿透、缓存击穿、缓存雪崩、缓存预热，如何解决
1）缓存穿透 ： 查询一个在redis中不存在的值，比如空值或者特殊的值，解决方案：将一些不存在的值也放入redis中；采用布隆过滤器； 2）缓存击穿 ：说某个key非常热点，当这个key在失效的瞬间，大量的请求直接请求数据库，解决方案：热点数据设置为永远不过期，或者加入互斥锁 3）缓存雪崩 ： 大批量的缓存集中在某个时刻失效，解决方案：设置过期时间不一致，或者加锁排队，或者建立备份缓存或者 事前：redis 高可用，主从+哨兵，redis cluster，避免全盘崩溃。 - 事中：本地 ehcache 缓存 + hystrix 限流&amp;降级，避免 MySQL 被打死。 - 事后：redis持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据； 4）缓存预热： 提前将常用数据加入到缓存中以提高速度 .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } Redis内存使用满会出现什么现象
无法写入只能读取 .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } Redis如何实现定时队列
.spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } Redis如何实现消息队列
1）基于List的 LPUSH+BRPOP 的实现，使用rpush和lpush操作入队列，lpop和rpop操作出队列，引入阻塞读blpop和brpop，阻塞读在队列没有数据的时候进入休眠状态，一旦数据到来则立刻醒过来，消息延迟几乎为零，这种方案当一直没有消息时会导致连接空闲从而被释放，下次使用连接时报错，而且也没有消费者ACK机制，也不能重复消费，也不能进行广播； 2）PUB/SUB，订阅/发布模式，广播模式，消息可以即时发送，但是若消息发布时消费者不在线会丢失小消息，消息积压时也不好处理； 3）基于Sorted Set，消息id自己实现有序递增，缺点是不能存在重复的消息id； 4）基于stream，redis5.0开始支持，借鉴kafka，采用消息链表，消息持久化，可以记录消费者的消费进度，可以确保消息至少被消费一次，但是消息过多时旧消息会丢失，消费者消费消息但不ack会导致pel列表增大而消耗内存 .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } Redis的并发竞争如何解决
1）多个实例更新一个key时通过加锁排队让命令串形化 .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } Redis和数据库如何实现双写一致性
1）Cache Aside Pattern ：-读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。 - 更新的时候，先更新数据库，然后再删除缓存，这种方案实际上在高并发的时候可以继续进行优化 .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } 有哪些基于Redis实现的分布式锁
1）setnx + expire； 2）setifabsent； 3）基于zookeeper的有序节点实现分布式锁； 4）redssion ：采用看门狗，定期续期 ； 5）redlock ： 将加锁命令发送到多个节点参与，如果大多数都加锁成功就成功，如果失败就逐个恢复锁； .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } Redis中的key过期了是否立即释放内存，为什么
不是 .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } 如何保证Redis的高可用和高并发
1）基于一主多从，主节点进行写入，每秒w级别的qps，从节点进行读取，每秒10w级别的qps 2）加上哨兵，当节点出现故障时进行主备切换 .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } Redis集群模式下，redis的key如何寻址，分布式寻址都有哪些算法
寻址算法 ： 1）hash 算法（大量缓存重建）：计算hash后取模，访问不同的节点 2）一致性 hash 算法（自动缓存迁移）+ 虚拟节点（自动负载均衡） ：将整个 hash 值空间组织成一个虚拟的圆环 3）redis cluster 的 hash slot 算法 ：对每个 key 计算 CRC16 值，然后对 16384 取模，放入16384个slot中的一个，每个redis节点持有部分slot .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } 一致性hash算法是什么
.spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } Redis变慢如何排查
1）查看慢命令，分析是否存在复杂命令 2）查看是否存在大key 3）查看是否缓存雪崩 4）查看淘汰策略，查看内存是否打满 5）查看fork进程频率是否合理 6）查看内存分配是否合理 7）查看aof追加策略 8）如果是单机部署了多个redis，定位是否存在aof竞争问题 9）查看是否使用swap 10）查看网卡负载是否正常 .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } 如何为Redis一次增加大批量数据
1）管道2）手动拼接发送resp命令 .spoiler { color: black; background-color:black; } .spoiler:hover{ color: white; } 开发层次有哪些常用的优化建议
key的长度尽量要短，在数据量非常大时，过长的key名会占用更多的内存； 一定避免存储过大的数据（大value），过大的数据在分配内存和释放内存时耗时严重，会阻塞主线程； Redis 4.0以上建议开启lazy-free机制，释放大value时异步操作，不阻塞主线程； 建议设置过期时间，把Redis当做缓存使用，尤其在数量很大的时，不设置过期时间会导致内存的无限增长； 不使用复杂度过高的命令，例如SORT、SINTER、SINTERSTORE、ZUNIONSTORE、ZINTERSTORE，使用这些命令耗时较久，会阻塞主线程； 查询数据时，一次尽量获取较少的数据，在不确定容器元素个数的情况下，避免使用LRANGE key 0 -1，ZRANGE key 0 -1这类操作，应该设置具体查询的元素个数，推荐一次查询100个以下元素； 写入数据时，一次尽量写入较少的数据，例如HSET key value1 value2 value3…，控制一次写入元素的数量，推荐在100以下，大数据量分多个批次写入； 批量操作数据时，用MGET/MSET替换GET/SET、HMGET/MHSET替换HGET/HSET，减少请求来回的网络IO次数，降低延迟，对于没有批量操作的命令，推荐使用pipeline，一次性发送多个命令到服务端； 禁止使用KEYS命令，需要扫描实例时，建议使用SCAN，线上操作一定要控制扫描的频率，避免对Redis产生性能抖动 避免某个时间点集中过期大量的key，集中过期时推荐增加一个随机时间，把过期时间打散，降低集中过期key时Redis的压力，避免阻塞主线程； 根据业务场景，选择合适的淘汰策略，通常随机过期要比LRU过期淘汰数据更快； 使用连接池访问Redis，并配置合理的连接池参数，避免短连接，TCP三次握手和四次挥手的耗时也很高； 只使用db0，不推荐使用多个db，使用多个db会增加Redis的负担，每次访问不同的db都需要执行SELECT命令，如果业务线不同，建议拆分多个实例，还能提高单个实例的性能； 读的请求量很大时，推荐使用读写分离，前提是可以容忍从节数据更新不及时的问题； 写请求量很大时，推荐使用集群，部署多个实例分摊写压力 运维层次有哪些常用的优化建议 不同业务线部署不同的实例，各自独立，避免混用，推荐不同业务线使用不同的机器，根据业务重要程度划分不同的分组来部署，避免某一个业务线出现问题影响其他业务线； 保证机器有足够的CPU、内存、带宽、磁盘资源，防止负载过高影响Redis性能； 以master-slave集群方式部署实例，并分布在不同机器上，避免单点，slave必须设置为readonly； master和slave节点所在机器，各自独立，不要交叉部署实例，通常备份工作会在slave上做，做备份时会消耗机器资源，交叉部署会影响到master的性能； 推荐部署哨兵节点增加可用性，节点数量至少3个，并分布在不同机器上，实现故障自动故障转移； 提前做好容量规划，一台机器部署实例的内存上限，最好是机器内存的一半，主从全量同步时会占用最多额外一倍的内存空间，防止网络大面积故障引发所有master-slave的全量同步导致机器内存被吃光； 做好机器的CPU、内存、带宽、磁盘监控，在资源不足时及时报警处理，Redis使用Swap后性能急剧下降，网络带宽负载过高访问延迟明显增大，磁盘IO过高时开启AOF会拖慢Redis的性能； 设置最大连接数上限，防止过多的客户端连接导致服务负载过高； 单个实例的使用内存建议控制在10G以下，过大的实例会导致备份时间久、资源消耗多，主从全量同步数据时间阻塞时间更长； 设置合理的slowlog阈值，推荐10毫秒，并对其进行监控，产生过多的慢日志需要及时报警； 设置合理的复制缓冲区repl-backlog大小，适当调大repl-backlog可以降低主从全量复制的概率； 设置合理的slave节点client-output-buffer-limit大小，对于写入量很大的实例，适当调大可以避免主从复制中断问题； 备份时推荐在slave节点上做，不影响master性能； 不开启AOF或开启AOF配置为每秒刷盘，避免磁盘IO消耗降低Redis性能； 当实例设置了内存上限，需要调大内存上限时，先调整slave再调整master，否则会导致主从节点数据不一致； 对Redis增加监控，监控采集info信息时，使用长连接，频繁的短连接也会影响Redis性能； 线上扫描整个实例数时，记得设置休眠时间，避免扫描时QPS突增对Redis产生性能抖动； 做好Redis的运行时监控，尤其是expired_keys、evicted_keys、latest_fork_usec指标，短时间内这些指标值突增可能会阻塞整个实例，引发性能问题</content></entry><entry><title>MySQL排他锁实战</title><url>https://www.zyg-tech.me/post/mysql%E6%8E%92%E4%BB%96%E9%94%81%E5%AE%9E%E6%88%98/</url><categories><category>MySQL</category><category>锁</category></categories><tags><tag>MySQL</tag><tag>分布式锁</tag></tags><content type="html"> 1. 需求背景 ​ 基于MySQL/Oracle数据库实现分布式锁，保证一个项目中的定时任务代码在多台机器中同时执行时最多有一个任务可以成功获取锁，其他任务获取锁失败
2. 排他锁介绍 2.1 概念 ​ 如果事务T对数据A加上排他锁(exclusive lock，即X锁)后，则其他事务不能再对A加任任何类型的锁，将会等待事务T结束。获准排他锁的事务既能读数据，又能修改数据.
​ 在MySQL中，X锁仅适用于InnoDB引擎，而且必须在事务中才能生效，根据where条件是否通过索引命中数据，MySQL中的X锁分为行锁与表锁 ：命中数据时采用行锁，本质是对索引加锁；其他情况下均为表锁（例如没有where条件对应的数据，where后的字段没有索引）；特殊地，如果表数据过少，InnoDB引擎也可能将SQL优化为表锁，这种情况下可以通过force index来强制使用索引。
2.2 用法示例 2.2.1 基本用法 select … for update;
例如：select * from goods where id = 1 for update;
2.2.2 进阶用法 # nowait --&amp;gt; 不再等待事务而是立即返回结果，如果发现where条件的结果集被其他事务锁定则立即返回失败，该语法自MySQL的8.0版本开始支持，Oracle支持 select ... for update no wait; # wait --&amp;gt; 最多等待指定的时间x秒之后返回结果，该语法在Orale中支持 select ... for update wait x; # skip locked --&amp;gt; 如果数据锁定时跳过锁定的数据,该语法自MySQL的8.0版本开始支持，Oracle支持 select ... for update skip locked; 3.准备数据 3.1 准备表 create table t_gdts_sync_flag ( n_id bigint auto_increment comment '流水id' primary key, c_company_id varchar(20) null comment '集团id,对应t_gdts_company_rel的n_id', n_type tinyint(2) null comment '同步标识类型,1集团,2部门,3人员', c_status varchar(10) null comment '同步状态,sync/idle' ) comment '同步标识表'; 3.2 准备数据 INSERT INTO gropt.t_gdts_sync_flag (n_id, c_company_id, n_type, c_status) VALUES (75, '1326009432085127169', 1, 'idle'); INSERT INTO gropt.t_gdts_sync_flag (n_id, c_company_id, n_type, c_status) VALUES (76, '1326009432085127169', 2, 'idle'); INSERT INTO gropt.t_gdts_sync_flag (n_id, c_company_id, n_type, c_status) VALUES (77, '1326009432085127169', 3, 'idle'); 4. 实战 4.1 定义用于获取锁的线程池 4.2 获取锁的SQL语句 4.3 获取锁的Service代码 4.4 定时任务代码</content></entry><entry><title>Hystrix熔断器</title><url>https://www.zyg-tech.me/post/hystrix%E7%86%94%E6%96%AD%E5%99%A8/</url><categories><category>熔断</category></categories><tags><tag>服务高可用</tag><tag>熔断</tag></tags><content type="html"> 熔断器 状态及转换 Hystrix提供的熔断器具有自我反馈，自我恢复的功能，Hystrix会根据调用接口的情况，让熔断器在closed,open,half-open三种状态之间自动切换,三种状态简要说明如下:
closed : 代表关闭熔断,默认状态,在此期间执行远程调用方法 open : 代表打开熔断,在此期间执行本地降级策略,不执行远程调用 half-open : 代表中间状态,在此期间,先执行远程调用,如果成功,下次继续执行远程调用,如果失败,转换为open状态 1)正常状态下为closed状态,若访问接口超过设置阈值且错误请求数比例达到设置值时,转换为open状态,时间段从0开始(打开熔断)
2)保持open状态一个时间段;
3)下个时间段后,状态自动转换为half-open,在此期间,
​ 3.1)如果第一次请求时接口失败,则转换为open状态,时间段从0开始,
​ 3.2)如果请求数量达到设置阈值且错误请求书比例未达到设置值时,转换状态为closed,时间段从0开始(恢复正常),
​ 3.3)如果请求数量没有达到阈值, 一直保持half-open状态
核心流程 将远程服务调用逻辑封装进一个HystrixCommand。 对于每次服务调用可以使用同步或异步机制，对应执行execute()或queue()。 判断熔断器(circuit-breaker)是否打开或者半打开状态，如果打开跳到步骤8，进行回退策略，如果关闭进入步骤4。 判断线程池/队列/信号量（使用了舱壁隔离模式）是否跑满，如果跑满进入回退步骤8，否则继续后续步骤5。 run方法中执行了实际的服务调用。 a. 服务调用发生超时时，进入步骤8。 判断run方法中的代码是否执行成功。 a. 执行成功返回结果。 b. 执行中出现错误则进入步骤8。 所有的运行状态(成功，失败，拒绝，超时)上报给熔断器，用于统计从而影响熔断器状态。 进入getFallback()回退逻辑。 a. 没有实现getFallback()回退逻辑的调用将直接抛出异常。 b. 回退逻辑调用成功直接返回。 c. 回退逻辑调用失败抛出异常。 返回执行成功结果。</content></entry><entry><title>服务压测调优</title><url>https://www.zyg-tech.me/post/%E6%9C%8D%E5%8A%A1%E5%8E%8B%E6%B5%8B%E8%B0%83%E4%BC%98/</url><categories><category>调优</category></categories><tags><tag>服务优化</tag><tag>调优</tag><tag>Linux</tag></tags><content type="html"> 服务压测问题修复 Linux服务器环境优化 调整linux最大线程数 ​ /etc/sysctl.conf 配置文件中，加入 sys.kernel.threads-max = 40960
调整linux全局最大pid ​ /etc/sysctl.conf 配置文件中，加入 sys.kernel.pid_max = 40960
调整linux TCP进程参数 ​ /etc/sysctl.conf 配置文件中，加入 以下内容,执行：sysctl -p ，使设置立即生效：
# 进程可以同时打开的最大文件句柄数，这个参数直接限制最大并发连接数 fs.file-max=999999 ############## TCP数据窗口相关参数 ############## # 默认的TCP数据接收窗口大小/字节,默认229376 net.core.rmem_default = 256960 # 最大的TCP数据接收窗口大小/字节,默认131071 net.core.rmem_max = 513920 # 默认的TCP数据发送窗口大小/字节,默认229376 net.core.wmem_default = 256960 # 最大的TCP数据发送窗口/字节,默认131071 net.core.wmem_max = 513920 ################# TCP队列相关参数 ############### # 当网卡接收数据包的速度大于内核处理数据的时候，会有一个队列保存这些数据包,即接收队列长度。这个参数表示这个队列的最大值,默认1000 net.core.netdev_max_backlog = 2000 # TCP三次握手建立阶段服务器接收SYN请求队列的最大长度,即SYN半连接队列长度,对于超出该队列的请求直接丢弃 net.ipv4.tcp_max_syn_backlog = 262144 # 全局的每一个端口最大的监听队列的长度,默认128 net.core.somaxconn = 2048 ############## TCP缓冲区相关参数 ########### # 全局的所有TCP的SocketBuffer配置,该SocketBuffer用于发送方发送数据/接收方接受数据时存储这些数据,有三个值，单位为内存页(通常为4K):当TCP使用了低于第一个值的内存页面数时，TCP不会考虑释放内存;当TCP使用了超过第二个值的内存页面数量时,TCP试图稳定其内存使用，进入pressure模式;当内存占用超过第三个值，系统拒绝分配socket,报错TCP: too many of orphaned sockets.默认94011 125351 188022 net.ipv4.tcp_mem = 131072 262144 524288 # TCP读缓冲区/字节,三个值分别表示TCP接收缓存（用于TCP接收滑动窗口）的最小值、默认值、最大值,默认4096 87380 4011232 net.ipv4.tcp_rmem = 8760 256960 4088000 # TCP写缓冲区/字节,三个值分别表示TCP发送缓存（用于TCP接收滑动窗口）的最小值、默认值、最大值,默认4096 16384 4011232 net.ipv4.tcp_wmem = 8760 256960 4088000 # 每个套接字所允许的最大缓冲区的大小/字节,默认20480 net.core.optmem_max = 81920 ############### keepalive相关参数 ##################### # CLOSE_WAIT 状态维持的秒数 = tcp_keepalive_time + tcp_keepalive_intvl * tcp_keepalive_probes # 当keepalive启用时，TCP发送keealive消息的频度,默认7200/秒 net.ipv4.tcp_keepalive_time = 1800 # 以该参数指定的秒数为时间间隔/s，向客户端发起对它的探测 net.ipv4.tcp_keepalive_intvl = 30 # 内核发起对客户端探测的次数，如果都没有得到响应，那么就断定客户端不可达或者已关闭，内核就关闭该TCP连接 net.ipv4.tcp_keepalive_probes = 3 ############### Time_wait相关参数 ##################### # 是否开启timstamp校验,该配置项会影响net.ipv4.tcp_tw_reuse、net.ipv4.tcp_tw_recycle,只有发起方和接收方都开启该项才会使得net.ipv4.tcp_tw_reuse、net.ipv4.tcp_tw_recycle生效,该配置项提供以下两个功能:a.更加准确的RTT测量数据，尤其是有丢包时 – RTTM b. 保证了在极端情况下，TCP的可靠性 – PAWS net.ipv4.tcp_timestamps = 1 # 是否允许将TIME—WAIT状态的socket重新用于新的TCP连接,默认0,1开启,开启后将会在Time_wait状态的1s后复用socket net.ipv4.tcp_tw_reuse = 1 # 设置是否对TIME_WAIT状态的TCP进行快速回收,默认0,1开启 net.ipv4.tcp_tw_recycle = 1 # 当服务器主动关闭连接的时候，主动关闭方的socket保持在FIN-WAIT-2状态的最大时间/秒,默认60 net.ipv4.tcp_fin_timeout = 30 ############### 其他参数 ##################### # 是否启用有选择的应答,开启此项后,可以让发送方只发送丢失部分的数据,即支持乱序接收 net.ipv4.tcp_sack = 1 # 是否打开FACK拥塞避免和快速重传功能 net.ipv4.tcp_fack = 1 # 是否支持更大的TCP窗口,如果TCP窗口最大超过65535(64K), 必须设置该数值为1 net.ipv4.tcp_window_scaling = 1 # 是否打开SYN Cookie功能，该功能可以防止部分SYN flood攻击 net.ipv4.tcp_syncookies = 1 # 在UDP和TCP连接本地端口的取值范围 net.ipv4.ip_local_port_range = 1024 65000 调整linux最大文件数量 /etc/security/limits.conf文件尾部添加如下代码：
* soft nofile 65535 * hard nofile 65535 Tmcat参数优化 设置内存参数 tomcat安装目录/bin/catalina.sh 106 行添加以下内容
JAVA_OPTS=&amp;quot;-Xmx8192M -Xms8192M -XX:MaxPermSize=512M -XX:PermSize=512M -XX:+UseG1GC -XX:MaxGCPauseMillis=100 -XX:+ParallelRefProcEnabled -XX:+HeapDumpOnOutOfMemoryError -XX:+PrintGCApplicationStoppedTime -XX:+PrintHeapAtGC&amp;quot; 【注意】不要换行是一行 参数 参考地址为：https://console.perfma.com/ 线程数计算公式： Max memory （除去系统占用和其他应用程序占用后的操作系统总内存大小） = [-Xmx] + [-XX:MaxMetaSpaceSize] + number_of_threads * [-Xss]
修改日志打印 访问日志原始值：
&amp;lt;Valve className=&amp;quot;org.apache.catalina.valves.AccessLogValve&amp;quot; directory=&amp;quot;logs&amp;quot; prefix=&amp;quot;localhost_access_log.&amp;quot; suffix=&amp;quot;.txt&amp;quot; pattern=&amp;quot;%h %l %u %t %s %b&amp;quot; /&amp;gt; 调整后的值:
&amp;lt;Valve className=&amp;quot;org.apache.catalina.valves.AccessLogValve&amp;quot; directory=&amp;quot;logs&amp;quot; prefix=&amp;quot;localhost_access_log.&amp;quot; suffix=&amp;quot;.txt&amp;quot; pattern=&amp;quot;%h %l %u %t %q %s %b %F %D %I &amp;quot; /&amp;gt; pattern属性的值由文字文本字符串和以“％”字符为前缀的模式标识符组合而成，以替换为来自当前请求和响应的相应变量值。支持以下模式代码：(原始地址:http://tomcat.apache.org/tomcat-7.0-doc/config/valve.html)
％ a-远程IP地址 **％A-**本地IP地址 **％b-**发送的字节，不包括HTTP标头，如果为零则为&amp;rsquo;-&amp;rsquo; **％B-**发送的字节，不包括HTTP标头 **％h-**远程主机名（如果enableLookups连接器为false，则为IP地址 ） **％H-**请求协议 ％l -identd的远程逻辑用户名（总是返回“-”） **％m-**请求方法（GET，POST等） **％p-**接收此请求的本地端口。另请参见%{xxx}p下文。 **％q-**查询字符串（如果存在，则以“？”开头） **％r-**请求的第一行（方法和请求URI） **％s-**响应的HTTP状态代码 **％S-**用户会话ID **％t-**日期和时间，采用通用日志格式 **％u-**已验证（如果有）的远程用户，否则为&amp;rsquo;-&amp;rsquo; **％U-**请求的URL路径 **％v-**本地服务器名称 **％D-**以毫秒为单位处理请求所花费的时间。注意：在httpd中，％D是微秒。从Tomcat 10开始，行为将与httpd对齐。 **％T-**处理请求所花费的时间，以秒为单位。注意：此值具有毫秒分辨率，而在httpd中具有第二分辨率。行为将与Tomcat 10及更高版本中的httpd保持一致。 **％F-**提交响应所花费的时间（以毫秒为单位） **％I-**当前请求线程名称（以后可以与堆栈跟踪进行比较） 调整线程数 tomcat安装目录/conf/server.xml 71行
调整前原始值：
&amp;lt;Connector port=&amp;quot;8080&amp;quot; protocol=&amp;quot;HTTP/1.1&amp;quot; connectionTimeout=&amp;quot;20000&amp;quot; redirectPort=&amp;quot;8443&amp;quot; /&amp;gt; 调整后的值：
&amp;lt;Connector port=&amp;quot;8080&amp;quot; protocol=&amp;quot;HTTP/1.1&amp;quot; maxKeepAliveRequests=&amp;quot;200&amp;quot; socketBuffer=&amp;quot;9000&amp;quot; enableLookups=&amp;quot;false&amp;quot; tcpNoDelay=&amp;quot;true&amp;quot; minSpareThreads=&amp;quot;100&amp;quot; maxSpareThreads=&amp;quot;100&amp;quot; maxThreads=&amp;quot;2000&amp;quot; connectionTimeout=&amp;quot;5000&amp;quot; maxHttpHeaderSize=&amp;quot;32768&amp;quot; URIEncoding=&amp;quot;UTF-8&amp;quot; acceptCount=&amp;quot;200&amp;quot; redirectPort=&amp;quot;8443&amp;quot; /&amp;gt; 配置项解释
参数 含义 示例 port 绑定的端口,如果设置为0，tomcat则随机获取一个空闲端口 默认 port=&amp;quot;8080&amp;rdquo; protocol 传输协议和版本 默认 protocol = &amp;ldquo;HTTP/1.1&amp;rdquo; connectionTimeout 连接超时时间，单位毫秒 默认 connectionTimeout=&amp;quot;20000&amp;rdquo; redirectPort 接收到的ssl请求后重定向的端口 默认 redirectPort=&amp;quot;8443&amp;rdquo; maxThreads tomcat能创建来处理请求的最大线程数，也为最大并发数 超过则放入请求队列中进行排队，默认值为200；需要根据业务和系统性能进行调整 maxThreads=&amp;quot;1000&amp;rdquo; URIEncoding url的字符编码，在tomcat8.5版本中，该值默认为UTF-8,除非在org.apache.catalina.STRICT_SERVLET_COMPLIANCE 将system property 设置为true才会使用ISO-8859-1 URIEncoding=&amp;quot;UTF-8&amp;rdquo; minProcessors 启动时创建的线程数（最小线程数） minProcessors=&amp;quot;50&amp;rdquo; acceptCount 指定当所有可以使用的处理请求的线程数都被使用时，可以放到队列中的请求数，就是被排队的请求数，超过这个数的请求将拒绝连接 默认值为100 acceptcount=&amp;quot;500&amp;rdquo; acceptorThreadCount 可以用于接受连接的进程数，默认为1，但是在一些多核的的服务器上，我们会将它的值设置为2或者更大的数，来应对一些不活跃的连接。 minSpareThreads 最小空闲线程数，任何情况都会存活的线程数，即便超过了最大空闲时间，也不会被回收，默认值10; minSpareThreads=&amp;quot;25&amp;rdquo; maxSpareThreads 最大空闲线程数，在最大空闲时间（maxIdleTime）内活跃过，此时空闲，当空闲时间大于maxIdleTime则被回收，小则继续存活，等待被调度，默认值50； enableLookups 调用request、getRemoteHost()执行DNS查询，以返回远程主机的主机名，如果设置为false，则直接返回IP地址 默认是禁用的，在请求过滤中的根据远程主机名过滤，需要将该参数设置为true enableLookups=&amp;quot;false&amp;rdquo; maxIdleTime 最大空闲时间，超过这个空闲时间，且线程数大于minSpareThreads的，都会被回收，默认值1分钟（60000ms) maxPostSize address 对于一些具有多个ip的服务器，我们可以通过该参数指定绑定的ip，默认情况下监听所有的地址 address=&amp;quot;192.168.1.110&amp;rdquo; compressibleMimeType 该值用来指定哪些文件类型的文件可以进行压缩，默认值为：text/html,text/xml,text/plain,text/css,text/javascript,application/javascript compression 开启gzip 压缩，可以接受的值是 &amp;ldquo;off&amp;rdquo;(禁用压缩),&amp;ldquo;on&amp;rdquo;(开启压缩),&amp;ldquo;force(强制压缩)&amp;quot;，&amp;ldquo;1-9&amp;rdquo;(等效于开启压缩，并且设定压缩等级),开启了压缩，也就意味着要占用更多的cpu资源 compression compressionMinSize 在compression 参数指定为on后，该参数用来指定压缩的阈值，只有大于该阈值才会被压缩，默认为 2048 keepAliveTimeout 指connector两个HTTP请求直接的等待时间，超过该时间没有接收到第二个HTTP请求就关闭连接，默认是使用connectionTimeout 的值，单位为毫秒 maxConnections 在一定时间内可以接受和处理的最大连接数，达到限制后，服务器接受但不处理该链接，但可以存放到acceptCount，该默认值因连接器类型而异。对于NIO和NIO2，默认值为10000。对于APR / native，默认为8192。 maxCookieCount 请求允许的最大cookie 数，值小于0表示无限制，默认值为 200 disableUploadTimeout 默认是true ，禁用数据上传超时 connectionUploadTimeout 设定数据上传的超时时间，只有在disableUploadTimeout设置为false才生效，单位毫秒 connectionUploadTimeout=&amp;quot;50000&amp;rdquo; processorCache 进程缓冲器，默认值是maxThreads的值,使用好该值可以提升并发请求。</content></entry><entry><title>Docker 常用命令</title><url>https://www.zyg-tech.me/post/docker-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url><categories><category>Docker</category></categories><tags><tag>容器化</tag><tag>部署运维</tag><tag>Docker</tag><tag>命令</tag></tags><content type="html"> Docker是一个开源的应用容器引擎，让开发者可以打包应用及依赖包到一个可移植的镜像中，然后发布到任何流行的Linux或Windows机器上。使用Docker可以更方便地打包、测试以及部署应用程序。
Docker环境安装 安装yum-utils； yum install -y yum-utils device-mapper-persistent-data lvm2 复制代码 为yum源添加docker仓库位置； yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 复制代码 安装docker服务； yum install docker-ce 复制代码 启动docker服务。 systemctl start docker 复制代码 Docker镜像常用命令 搜索镜像 docker search java 复制代码 下载镜像 docker pull java:8 复制代码 查看镜像版本 由于docker search命令只能查找出是否有该镜像，不能找到该镜像支持的版本，所以我们需要通过Docker Hub来搜索支持的版本。
进入Docker Hub的官网，地址：https://hub.docker.com
然后搜索需要的镜像：
查看镜像支持的版本：
进行镜像的下载操作：
docker pull nginx:1.17.0 列出镜像 docker images 删除镜像 指定名称删除镜像： docker rmi java:8 指定名称删除镜像（强制）： docker rmi -f java:8 删除所有没有引用的镜像： docker rmi `docker images | grep none | awk &amp;#39;{print $3}&amp;#39;` 强制删除所有镜像： docker rmi -f $(docker images) 打包镜像 # -t 表示指定镜像仓库名称/镜像名称:镜像标签 .表示使用当前目录下的Dockerfile文件 docker build -t mall/mall-admin:1.0-SNAPSHOT . Docker容器常用命令 新建并启动容器 docker run -p 80:80 --name nginx \ -e TZ=&amp;#34;Asia/Shanghai&amp;#34; \ -v /mydata/nginx/html:/usr/share/nginx/html \ -d nginx:1.17.0 -p：将宿主机和容器端口进行映射，格式为：宿主机端口:容器端口； &amp;ndash;name：指定容器名称，之后可以通过容器名称来操作容器； -e：设置容器的环境变量，这里设置的是时区； -v：将宿主机上的文件挂载到宿主机上，格式为：宿主机文件目录:容器文件目录； -d：表示容器以后台方式运行。 列出容器 列出运行中的容器： docker ps 列出所有容器： docker ps -a 停止容器 注意：$ContainerName表示容器名称，$ContainerId表示容器ID，可以使用容器名称的命令，基本也支持使用容器ID，比如下面的停止容器命令。
docker stop $ContainerName(or $ContainerId) 例如：
docker stop nginx #或者 docker stop c5f5d5125587 强制停止容器 docker kill $ContainerName 启动容器 docker start $ContainerName 进入容器 先查询出容器的pid： docker inspect --format &amp;#34;{{.State.Pid}}&amp;#34; $ContainerName 根据容器的pid进入容器： nsenter --target &amp;#34;$pid&amp;#34; --mount --uts --ipc --net --pid 删除容器 删除指定容器： docker rm $ContainerName 按名称通配符删除容器，比如删除以名称mall-开头的容器： docker rm `docker ps -a | grep mall-* | awk &amp;#39;{print $1}&amp;#39;` 强制删除所有容器； docker rm -f $(docker ps -a -q) 查看容器的日志 查看容器产生的全部日志： docker logs $ContainerName 动态查看容器产生的日志： docker logs -f $ContainerName 查看容器的IP地址 docker inspect --format &amp;#39;{{ .NetworkSettings.IPAddress }}&amp;#39; $ContainerName 修改容器的启动方式 # 将容器启动方式改为always docker container update --restart=always $ContainerName 同步宿主机时间到容器 docker cp /etc/localtime $ContainerName:/etc/ 指定容器时区 docker run -p 80:80 --name nginx \ -e TZ=&amp;#34;Asia/Shanghai&amp;#34; \ -d nginx:1.17.0 查看容器资源占用状况 查看指定容器资源占用状况，比如cpu、内存、网络、io状态： docker stats $ContainerName 查看所有容器资源占用情况： docker stats -a 查看容器磁盘使用情况 docker system df 执行容器内部命令 docker exec -it $ContainerName /bin/bash 指定账号进入容器内部 # 使用root账号进入容器内部 docker exec -it --user root $ContainerName /bin/bash 查看所有网络 docker network ls ## 结果示例 [root@local-linux ~]# docker network ls NETWORK ID NAME DRIVER SCOPE 59b309a5c12f bridge bridge local ef34fe69992b host host local a65be030c632 none 创建外部网络 docker network create -d bridge my-bridge-network 指定容器网络 docker run -p 80:80 --name nginx \ --network my-bridge-network \ -d nginx:1.17.0 修改镜像的存放位置 查看Docker镜像的存放位置： docker info | grep &amp;#34;Docker Root Dir&amp;#34; 关闭Docker服务： systemctl stop docker 先将原镜像目录移动到目标目录： mv /var/lib/docker /mydata/docker 建立软连接： ln -s /mydata/docker /var/lib/docker 再次查看可以发现镜像存放位置已经更改。 本文 GitHub github.com/macrozheng/… 已经收录，欢迎大家Star！
作者：MacroZheng 链接：https://juejin.cn/post/6895888125886332941 来源：掘金 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</content></entry><entry><title>Spring中Async的使用与源码解析</title><url>https://www.zyg-tech.me/post/spring%E4%B8%ADasync%E7%9A%84%E4%BD%BF%E7%94%A8%E4%B8%8E%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/</url><categories><category>SpringBoot</category><category>线程池</category></categories><tags><tag>线程池</tag><tag>异步</tag><tag>SpringBoot</tag></tags><content type="html"> 背景介绍 对于异步方法调用，从Spring3开始提供了@Async注解，该注解可以被标注在方法上，以便异步地调用该方法。调用者将在调用时立即返回，方法的实际执行将提交给Spring TaskExecutor的任务中，由指定的线程池中的线程执行。
常见的场景 系统日志记录 耗时任务的执行 使用方法 1.启动类增加@EnableAsync注解(since Spring 3.1)
@EnableAsync @SpringBootApplication public class SpringBootDemoAsyncApplication { public static void main(String[] args) { SpringApplication.run(SpringBootDemoAsyncApplication.class, args); } } 2.如有需要，可以自定义线程池
@Configuration public class ExecutorConfiguration { /** * 配置应用访问日志专用线程池 * @return */ @Bean(name = &amp;#34;sodAppLogAsyncExecutor&amp;#34;) public ThreadPoolTaskExecutor asyncExecutor() { ThreadPoolTaskExecutor threadPool = new ThreadPoolTaskExecutor(); threadPool.setThreadNamePrefix(&amp;#34;drs-sodAppLog-&amp;#34;); threadPool.setCorePoolSize(3); threadPool.setMaxPoolSize(4); threadPool.setKeepAliveSeconds(60); threadPool.setQueueCapacity(11); threadPool.setRejectedExecutionHandler(new ThreadPoolExecutor.DiscardPolicy()); //优雅关闭 threadPool.setWaitForTasksToCompleteOnShutdown(true); threadPool.setAwaitTerminationSeconds(60 * 15); return threadPool; } } 3.在需要使用异步的方法上添加@Async注解，可以通过value属性指定线程池,返回值支持void、Future、ListenableFuture、CompletableFuture，如果不指定value，那么采用默认线程池
/** * 模拟5秒的异步任务 */ @Async public Future&amp;lt;Boolean&amp;gt; asyncTask1() throws InterruptedException { doTask(&amp;#34;asyncTask1&amp;#34;, 5); return new AsyncResult&amp;lt;&amp;gt;(Boolean.TRUE); } /** * 模拟业务代码 * @param taskName * @param time */ private void doTask(String taskName, Integer time) { log.info(&amp;#34;{}模拟执行【{}】,线程内存地址:{}&amp;#34;, taskName, Thread.currentThread().getName(), UnsafeUtil.addressOf(Thread.currentThread())); } Spring实现的线程池 SimpleAsyncTaskExecutor：默认线程池，每次调用都启动一个新线程(并不会复用线程池已有线程),支持对并发总数设限（ConcurrencyLimit，默认-1不限制，0不允许），当超过线程并发总数限制时，阻塞新的调用 ThreadPoolTaskExecutor:对JDK的ThreadPoolExecutor的封装，SpringBoot通过TaskExecutionAutoConfiguration自动装配了一个名为applicationTaskExecutor的ThreadPoolTaskExecutor @ConditionalOnClass(ThreadPoolTaskExecutor.class) @Configuration @EnableConfigurationProperties(TaskExecutionProperties.class) public class TaskExecutionAutoConfiguration { @Bean @ConditionalOnMissingBean public TaskExecutorBuilder taskExecutorBuilder() { TaskExecutionProperties.Pool pool = this.properties.getPool(); TaskExecutorBuilder builder = new TaskExecutorBuilder(); builder = builder.queueCapacity(pool.getQueueCapacity()); builder = builder.corePoolSize(pool.getCoreSize()); builder = builder.maxPoolSize(pool.getMaxSize()); builder = builder.allowCoreThreadTimeOut(pool.isAllowCoreThreadTimeout()); builder = builder.keepAlive(pool.getKeepAlive()); builder = builder.threadNamePrefix(this.properties.getThreadNamePrefix()); builder = builder.customizers(this.taskExecutorCustomizers); builder = builder.taskDecorator(this.taskDecorator.getIfUnique()); return builder; } @Lazy @Bean(name = APPLICATION_TASK_EXECUTOR_BEAN_NAME) @ConditionalOnMissingBean(Executor.class) public ThreadPoolTaskExecutor applicationTaskExecutor(TaskExecutorBuilder builder) { return builder.build(); } } SimpleAsyncTaskExecutor 属性列表
Daemon:是否为守护线程，默认false ThreadPriority:线程优先级,默认5 ThreadNamePrefix:线程名前缀，默认&amp;quot;SimpleAsyncTaskExecutor&amp;rdquo; ConcurrencyLimit:并发上限,默认-1不限制，0表示不允许并发？？？？ ThreadPoolTaskExecutor 属性列表
CorePoolSize：线程池创建时候初始化的线程数,默认1 MaxPoolSize：线程池最大的线程数，只有在缓冲队列满了之后才会申请超过核心线程数的线程，默认Integer.MAX QueueCapacity：用来缓冲执行任务的队列的队列大小，默认Integer.MAX KeepAliveSeconds：线程的空闲时间，单位/s，当超过了核心线程出之外的线程在空闲时间到达之后会被销毁,默认60 ThreadNamePrefix：线程池中线程名的前缀，继承自父类ExecutorConfigurationSupport，默认是BeanName/方法名 RejectedExecutionHandler：线程池对拒绝任务的处理策略，自父类ExecutorConfigurationSupport,（策略为JDK ThreadPoolExecutor自带） AbortPolicy：默认策略，直接抛出异常 RejectedExecutionException CallerRunsPolicy：直接在 execute 方法的调用线程中运行被拒绝的任务；如果执行程序已关闭，则会丢弃该任务 DiscardPolicy：该策略直接丢弃 DiscardOldestPolicy：该策略会先将最早入队列的未执行的任务丢弃掉，然后尝试执行新的任务。如果执行程序已关闭，则会丢弃该任务 waitForTasksToCompleteOnShutdown：关闭程序时是否等待任务执行完毕，继承自父类ExecutorConfigurationSupport，默认false表示中断正在执行的任务，清空队列 awaitTerminationSeconds：关闭程序时的等待时间，需配合waitForTasksToCompleteOnShutdown使用，继承自父类ExecutorConfigurationSupport，默认0 线程处理流程 /** * Executes the given task sometime in the future. The task * may execute in a new thread or in an existing pooled thread. * * If the task cannot be submitted for execution, either because this * executor has been shutdown or because its capacity has been reached, * the task is handled by the current {@code RejectedExecutionHandler}. * * @param command the task to execute * @throws RejectedExecutionException at discretion of * {@code RejectedExecutionHandler}, if the task * cannot be accepted for execution * @throws NullPointerException if {@code command} is null */ public void execute(Runnable command) { if (command == null) throw new NullPointerException(); /* * Proceed in 3 steps: * * 1. If fewer than corePoolSize threads are running, try to * start a new thread with the given command as its first * task. The call to addWorker atomically checks runState and * workerCount, and so prevents false alarms that would add * threads when it shouldn&amp;#39;t, by returning false. * * 2. If a task can be successfully queued, then we still need * to double-check whether we should have added a thread * (because existing ones died since last checking) or that * the pool shut down since entry into this method. So we * recheck state and if necessary roll back the enqueuing if * stopped, or start a new thread if there are none. * * 3. If we cannot queue task, then we try to add a new * thread. If it fails, we know we are shut down or saturated * and so reject the task. */ int c = ctl.get(); if (workerCountOf(c) &amp;lt; corePoolSize) { if (addWorker(command, true)) return; c = ctl.get(); } if (isRunning(c) &amp;amp;&amp;amp; workQueue.offer(command)) { int recheck = ctl.get(); if (! isRunning(recheck) &amp;amp;&amp;amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); } else if (!addWorker(command, false)) reject(command); } 如果此时线程池中的数量小于corePoolSize，即使线程池中的线程都处于空闲状态，也要创建新的线程来处理被添加的任务。 如果此时线程池中的数量等于 corePoolSize，但是缓冲队列 workQueue未满，那么任务被放入缓冲队列。 如果此时线程池中的数量大于corePoolSize，缓冲队列workQueue满，并且线程池中的数量小于maxPoolSize，那么建新的线程来处理被添加的任务。 如果此时线程池中的数量大于corePoolSize，缓冲队列workQueue满，并且线程池中的数量等于maxPoolSize，那么通过handler所指定的策略来处理此任务。（也就是：处理任务的优先级为：核心线程corePoolSize、任务队列workQueue、最大线程 maxPoolSize，如果三者都满了，使用handler处理被拒绝的任务） 当线程池中的线程数量大于corePoolSize时，如果某线程空闲时间超过keepAliveTime，线程将被终止。这样，线程池可以动态的调整池中的线程数 自定义线程池 自定义线程池有如下模式：
配置由自定义的TaskExecutor 重新实现接口AsyncConfigurer 继承AsyncConfigurerSupport 方式一：自定义TaskExecutor @Configuration public class ExecutorConfiguration { /** * 配置应用访问日志专用线程池 * @return */ @Bean(name = &amp;#34;sodAppLogAsyncExecutor&amp;#34;) public ThreadPoolTaskExecutor asyncExecutor() { ThreadPoolTaskExecutor threadPool = new ThreadPoolTaskExecutor(); threadPool.setThreadNamePrefix(&amp;#34;drs-sodAppLog-&amp;#34;); threadPool.setCorePoolSize(3); threadPool.setMaxPoolSize(4); threadPool.setKeepAliveSeconds(60); threadPool.setQueueCapacity(11); threadPool.setRejectedExecutionHandler(new ThreadPoolExecutor.DiscardPolicy()); //优雅关闭 threadPool.setWaitForTasksToCompleteOnShutdown(true); threadPool.setAwaitTerminationSeconds(60 * 15); return threadPool; } } 方式二：实现AsyncConfigurer /** * 自定义线程池方法二：自定义类，配置默认Executor与默认异步异常处理器 * @author zyg */ @Configuration public class CusAsyncConfigure implements AsyncConfigurer { /** * 配置默认Executor */ @Override public Executor getAsyncExecutor() { ThreadPoolTaskExecutor threadPool = new ThreadPoolTaskExecutor(); threadPool.setThreadNamePrefix(&amp;#34;cus-async-configure-&amp;#34;); threadPool.setCorePoolSize(2); threadPool.setMaxPoolSize(3); threadPool.setKeepAliveSeconds(60); threadPool.setQueueCapacity(5); threadPool.setRejectedExecutionHandler(new ThreadPoolExecutor.DiscardPolicy()); return threadPool; } /** * 配置默认异步异常处理器 */ @Override public AsyncUncaughtExceptionHandler getAsyncUncaughtExceptionHandler() { return new CusAsyncUncaughtExceptionHandler(); } } （原理是ProxyAsyncConfiguration的父类AbstractAsyncConfiguration的setConfigurers(Collection)中执行了AsyncConfigurer的方法来配置Executor与AsyncUncaughtExceptionHandler）
方式三：继承AsyncConfigurerSupport /** * 自定义线程池方法三:继承AsyncConfigurerSupport,重写getAsyncExecutor与getAsyncUncaughtExceptionHandler * @author zyg */ @Configuration public class CusAsyncConfigurerSupport extends AsyncConfigurerSupport { /** * 配置默认Executor */ @Override public Executor getAsyncExecutor() { ThreadPoolTaskExecutor threadPool = new ThreadPoolTaskExecutor(); threadPool.setThreadNamePrefix(&amp;#34;cus-async-configure-support-&amp;#34;); threadPool.setCorePoolSize(2); threadPool.setMaxPoolSize(3); threadPool.setKeepAliveSeconds(60); threadPool.setQueueCapacity(5); threadPool.setRejectedExecutionHandler(new ThreadPoolExecutor.DiscardPolicy()); return threadPool; } /** * 配置默认异步异常处理器 */ @Override public AsyncUncaughtExceptionHandler getAsyncUncaughtExceptionHandler() { return new CusAsyncUncaughtExceptionHandler(); } } （原理是AsyncConfigurerSupport的父类是AsyncConfigurer）
异常处理 如果任务的返回类型是Future，那么将直接抛出异常，否则异常由AsyncUncaughtExceptionHandler的handleUncaughtException()进行处理，Spring自4.1默认提供了SimpleAsyncUncaughtExceptionHandler，该类处理异常的逻辑是通过日志打印错误，如有需要可以自定义类继承AsyncUncaughtExceptionHandler，复写其handleUncaughtException()方法。
/** * 自定义线程池方法二：自定义默认异步异常处理器 * @author zyg */ @Component public class CusAsyncUncaughtExceptionHandler implements AsyncUncaughtExceptionHandler { private Logger logger = LoggerFactory.getLogger(this.getClass()); @Override public void handleUncaughtException(Throwable ex, Method method, Object... params) { logger.error(&amp;#34;自定义异步异常处理器捕捉到异常，&amp;#34;,ex); } } @EnableAsync加载流程 前置知识点 @Import注解的作用 BeanPostProcessor在Spring中的作用 Aware类接口在Spring中的作用 切面与通知的概念与作用 代码分析： @EnableAsync中Import了AsyncConfigurationSelector； AsyncConfigurationSelector的作用是通过配置确定是调用ProxyAsyncConfiguration还是AspectJ的AspectJAsyncConfiguration； 在ProxyAsyncConfiguration的asyncAdvisor()方法可以看到，其中定义了后置处理器AsyncAnnotationBeanPostProcessor AsyncAnnotationBeanPostProcessor直接或间接实现了BeanFactoryAware、BeanPostProcessor两个接口，既然AsyncAnnotationBeanPostProcessor实现了BeanFactoryAware，那么就会执行setBeanFactory(BeanFactory)方法,该方法中设置了切面AsyncAnnotationAdvisor 切面中定义了切点：类上标注@Async、@Asynchronous注解的切点与在方法上标注@Async、@Asynchronous注解的切点 切面中定义了通知：通知Executor与SimpleAsyncUncaughtExceptionHandler， 通知具体的实现类为AnnotationAsyncExecutionInterceptor，它的父类AsyncExecutionInterceptor进行了实际的通知处理操作 配置默认Executor 在生成切面AsyncAnnotationAdvisor对象时，生成了AnnotationAsyncExecutionInterceptor对象，调用了AnnotationAsyncExecutionInterceptor的configure(Supplier,Supplier)方法,在该方法中，调用了getDefaultExecutor(BeanFactory)来寻找默认Executor，查找Executor的优先级如下：
从BeanFactory中查找类型为TaskExecutor的对象 从BeanFactory中查找类型为Executor、Bean名称为taskExecutor的对象 如果上述步骤中找不到，那么子类AsyncExecutionInterceptor中生成SimpleAsyncTaskExecutor对象 通知的处理 通过determineAsyncExecutor(Method)方法查找AsyncExecutor 包装一下任务，当任务出现异常时调用AsyncUncaughtExceptionHandler的handleUncaughtException()处理异常 调用AsyncExecutor的submit()/submitListenable()/CompletableFuture.supplyAsync()等方法提交任务 查找AsyncExecutor AsyncExecutionAspectSupport的determineAsyncExecutor(Method)中查找了AsyncEexcutor，逻辑如下
首先尝试从成员变量Map&amp;lt;Method, AsyncTaskExecutor&amp;gt; executors查找是否存在，如果存在则返回 然后从AsyncExecutionAspectSupport.getExecutorQualifier()获取专属于该Method的AsyncExecutor的Bean名称，如果存在，则向BeanFactory获取类型为Executor、Bean名称为该名称的Executor并返回 从成员变量SingletonSupplier获取，如果存在则返回 如果经过上述几步查找仍然无法找到那么就返回空 如果经过上述几步找到了Executor，判断Executor的类型 如果是AsyncListenableTaskExecutor，将其强制转换为AsyncListenableTaskExecutor后放入到成员变量executors中 如果不是AsyncListenableTaskExecutor，通过TaskExecutorAdapter包装一个concurrentExecutor然后放入到成员变量executors中 异步事务 在@Async标注的方法，同时也适用了@Transactional进行了标注；在其调用数据库操作时，将无法产生事务管理的控制，原因就在于其是基于异步处理的操作。 那该如何给这些操作添加事务管理呢？可以将需要事务管理操作的方法放置到异步方法内部，在内部被调用的方法上添加@Transactional. 例如： 方法A，同时使用了@Async/@Transactional来标注，但是无法产生事务控制的目的。 方法B，使用了@Async来标注， B中调用了方法C、D，方法C、D分别使用@Transactional做了标注，则可实现事务控制的目的。</content></entry><entry><title>Netty架构简介</title><url>https://www.zyg-tech.me/post/netty%E6%9E%B6%E6%9E%84%E7%AE%80%E4%BB%8B/</url><categories><category>Netty</category></categories><tags><tag>高性能组件</tag><tag>代码研究</tag></tags><content type="html"> Netty功能特性如下
1）传输服务：支持 BIO 和 NIO；
2）容器集成：支持 OSGI、JBossMC、Spring、Guice 容器；
3）协议支持：HTTP、Protobuf、二进制、文本、WebSocket 等一系列常见协议都支持。还支持通过实行编码解码逻辑来实现自定义协议；
4）Core 核心：可扩展事件模型、通用通信 API、支持零拷贝的 ByteBuf 缓冲对象。
高性能设计 Netty 作为异步事件驱动的网络，高性能之处主要来自于其 I/O 模型和线程处理模型，前者决定如何收发数据，后者决定如何处理数据
Netty采用的I/O模型为NIO,如下图
Netty采用的线程处理模型为Reactor模型.Reactor 模型中有 2 个关键组成：
1）Reactor：Reactor 在一个单独的线程中运行，负责监听和分发事件，分发给适当的处理程序来对 IO 事件做出反应。它就像公司的电话接线员，它接听来自客户的电话并将线路转移到适当的联系人；
2）Handlers：处理程序执行 I/O 事件要完成的实际事件，类似于客户想要与之交谈的公司中的实际官员。Reactor 通过调度适当的处理程序来响应 I/O 事件，处理程序执行非阻塞操作。
Reactor模型共有3个变种:单 Reactor 单线程、单 Reactor 多线程、主从 Reactor 多线程.
Netty的线程模型是基于主从 Reactors 多线程模型进行修改.
核心组件 Boostrap:客户端程序的启动引导类,主要作用是配置整个 Netty 程序，串联各个组件
ServerBootstrap:服务端启动引导类
ChannelEvent : 因为Netty是基于事件驱动的，ChannelEvent就相当于某一个事件，比如说连接成功时打印一句话
Channel:网络通信的组件，能够用于执行网络 I/O 操作,下面是一些常用的 Channel 类型：
NioSocketChannel，异步的客户端 TCP Socket 连接。 NioServerSocketChannel，异步的服务器端 TCP Socket 连接。 NioDatagramChannel，异步的 UDP 连接。 NioSctpChannel，异步的客户端 Sctp 连接。 NioSctpServerChannel，异步的 Sctp 服务器端连接，这些通道涵盖了 UDP 和 TCP 网络 IO 以及文件 IO。
Selector:通过 Selector 一个线程可以监听多个连接的 Channel 事件。当向一个 Selector 中注册 Channel 后，Selector 内部的机制就可以自动不断地查询Selector中注册的 Channel 是否有已就绪的 I/O 事件（例如可读，可写，网络连接完成等），这样程序就可以很简单地使用一个线程高效地管理多个 Channel
NioEventLoop:NioEventLoop 中维护了一个线程和任务队列，支持异步提交执行任务，线程启动时会调用 NioEventLoop 的 run 方法，执行 I/O 任务和非 I/O 任务
NioEventLoopGroup : 主要管理 eventLoop 的生命周期，可以理解为一个线程池，内部维护了一组线程，每个线程(NioEventLoop)负责处理多个 Channel 上的事件
ChannelHandler : 一个接口，处理 I/O 事件或拦截 I/O 操作，并将其转发到其 ChannelPipeline(业务处理链)中的下一个处理程序。
ChannelHandler 本身并没有提供很多方法，因为这个接口有许多的方法需要实现，方便使用期间，可以继承它的子类：
ChannelInboundHandler 用于处理入站 I/O 事件。 ChannelOutboundHandler 用于处理出站 I/O 操作。
或者使用以下适配器类：
ChannelInboundHandlerAdapter 用于处理入站 I/O 事件。 ChannelOutboundHandlerAdapter 用于处理出站 I/O 操作。 ChannelDuplexHandler 用于处理入站和出站事件。
ChannelPipline : 保存 ChannelHandler 的 List，用于处理或拦截 Channel 的入站事件和出站操作,可以理解为一种高级形式的拦截过滤器模式
ChannelHandlerContext : 保存 Channel 相关的所有上下文信息
组件间关系 当客户端和服务端连接的时候会建立一个 Channel,这个 Channel 我们可以理解为 Socket 连接，它负责基本的 IO 操作，例如：bind（），connect（），read（），write（） 等等,简单的说，Channel 就是代表连接，实体之间的连接，程序之间的连接，文件之间的连接，设备之间的连接。同时它也是数据入站和出站的载体。
EventLoopGroup、EventLoop、Channel关系如下
在 Netty 中每个 Channel 都有且仅有一个 ChannelPipeline 与之对应，它们的组成关系如下：
一个 Channel 包含了一个 ChannelPipeline，而 ChannelPipeline 中又维护了一个由 ChannelHandlerContext 组成的双向链表，并且每个 ChannelHandlerContext 中又关联着一个 ChannelHandler。
入站事件和出站事件在一个双向链表中，入站事件会从链表 head 往后传递到最后一个入站的 handler，出站事件会从链表 tail 往前传递到最前一个出站的 handler，两种类型的 handler 互不干扰。
这些核心组件的整体关系如下
核心工作流程 典型的初始化并启动 Netty 服务端的过程代码如下：
public final class EchoServer { static final boolean SSL = System.getProperty(&amp;#34;ssl&amp;#34;) != null; static final int PORT = Integer.parseInt(System.getProperty(&amp;#34;port&amp;#34;, &amp;#34;8007&amp;#34;)); public static void main(String[] args) throws Exception { // 配置SSL final SslContext sslCtx; if (SSL) { SelfSignedCertificate ssc = new SelfSignedCertificate(); sslCtx = SslContextBuilder.forServer(ssc.certificate(), ssc.privateKey()).build(); } else { sslCtx = null; } // 配置服务端 EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); final EchoServerHandler serverHandler = new EchoServerHandler(); try { ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 100) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChannelInitializer&amp;lt;SocketChannel&amp;gt;() { @Override public void initChannel(SocketChannel ch) throws Exception { ChannelPipeline p = ch.pipeline(); if (sslCtx != null) { p.addLast(sslCtx.newHandler(ch.alloc())); } //p.addLast(new LoggingHandler(LogLevel.INFO)); p.addLast(serverHandler); } }); // Start the server. ChannelFuture f = b.bind(PORT).sync(); // Wait until the server socket is closed. f.channel().closeFuture().sync(); } finally { // Shut down all event loops to terminate all threads. bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } } 基本过程描述如下：
1）初始化创建 2 个 NioEventLoopGroup：其中 boosGroup 用于 Accetpt 连接建立事件并分发请求，workerGroup 用于处理 I/O 读写事件和业务逻辑。
2）基于 ServerBootstrap(服务端启动引导类)：配置 EventLoopGroup、Channel 类型，连接参数、配置入站、出站事件 handler。
3）绑定端口：开始工作。
Netty启动流程图如下
结合上面介绍的 Netty Reactor 模型，介绍服务端 Netty 的工作架构图：
ps:上图中NioEventGroup有误,应为NioEventLoop</content></entry><entry><title>TopN问题解决</title><url>https://www.zyg-tech.me/post/topn%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/</url><categories><category>数据库</category></categories><tags><tag>MySQL</tag><tag>TopN</tag></tags><content type="html"> 需求 将数据分组,每组内取前n条.最常见的需求是取每组内第一条,例如以imei分组,组内取time最新的一条
表结构 create table com( n_id int auto_increment primary key, c_imei varchar(10) null, c_time bigint null, c_name varchar(10) null ); create index com_c_imei_index on com (c_imei); 表数据 INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (1, 'a', 8, '010101'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (2, 'e', 2, '020202'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (3, 'c', 9, '030303'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (4, 'b', 4, '040404'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (5, 'd', 5, '050505'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (6, 'a', 6, '060606'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (7, 'e', 4, '070707'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (8, 'c', 3, '0808080'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (9, 'b', 5, '090909'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (10, 'd', 8, '101010'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (11, 'a', 5, '111111'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (12, 'e', 7, '121212'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (13, 'c', 2, '131313'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (14, 'b', 6, '141414'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (15, 'd', 9, '151515'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (16, 'a', 2, '161616'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (17, 'e', 1, '171717'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (18, 'c', 5, '181818'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (19, 'b', 8, '191919'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (20, 'd', 7, '202020'); SQL #方法一，自连接 SELECT a.c_imei, a.n_id, a.c_time FROM com a LEFT JOIN com b ON a.c_imei = b.c_imei AND a.c_time &amp;lt; b.c_time WHERE b.c_time IS NULL ORDER BY a.c_imei; #方法一的另一种形式,如果要取每组内前n条，那么将1改成n即可 SELECT n_id, c_imei, c_time, c_name FROM com a WHERE (SELECT count(*) FROM com b WHERE a.c_imei = b.c_imei AND a.c_time &amp;lt; b.c_time) &amp;lt; 1 order by c_imei; #方法二，派生表排序后分组，注意limit必须加不然没用 select n_id, c_imei, c_time, c_name from (select n_id, c_imei, c_time, c_name from com order by c_time desc limit 999999) a group by a.c_imei; #方法三,相关子查询，注意GROUP_CONCAT结果的长度受限于group_concat_max_len，默认1024 SELECT n_id, c_imei, c_time, c_name FROM com WHERE n_id IN (SELECT SUBSTRING_INDEX(GROUP_CONCAT(n_id ORDER BY c_time DESC), ',', 1) FROM com GROUP BY c_imei) ORDER BY c_imei; #方法四,派生表关联查询 select distinct com.n_id, com.c_imei, com.c_time, com.c_name from com join (select c_imei, max(c_time) as ct from com group by c_imei) tmp on com.c_imei = tmp.c_imei and com.c_time = tmp.ct order by com.c_imei; ##方法四优化 select distinct com.n_id, com.c_imei, com.c_time, com.c_name from com right join (select c_imei, max(c_time) as ct from com group by c_imei) tmp on com.c_imei = tmp.c_imei and com.c_time = tmp.ct order by com.c_imei; 其他方法 MySQL8及以上的row_number、rank、dense_rank、over函数</content></entry><entry><title>参数校验</title><url>https://www.zyg-tech.me/post/%E5%8F%82%E6%95%B0%E6%A0%A1%E9%AA%8C/</url><categories><category>校验</category></categories><tags><tag>校验</tag><tag>Spring</tag><tag>HibernateValidate</tag></tags><content type="html"> 作为后台开发人员,为保证数据的有效性与完整性,避免处理前台传递的无效或不完整的信息,会进行后台的数据校验,常用的是Spring中的SpringValidation, 事实上它是对Hibernate Validator的封装,而Hibernate Validator又是对Bean Validation规范的实现,下面我们来较为全面的了解一下关于校验的那点事儿.
1.Bean Validation规范 Bean Validation规范主要用于对 Bean 中的字段的值进行约束定义、描述和验证,截止目前一共有三个版本 : Bean Validation 1.0/1.1/2.0,分别对应 JSR 303/349/380,有兴趣的同学可以到https://www.jcp.org/en/jsr/overview , 根据JSR编号查找相应的规范提案,关于Bean Validation各版本区别可前往https://beanvalidation.org查看。
2.Bean Validation实现 规范离不开相应的实现,Bean Validation的实现有两个 : Hibernate Validator与Apache BVal,Spring Validation就是基于Hibernate Validator封装的,它们都离不开javax Validation,公司也封装了framework-validation供大家使用。
这里介绍一下规范和实现之间的版本关系 :
Bean Validation 1.0 &amp;ndash;&amp;gt; Hibernate Validator 4.3.1与Apache BVal 0.5 Bean Validation 1.1 &amp;ndash;&amp;gt; Hibernate Validator 5.1.1与Apache BVal 1.1.2 Bean Validation 2.0 &amp;ndash;&amp;gt; Hibernate Validator 6.0.1 Bean Validation 主要提供了以下验证规则(javax.validation.constraints): 1)AssertFalse : 验证 Boolean 对象是否为 true 2)AssertTrue : 验证 Boolean 对象是否为 false 3)DecimalMax : 被标注的值必须不大于约束中指定的最大值(含精度) 4)DecimalMin : 被标注的值必须不小于约束中指定的最小值(含精度) 5)Digits : 验证 Number 和 String 的构成是否合法 6)Future : 验证 Date 和 Calendar 对象是否在当前时间之后 7)Max : 验证 Number 和 String 对象是否小等于指定的值 8)Min : 验证 Number 和 String 对象是否大等于指定的值 9)NotNull : 验证对象是否不为null 10)Null : 验证对象是否为null 11)Past : 验证 Date 和 Calendar 对象是否在当前时间之前 12)Pattern : 验证 Date 和 Calendar 对象是否在当前时间之后 13)Size : 验证CharSequence/Collection/Map/Array对象长度是否在给定的范围之内
Hibernate Validator在javax.validation的基础上增加了以下验证规则(org.hibernate.validator.constraints): 1)CreditCardNumber : 信用卡验证 2)EAN : 验证是否为EAN-13的商品用条码 3)Email : 邮箱地址验证 4)Length : 验证字符串长度 5)LuhnCheck : 验证是否符合模10算法的规则,例如大多数银行卡号编码规则采用了模10算法,前往https://en.wikipedia.org/wiki/Luhn_algorithm#cite_note-0 参考该算法 6)Mod10Check : 验证是否符合Mod10算法 7)Mod11Check : 验证是否符合Mod11算法 8)NotBlank : 检查约束字符串是不是Null还有被Trim的长度是否大于0,只对字符串,且会去掉前后空格 9)NotEmpty : 检查约束元素是否为NULL或者是EMPTY 10)ParameterScriptAssert : 使用脚本进行验证 11)Range : 校验数字或表示数字的字符串的取值范围 12)SafeHtml : 校验是否包含恶意脚本 13)ScriptAssert : 调用静态方法验证 14)URL : 校验是否是合法的URL
Spring Validation没有增加额外的验证规则,而是着重于通过BeanPostProcesser、Interceptor等在接收HTTP请求处理参数时进行参数校验,并封装了验证结果如BindingResult、Errors等,方便开发者使用。
3.Bean Validation实践 3.1 javax Validation原生基础用法 Maven地址
&amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;javax.validation&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;validation-api&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;1.1.0.Final&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; 实体类
public class FlowLearning { @NotNull private Long id; //other properties } 校验方法
Validator validator = Validation.buildDefaultValidatorFactory().getValidator(); Set&amp;lt;ConstraintViolation&amp;lt;Object&amp;gt;&amp;gt; resultSet = validator.validate(flowLEarning,FlowLearning.class); if (!CollectionUtils.isEmpty(resultSet)) { throw new IllegalArgumentException(resultSet.toString()); } javax.validation.Validator为验证对象提供了三个方法 1)Set&amp;lt;ConstraintViolation&amp;gt; validate(T object, Class&amp;lt;?&amp;gt;&amp;hellip; groups) &amp;ndash;&amp;gt;验证一个给定的对象 2)Set&amp;lt;ConstraintViolation&amp;gt; validateProperty(T object, String propertyName, Class&amp;lt;?&amp;gt;&amp;hellip;groups) &amp;ndash;&amp;gt;验证给定对象中的字段或者属性 3)Set&amp;lt;ConstraintViolation&amp;gt; validateValue(ClassbeanType, String propertyName, Object value, Class&amp;lt;?&amp;gt;&amp;hellip; groups) &amp;ndash;&amp;gt;验证给定对象中的属性的具体值
3.2 spring validation 注解校验 略
3.3 @ScriptAssert校验复杂的业务逻辑 实体类
@Getter @Setter // @ScriptAssert的lang指脚本语言,script中的方法名需要完全限定名 @ScriptAssert(lang = &amp;quot;javascript&amp;quot;, script = &amp;quot;com.xdja.oa.nyingchi.admin.User.mockScriptAssert(_this.position,_this.amount)&amp;quot;) public class User { private String position; private Integer amount; public static boolean mockScriptAssert(String position,Integer amount){ if(StringUtils.isEmpty(position) || amount == null || amount &amp;lt;0){ return false; }else { return true; } } } 校验方法
@RequestMapping(value = &amp;quot;script&amp;quot;, method = RequestMethod.POST) public ResponseMsg scripts(@Validated @RequestBody User user, BindingResult bindingResult){ if(bindingResult.hasErrors()){ throw new IllegalArgumentException(&amp;quot;参数不合法&amp;quot;); }else{ //校验成功,处理业务逻辑 } return ResponseMsg.success(); } @ScriptAssert中的lang属性指的是哪种脚本语言,要查看当前jdk版本所支持的脚本语言,可以通过如下代码获取
ScriptEngineManager scriptEngineManager = new ScriptEngineManager(); List&amp;lt;ScriptEngineFactory&amp;gt; engineFactories = scriptEngineManager.getEngineFactories(); if(engineFactories.size() == 0) { System.out.println(&amp;quot;本JVM尚不支持任何脚本引擎&amp;quot;); return; } System.out.println(&amp;quot;本JVM支持的脚本引擎有:&amp;quot;); for(ScriptEngineFactory engineFactory : engineFactories) { System.out.println(&amp;quot;引擎名称:&amp;quot; + engineFactory.getEngineName()); System.out.println(&amp;quot;\t可被ScriptEngineManager识别的名称:&amp;quot; + engineFactory.getNames()); System.out.println(&amp;quot;\t该引擎支持的脚本语言名称:&amp;quot; + engineFactory.getLanguageName()); System.out.println(&amp;quot;\t是否线程安全:&amp;quot; + engineFactory.getParameter(&amp;quot;THREADING&amp;quot;)); } 3.4 原生自定义Validator 自定义注解
@Target( { METHOD, FIELD, ANNOTATION_TYPE }) @Retention(RUNTIME) @Documented @Constraint(validatedBy = CheckStringValidator.class) public @interface CheckString { String message() default &amp;quot;字符串校验失败！请少侠重新来过~&amp;quot;; Class&amp;lt;?&amp;gt;[] groups() default {}; Class&amp;lt;? extends Payload&amp;gt;[] payload() default {}; CheckType checkType() ; } 注解中的枚举
public enum CheckType { EMPTY,NOT_EMPTY } 注解校验器
public class CheckStringValidator implements ConstraintValidator&amp;lt;CheckString,String&amp;gt; { private CheckType checkType; @Override public void initialize(CheckString constraintAnnotation) { this.checkType = constraintAnnotation.checkType(); } @Override public boolean isValid(String string, ConstraintValidatorContext context) { if(string == null || checkType == null){ return false; }else{ boolean result = false; switch(checkType){ case NOT_EMPTY : result = !StringUtils.isEmpty(string); break; case EMPTY: result = StringUtils.isEmpty(string); break; default: break; } return result; } } } 实体类
@Getter @Setter public class User { @CheckString(checkType = CheckType.NOT_EMPTY) private String position; } 校验
@RequestMapping(value = &amp;quot;script&amp;quot;, method = RequestMethod.POST) public ResponseMsg scripts(@Valid @RequestBody User user, BindingResult bindingResult){ if(bindingResult.hasErrors()){ throw new IllegalArgumentException(&amp;quot;参数不合法&amp;quot;); }else{ System.out.println(&amp;quot;校验成功&amp;quot;); } } 3.5 校验模式 日常开发中进行的校验大多只要某字段校验失败就视为校验失败无需继续校验了，为此，可以设置校验模式为FastFail.
HibernateValidatorConfiguration configuration = Validation.byProvider( HibernateValidator.class ).configure(); ValidatorFactory factory = configuration.addProperty( &amp;quot;hibernate.validator.fail_fast&amp;quot;, &amp;quot;true&amp;quot; ).buildValidatorFactory(); Validator validator = factory.getValidator(); 级联验证目前使用较少,不再介绍。</content></entry><entry><title>汇报搜索优化历程</title><url>https://www.zyg-tech.me/post/%E6%B1%87%E6%8A%A5%E6%90%9C%E7%B4%A2%E4%BC%98%E5%8C%96%E5%8E%86%E7%A8%8B/</url><categories><category>实战</category></categories><tags><tag>ES</tag><tag>搜索</tag></tags><content type="html"> 1.背景介绍 OA中存在工作汇报与汇报审批两个应用，前者用于员工填写汇报，如日报、周报、月报、会议纪要等，后者用于领导查阅员工填写的汇报，在查阅汇报时提供搜索功能，可根据关键字对汇报内容进行搜索。
1.1 表关系 搜索汇报相关的数据表表结构如下
t_report(汇报主表,存储员工填写的汇报记录,与t_report_value为一对多关系) 字段名 字段类型 字段说明 n_id bigint(20) 主键 n_account_id bigint(20) 人员id n_modify_time bigint(20) 修改时间 n_report_date bigint(20) 汇报日期 n_status bigint(20) 数据状态,0正常,1已删除 其他字段…. t_report_value(汇报子表,存储员工填写的汇报记录详情) 字段名 字段类型 字段说明 n_id bigint(20) 主键 n_report_id bigint(20) 汇报id，等同t_report的n_id n_moudle_id bigint(20) 模板id n_moudle_widget_id bigint(20) 模板的控件id c_widget_value varchar(12380) 汇报的内容 其他字段…. t_report_moudle(汇报模板表,存储汇报使用的模板,与t_report_widget为一对多关系) n_id bigint(20) 主键 c_name varchar(255) 模板名称 其他字段… t_report_widget(汇报控件表,存储汇报使用的模板中的控件) n_id bigint(20) 主键 n_moudle_id bigint(20) 模板id,等同t_report_moudle的n_id c_title varchar(20) 控件名,如标题、内容、本周总结、本月计划 n_value_limt int(8) 控件值长度限制,如标题最大长度、内容最大长度 其他字段…. 1.2 数据增长速度 模板表与模板控件表的数量增长较慢，数据增长主要为汇报主表与汇报子表，每天两表的数据增长速度大致如下
t_report：1 * 员工数
t_report_value : 1 * 员工数 * 模板数 * 控件数
1.3 搜索流程 搜索功能流程如下：
A接收请求
B查询当前人管辖的人员列表
C查询当前人能够查看的模板id列表
D将前两步的结果、关键词、分页参数等一起作为条件，搜索符合条件的汇报
E包装汇报的其他数据(如汇报的浏览数量、汇报的附件数量)
F返回数据
2.阶段A – MySQL like查询 在应用运行初期，由于汇报数据少，数据增长速度慢，且对搜索接口未提出其他方面的要求，因此采用like模糊查询符合条件的汇报数据，核心SQL如下
SELECT
DISTINCT t1.n_id AS id,
t1.n_create_time AS createTime,
t1.n_modify_time AS modifyTime,
t1.n_account_id AS accountId,
t1.c_coordinate AS coordinate,
t1.c_at_ids AS atIds,
t1.n_report_date AS reportDate
FROM
t_report t1
LEFT JOIN t_report_value brmwv ON t1.n_id = brmwv.n_report_id
WHERE
brmwv.c_widget_value like &amp;lsquo;%:1%&amp;rsquo;
AND brmwv.n_employee_id IN(:2)
AND brmwv.n_moudle_id IN(:3)
AND t1.n_delete_flag = 0
AND t1.n_modify_time &amp;lt; :4
ORDER BY
t1.n_report_date DESC,
t1.n_modify_time DESC LIMIT 0, :5
##:1为关键词,:2为人员列表,:3为模块列表,:4为分页参数,:5为分页条数
方案优点：无需额外改动
方案缺点：数据量多时效率低
3.阶段B - MySQL 全文索引 以公司环境为例，应用运行一年后，汇报主表的数据量大约为33w条(330天* 1000员工),汇报子表的数据量为33w条(330天 * 1000 员工 * 1个模板 * 1个控件),这时候搜索接口的查询汇报SQL平均速度为10S+，like搜索方案的主要瓶颈在于like搜索进行全表扫描，于是考虑在c_widget_value字段中建立索引来提高搜索速度，由于c_widget_value大部分为中文字符,因此需要在该字段建立全文索引并支持对中文的搜索。
经查阅资料，MySQL中的全文索引自v5.6.24开始支持InnoDB引擎，自v5.7开始增加ngram分词器以支持中日韩文，全文索引支持的数据库字段类型为char、varchar、text，于是此方案在MySQL中执行以下语句即可:
create fulltext index vfin on t_ report _value (c_widget_value) with parser ngram;
建立全文索引后SQL需要进行相应的改写，使用match against ，改写后的SQL如下
SELECT
DISTINCT t1.n_id AS id,
t1.n_create_time AS createTime,
t1.n_modify_time AS modifyTime,
t1.n_account_id AS accountId,
t1.c_coordinate AS coordinate,
t1.c_at_ids AS atIds,
t1.n_report_date AS reportDate
FROM
t _report t1
LEFT JOIN t_ report_ value brmwv ON t1.n_id = brmwv.n_report_id
WHERE
match(c_widget_value) against (':1&amp;rsquo;)
AND brmwv.n_employee_id IN(:2)
AND brmwv.n_moudle_id IN(:3)
AND t1.n_delete_flag = 0
AND t1.n_modify_time &amp;lt; :4
ORDER BY
t1.n_report_date DESC,
t1.n_modify_time DESC LIMIT 0, :5
##:1为关键词,:2为人员列表,:3为模块列表,:4为分页参数,:5为分页条数
在使用该方案时发现接口整体速度确实有了提升，但是当输入的关键词为单个字符或两个字符时无法查询到数据，于是继续查阅相关资料，得到以下信息：MySQL中的innodb_ft_min_token_size配置项表示全文索引最小分词长度,该值默认为3。于是将该配置项的值修改为1，重建了全文索引并重启MySQL，再次搜索时输入任意个字符均可搜索到相关数据。
方案时间：SQL平均时间2s，整体接口平均时间8s
方案优点：SQL查询效率提高
方案缺点：建立了索引额外占据了空间、对该表的CRUD都将降低响应速度、ngram分词粒度越细那么占据空间越大、修改MySQL的全文索引配置项后需要重建全文索引并重启MySQL才能生效、输入的关键词长度增加时SQL响应速度呈指数级增长。
4.阶段C - ElasticSearch + MySQL 全文索引方案与like方案相比，的确提升了SQL的响应速度，但是SQL响应速度受关键词影响极大，若输入的关键词长度过长，或输入的关键词几乎匹配了数据库中绝大部分数据，那么该接口的整体响应速度仍然堪忧；建立全文索引后，对t_ report_ value进行操作时响应速度将会有所降低；数据进一步增长时SQL速度将进一步变慢，在百万级以上时表现不佳；ngram分词器的分词规则不够灵活，导致分词后的索引占据空间很大。
一想到大数据量秒级响应，那么ElasticSearch会作为首选项。加上搜索接口对数据实时性要求不高，因此可以将汇报主表与汇报子表的数据存储在ElasticSearch中，对c_widget_value使用ik_smart进行分词存储，并定时更新ES数据，查询时从ES查询数据，然后再进行接口内其他业务操作。
由于ES并不擅长关联操作，于是该方案设计为OA后台执行定时任务，将汇报主表与汇报子表的数据增量整合为一张表t_report_sync_data,再通过LogStash将MySQL中表t_report_sync_data的数据增量同步到ES中。
记表t_ report为表A(汇报主表), t_report_value为表B(汇报子表), t _report_moudle(汇报模板表)为 C，以下是t_report_sync_data中各字段与这些表的对应关系
字段名 原始表 原始字段 说明 reportId report n_id 汇报id createTime report n_create_time 汇报创建时间 modifyTime report n_modify_time 汇报修改时间 accountId report n_account_id 人员id coordinate report c_coordinate 坐标 atds report c_at_ids 艾特的人员id集合 deleteFlag report n_delete_flag 删除标识 companyId report n_company_id 企业id reportDate report n_report_date 汇报日期 moduleId reportValue n_module_widget_id 模块id widgetValue reportValue c_widget_value 控件值 那么查询时的SQL就改变为了ES的查询语句，Java代码如下
// 条件构建
BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();
//widgetValue,模糊查询
BoolQueryBuilder builder = QueryBuilders.boolQuery();
builder.should(QueryBuilders.matchPhraseQuery(&amp;ldquo;widgetValue&amp;rdquo;, queryBean.getWidgetValue()));
boolQueryBuilder.must(builder);
//accountId,in
boolQueryBuilder.filter(inParamBuilder(queryBean.getAccountIds(), &amp;ldquo;accountId&amp;rdquo;));
//moudleId, in
boolQueryBuilder.filter(inParamBuilder(queryBean.getMoudleIds(), &amp;ldquo;moudleId&amp;rdquo;));
//deleteFlag,0
boolQueryBuilder.filter(QueryBuilders.termQuery(&amp;ldquo;deleteFlag&amp;rdquo;, 0));
//modifyTime,&amp;lt;
RangeQueryBuilder rangeQuery = QueryBuilders.rangeQuery(&amp;ldquo;modifyTime&amp;rdquo;);
rangeQuery.lt(queryBean.getModifyTime());
boolQueryBuilder.filter(rangeQuery);
//聚合请求构建
//按reportId分桶,按reportDate降序,按modifyTime降序,取前n桶 TermsBuilder termsBuilder = AggregationBuilders .terms(&amp;ldquo;group_by_reportId&amp;rdquo;) .field(&amp;ldquo;reportId&amp;rdquo;) .subAggregation(AggregationBuilders.max(&amp;ldquo;sortA&amp;rdquo;).field(&amp;ldquo;reportDate&amp;rdquo;)) .subAggregation(AggregationBuilders.max(&amp;ldquo;sortB&amp;rdquo;).field(&amp;ldquo;modifyTime&amp;rdquo;)) . order(Terms.Order.compound(Terms.Order.aggregation(&amp;ldquo;sortA&amp;rdquo;,false),Terms.Order.aggregation(&amp;ldquo;sortB&amp;rdquo;,false))) .size(queryBean.getPageSize());
//设置每组内取一条数据
TopHitsBuilder hitsBuilder = AggregationBuilders.topHits(&amp;ldquo;groupDataDetail&amp;rdquo;).setSize(1);
//每组内, 设置查询的字段
hitsBuilder.setFetchSource(WORK_REPORT_FIELDS, null);
termsBuilder.subAggregation(hitsBuilder);
//将分组挂靠在查询请求内,size设置es hit的原始数据,由于业务系统一般不需要,故设置不返回此项
requestBuilder.addAggregation(termsBuilder).setSize(0);
//设置Query并获取响应
SearchResponse searchResponse = requestBuilder.setQuery(boolQueryBuilder).execute().actionGet();
//处理响应,略
//inParamBuilder方法如下，用于解决同一个字段的terms的参数过多问题
private QueryBuilder inParamBuilder(List list, String field) { int count = 800; int len = list.size(); int size = len % count == 0 ? len / count : (len / count) + 1; BoolQueryBuilder shouldQuery = QueryBuilders.boolQuery(); for (int i = 0; i &amp;lt; size; i++) { int fromIndex = i * count; int toIndex = Math.min(fromIndex + count, len); List subList = list.subList(fromIndex, toIndex); TermsQueryBuilder termsQueryBuilder = QueryBuilders.termsQuery(field, subList); shouldQuery.should(termsQueryBuilder); } return shouldQuery; }
ES的DSL语句如下
{
&amp;ldquo;size&amp;rdquo; : 0,
&amp;ldquo;query&amp;rdquo; : {
&amp;ldquo;bool&amp;rdquo; : {
&amp;ldquo;must&amp;rdquo; : {&amp;ldquo;bool&amp;rdquo; : {&amp;ldquo;should&amp;rdquo; : {&amp;ldquo;match&amp;rdquo; : {&amp;ldquo;widgetValue&amp;rdquo; : {&amp;ldquo;query&amp;rdquo; : &amp;ldquo;工作汇报&amp;rdquo;,&amp;ldquo;type&amp;rdquo; : &amp;ldquo;phrase&amp;rdquo;}}}}},
&amp;ldquo;filter&amp;rdquo; : [
​ {&amp;ldquo;bool&amp;rdquo; : {&amp;ldquo;should&amp;rdquo; : {&amp;ldquo;terms&amp;rdquo; : {&amp;ldquo;moudleId&amp;rdquo; : [ 1, 2, 3, 4, 5 ]}}}},
​ {&amp;ldquo;term&amp;rdquo; : {&amp;ldquo;deleteFlag&amp;rdquo; : 0}},
​ {&amp;ldquo;range&amp;rdquo; : {&amp;ldquo;modifyTime&amp;rdquo; : {&amp;ldquo;from&amp;rdquo; : null,&amp;ldquo;to&amp;rdquo; : 1554180590383,&amp;ldquo;include_lower&amp;rdquo; : true,&amp;ldquo;include_upper&amp;rdquo; : false}} } ]}
},
&amp;ldquo;aggregations&amp;rdquo; : {
&amp;ldquo;group_by_reportId&amp;rdquo; : {
&amp;ldquo;terms&amp;rdquo; : {
​ &amp;ldquo;field&amp;rdquo; : &amp;ldquo;reportId&amp;rdquo;,&amp;ldquo;size&amp;rdquo; : 200,&amp;ldquo;order&amp;rdquo; : [ {&amp;ldquo;sortA&amp;rdquo; : &amp;ldquo;desc&amp;rdquo;}, {&amp;ldquo;sortB&amp;rdquo; : &amp;ldquo;desc&amp;rdquo;}, {&amp;quot;_term&amp;rdquo; : &amp;ldquo;asc&amp;rdquo;} ]},
&amp;ldquo;aggregations&amp;rdquo; : {
​ &amp;ldquo;sortA&amp;rdquo; : {&amp;ldquo;max&amp;rdquo; : {&amp;ldquo;field&amp;rdquo; : &amp;ldquo;reportDate&amp;rdquo;}},
​ &amp;ldquo;sortB&amp;rdquo; : {&amp;ldquo;max&amp;rdquo; : {&amp;ldquo;field&amp;rdquo; : &amp;ldquo;modifyTime&amp;rdquo;}},
​ &amp;ldquo;groupDataDetail&amp;rdquo; : {&amp;ldquo;top_hits&amp;rdquo; : {&amp;ldquo;size&amp;rdquo; : 1, &amp;ldquo;_source&amp;rdquo; : {&amp;ldquo;includes&amp;rdquo; : [ &amp;ldquo;accountId&amp;rdquo;, &amp;ldquo;atIds&amp;rdquo;, &amp;ldquo;companyId&amp;rdquo;, &amp;ldquo;coordinate&amp;rdquo;, &amp;ldquo;createTime&amp;rdquo;, &amp;ldquo;deleteFlag&amp;rdquo;, &amp;ldquo;modifyTime&amp;rdquo;, &amp;ldquo;moudleId&amp;rdquo;, &amp;ldquo;reportDate&amp;rdquo;, &amp;ldquo;widgetValue&amp;rdquo; ],
​ &amp;ldquo;excludes&amp;rdquo; : [ ]} }}}}}}
经测试，该方案中ES环节所需时间稳定在0.8s左右，接口整体速度在1-6s。
优点：速度进一步提升且响应时间比较稳定
缺点：汇报相关的其他数据仍存储在MySQL中，整体接口瓶颈变为查询汇报其他数据时的速度过慢。
5.阶段D - ElasticSearch + Redis + MySQL 对整体接口相关数据进一步分析，根据数据修改频繁程度，可以将数据进行冷热分离，将修改频率较低的数据,如汇报主表与汇报子表，存储在ES中，并通过LogStash定时增量更新；将高频修改数据(如汇报的浏览数量)存储在Redis中，这样将会进一步提升搜索的响应速度。</content></entry><entry><title>MySQL全文索引使用</title><url>https://www.zyg-tech.me/post/mysql%E5%85%A8%E6%96%87%E7%B4%A2%E5%BC%95/</url><categories><category>MySQL</category></categories><tags><tag>MySQL</tag><tag>数据库</tag><tag>全文索引</tag></tags><content type="html"> 1.简介 在Web应用中,经常会遇到按照关键字进行模糊搜索的需求,当参数搜索的数据量较少时,我们一般使用like进行搜索,但是当数据量达到一定程度后,like方式的速度就会很慢很慢,这时候我们可以借助一些全文搜索的组件来实现需求.MySQL就提供了全文索引来支持模糊搜索.
2.限制条件 2.1引擎限制 MySQL 5.6 以前的版本，只有 MyISAM 存储引擎支持全文索引；
MySQL 5.6 及以后的版本，MyISAM 和 InnoDB 存储引擎均支持全文索引
2.2版本号限制 Mysql自v5.6.24版本开始在InnoDB引擎中增加全文索引功能，支持对英文的全文搜索,默认以空格作为分隔符;自v5.7版本开始增加ngram分词器以支持中文
2.3字段类型限制 全文索引支持的字段类型为char、varchar、text等这些基于文本的列
2.4连表限制 全文搜索仅支持在同一张表中进行,不支持对多张表中的关键字进行全文搜索
3.准备索引 我们以report表为例
-- 准备表 create table report ( id int auto_increment primary key, content varchar(1000) null ); -- 在content字段创建普通的全文索引 create fulltext index content_fti on report(content); -- 在content字段创建支持中文的全文索引 create fulltext index content_fti on report(content) WITH PARSER ngram; -- 删除索引,方式一 drop index content_fti on report; -- 删除索引,方式二 alter table report drop index content_fti; 4.准备配置 ​ 使用全文索引搜索时,搜索引擎受全文搜索的单词长度影响,如果关键词长度小于该配置项,那么将无法搜索出相匹配的结果,通过命令可以查看出相关配置项
-- 查看全文搜索配置 show variables like &amp;#39;%ft%&amp;#39;; -- 命令执行结果 // MyISAM:关键词最小长度默认4字符,最大长度84字符 ft_min_word_len = 4; ft_max_word_len = 84; // InnoDB:关键词最小长度默认3字符,最大长度84字符 innodb_ft_min_token_size = 3; innodb_ft_max_token_size = 84; 我们以常用的Innodb引擎为例,在MySQL的配置文件中修改配置项
[mysqld] innodb_ft_min_token_size = 1 ft_min_word_len = 1 修改后需要重启MySQL,然后修复全文索引(可以删除索引然后重新建立索引,如果是MyIsam引擎,也可以执行repair命令修复)
然而对于使用了ngram的全文索引来讲,它的全文搜索单词长度配置会忽略上述四个配置项,真正生效的为配置项ngram_token_size(默认2),可以通过在MySQL的配置文件中修改以下配置项或启动时追加参数&amp;ndash;ngram_token_size=1来实现对该配置项的修改
[mysqld] ngram_token_size=1 同样的,修改此项后需要重建全文索引
5.准备数据 略
6.使用索引 与like不同,全文索引的搜索需要使用match agnist,示例如下
select * from report where match(content) against('测试关键词'); match agnist本身还会返回非负浮点数作为搜索的结果行与关键词的相关度.除了match agnist的基础使用,全文搜索还支持以不同的检索模式进行搜索,常用的全文检索模式有两种： 1、自然语言模式(NATURAL LANGUAGE MODE) ， 自然语言模式是MySQL 默认的全文检索模式。自然语言模式不能使用操作符，不能指定关键词必须出现或者必须不能出现等复杂查询。当sql中指定了IN NATURAL LANGUAGE MODE修饰符或未给出修饰符，则全文搜索是自然语言搜索模式 。 2、BOOLEAN模式(BOOLEAN MODE) BOOLEAN模式可以使用操作符，可以支持指定关键词必须出现或者必须不能出现或者关键词的权重高还是低等复杂查询。
6.1自然语言检索模式 ​ 在该模式下,可以指定IN NATURAL LANGUAGE MOD,也可以不指定修饰符,下面给出一个按照结果行相关度倒序排列的SQL示例
select *,match(content) against(&amp;#39;一切&amp;#39;) as score from report where match(content) against(&amp;#39;一切&amp;#39;) order by score desc; 6.2布尔检索模式 MySQL可以使用IN BOOLEAN MODE修饰符执行布尔型全文本搜索 。在这种模式下,支持通过一些正则来进行高级搜索,布尔模式下支持以下操作符：
“+”表示必须包含 “-”表示必须排除 “&amp;gt;”表示出现该单词时增加相关性 “&amp;lt;”表示出现该单词时降低相关性 “*”表示通配符 “~”允许出现该单词，但是出现时相关性为负 “&amp;quot;&amp;quot;”表示短语 下面给出一些示例 'apple banana' ## 无操作符，表示或，要么包含apple，要么包含banana '+apple +juice' ## 必须同时包含两个词apple和juice '+apple macintosh' ## 必须包含apple，但是如果也包含macintosh的话，相关性会更高。 '+apple -macintosh' ## 必须包含apple，同时不能包含macintosh。 '+apple ~macintosh' ## 必须包含apple，但是如果也包含macintosh的话，相关性要比不包含macintosh的记录低。 '+apple +(&amp;gt;juice &amp;lt;pie)' ## 查询必须包含apple和juice或者apple和pie的记录，但是apple juice的相关性要比apple pie高。 'apple*' ## 查询包含以apple开头的单词的记录，如apple、apples、applet。 '&amp;quot;some words&amp;quot;' ## 使用双引号把要搜素的词括起来，效果类似于like '%some words%'， 例如“some words of wisdom”会被匹配到，而“some noise words”就不会被匹配。 7.InnoDB引擎的相关性 InnoDB引擎的全文索引基于Sphinx,算法基于BM-25和TF-IDF,InnoDB使用“术语频率-逆文档频率” （TF-IDF）加权系统的变体对给定的全文搜索查询对文档的相关性进行排名,单词出现在文档中的频率越高，单词出现在文档集合中的频率越低，文档的排名就越高。
7.1相关性排名的计算方式 术语频率（TF）值是单词在文档中出现的次数。IDF单词的逆文档频率（）值是使用以下公式计算的，其中 total_records是集合中matching_records的记录数，并且是搜索词出现的记录数。
${IDF} = log10( ${total_records} / ${matching_records} ) 当文档多次包含一个单词时，IDF值将乘以TF值：
${TF} * ${IDF} 使用TF和IDF 值，使用以下公式计算文档的相关性等级：
${rank} = ${TF} * ${IDF} * ${IDF} 8.停止词 可以通过配置停止词来禁止某些词语参与全文索引,详细使用见全文停用词
9.InnoDB分词原理 InnoDB 全文索引具有倒排索引设计。倒排索引存储一个单词列表，对于每个单词，存储单词出现的文档列表。为了支持邻近搜索，每个单词的位置信息也作为字节偏移量存储。
创建全文索引时,MySQL将创建一组表用于辅助
## 查看索引表 SELECT table_id, name, space from INFORMATION_SCHEMA.INNODB_SYS_TABLES WHERE name LIKE 'test/%'; ## 命令执行结果 424 test/FTS_000000000000006b_0000000000000388_INDEX_1 423 425 test/FTS_000000000000006b_0000000000000388_INDEX_2 424 426 test/FTS_000000000000006b_0000000000000388_INDEX_3 425 427 test/FTS_000000000000006b_0000000000000388_INDEX_4 426 428 test/FTS_000000000000006b_0000000000000388_INDEX_5 427 429 test/FTS_000000000000006b_0000000000000388_INDEX_6 428 430 test/FTS_000000000000006b_BEING_DELETED 429 431 test/FTS_000000000000006b_BEING_DELETED_CACHE 430 432 test/FTS_000000000000006b_CONFIG 431 433 test/FTS_000000000000006b_DELETED 432 434 test/FTS_000000000000006b_DELETED_CACHE 433 107 test/report 93 前六个表代表反向索引，并称为辅助索引表。对传入文档进行标记时，各个单词（也称为 “标记”）与位置信息和关联的文档ID（DOC_ID）一起插入索引表中。根据单词第一个字符的字符集排序权重，单词在六个索引表中得到完全排序和分区。
倒排索引分为六个辅助索引表，以支持并行索引创建。默认情况下，两个线程对索引表中的单词和相关数据进行标记化，排序和插入。线程数可以使用该innodb_ft_sort_pll_degree 选项配置 。FULLTEXT在大型表上创建索引时，请考虑增加线程数 。
辅助索引表名称以前缀 FTS_和后缀 INDEX_*。每个索引表通过索引表名称中与table_id索引表的匹配的十六进制值与索引表相关联。例如，table_id所述的 test/opening_lines表是 327，为此，十六进制值是0x147。如前面的示例所示，十六进制值“ 147 ”出现在与该test/opening_lines表关联的索引表的名称中。</content></entry><entry><title>Docker MySQL部署</title><url>https://www.zyg-tech.me/post/docker-mysql%E9%83%A8%E7%BD%B2/</url><categories><category>MySQL</category></categories><tags><tag>MySQL</tag><tag>Docker</tag></tags><content type="html"> 前提 安装docker,mac环境下可直接安装docker Desktop
拉取 #拉取5.7版本的mysql镜像 docker push mysql:5.7
运行 docker run -p 13306:3306 \ --name d-mysql-57 \ -e MYSQL_ROOT_PASSWORD=Mo20100528 \ -v /Users/zyg/softs/docker/mysql57/data:/var/lib/mysql \ -v /Users/zyg/softs/docker/mysql57/logs:/var/log/mysql \ -v /Users/zyg/softs/docker/mysql57/conf/my.cnf:/etc/my.cnf \ -d mysql:5.7 参数说明:
run　run 是运行一个容器 -d　表示后台运行 -p　表示容器内部端口和服务器端口映射关联 &amp;ndash;privileged=true　设值MySQL 的root用户权限, 否则外部不能使用root用户登陆 -v 容器内的路径(如/etc/mysql)挂载到宿主机 -e MYSQL_ROOT_PASSWORD=xxx 设置MySQL数据库root用户的密码 &amp;ndash;name 设值容器名称为mysql mysql:5.7 表示从docker镜像mysql:5.7中启动一个容器 &amp;ndash;character-set-server=utf8mb4 &amp;ndash;collation-server=utf8mb4_general_ci 设值数据库默认编码 停止上面启动的容器,容器名字为&amp;quot;d-mysql-57&amp;rdquo;
docker stop d-mysql-57 配置账户 ##进入容器
docker exec -it d-mysql-57 bash ##登录MySQL
``mysql -uroot -p` ##创建用户,名叫test,密码是test123,开启远程访问权限
GRANT ALL PRIVILEGES ON *.* TO 'test'@'%' IDENTIFIED BY 'test123' WITH GRANT OPTION; ##创建数据库,名叫xxx
create database xxx; 之后便可以通过该用户执行业务脚本</content></entry></search>