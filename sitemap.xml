<search><entry><title>微服务常见面试题</title><url>https://www.zyg-tech.me/post/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/</url><categories><category>面试题</category><category>Java</category><category>微服务</category><category>分布式</category></categories><tags><tag>面试题</tag><tag>Java</tag><tag>微服务</tag><tag>分布式</tag></tags><content type="html"> .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 理论篇 什么是CAP定理 * C ：一致性，在分布式系统中数据往往存在多个副本，一致性描述的是这些副本中的数据在内容和组织上的一致 * A ：可用性，在用户能够容忍的时间范围内返回用户期望的结果 * P ：分区容错性，在出现网络分区时系统仍然能够对外提供一致性的可用服务 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 什么是BASE理论 它是对CAP理论的进一步延伸 * BA ：基本可用，分布式系统在出现不可预知故障的时候，允许损失部分可用性 * S ： 软状态，许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时 * E ：最终一致性，系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } BASE理论和CAP定理的关系 在CAP定理中，如果满足其中两项(CP/AP)，在此基础上设计的系统就是BASE架构 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 分布式一致性 分布式一致性的定义 **一致性是指**分布式系统中的多个服务节点，给定一系列的操作，在约定协议的保障下，使它们**对外界呈现的状态是一致的。**换句话说**，也就是**保证集群中所有服务节点中的**数据完全相同**并且能够**对某个提案（Proposal）达成一致** .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 分布式一致性的要求 * 有限性 ： 达成一致的结果在**有限的时间**内完成 * 约同性 ：不同节点最终完成决略的结果是相同 * 合法性 ：决策的结果必须是系统中某个节点提出来的 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 分布式一致性的分类 * **严格一致性** ：对于数据项x的任何读操作将返回最近一次对x进行的写操作的结果所对应的值，效果上等同于一台机器 * **强一致性** ： 包括**顺序一致性**和**线性一致性**，**顺序一致性**是指任何执行结果都是相同的，就好像所有进程对数据存储的读、写操作是按某种序列顺序执行的，并且每个进程的操作按照程序所指定的顺序出现在这个序列中；**线性一致性**假设操作具有一个**全局有效时钟的时间戳**，但是这个时钟仅具有有限的精确度。要求时间戳在前的进程先执行 * **弱一致性** ：指系统并不保证后续进程或线程的访问都会返回最新的更新的值，系统在数据成功吸入之后，不承诺立即可以读到最新写入的值，也不会具体承诺多久读到。但是会尽可能保证在某个时间级别（秒级）之后。可以让数据达到一致性状态 * **最终一致性** ：**最终一致性**是弱一致性的特定形式。系统保证在没有后续更新的前提下，系统最终返回上一次更新操作的值。 **也就是说**，如果经过一段时间后要求能访问到更新后的数据，则是最终一致性 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 分布式共识性 分布式共识性的定义 **共识性**描述了分布式系统中多个节点之间，彼此对某个状态达成一致结果的过程。 在实践中，要保障系统满足不同程度的一致性，核心过程往往需要通过共识算法来达成 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 分布式共识性的常见算法 * Paxos * Raft * Proof-of-Work * Proof-of-Stake * Delegated Proof-of-Stake .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 共识性和一致性的区别 **一致性描述的是结果状态**，**共识则是一种手段**。**达成某种共识并不意味着就保障了一致性（这里的一致性指强一致性）。只能说共识机制，能够实现某种程度上的一致** .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 分布式协调 Zookeeper的使用场景 * 命名服务 ： 提供全局一致性的id * 配置管理 ： 将其作为一个高可用的配置存储器，允许分布式应用的参与者检索和更新配置文件 * 分布式锁 ： 通过 ZooKeeper 的临时节点和 Watcher 机制来实现分布式锁 * 集群管理 ： * 通过创建临时节点来建立心跳检测机制 * 分布式系统的每个服务节点还可以将自己的节点状态写入临时节点从而完成节点的状态报告 * 通过数据的订阅和发布功能，ZooKeeper 还能对分布式系统进行模块的解耦和任务的调度 * 通过监听机制，还能对分布式系统的服务节点进行动态上下线，从而实现服务的动态扩容 * Leader节点选举 * 队列管理 ： 实现同步队列/生产者和消费者模型 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 概述Zookeeper的选举流程 * **自增选举轮次** * **初始化选票** * **发送初始化选票** * **接收外部投票** * **判断选举轮次** * **选票 PK** * **统计选票** * **更新服务器状态** .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 概述Zookeeper的ZAB协议的原子广播 **所有的写请求都会被转发给 Leader，Leader 会以原子广播的方式通知 Follow。当半数以上的 Follow 已经更新状态持久化后，Leader 才会提交这个更新，然后客户端才会收到一个更新成功的响应。**这有些类似数据库中的两阶段提交协议。 在整个消息的广播过程中，Leader 服务器会每个事务请求生成对应的 Proposal，并为其分配一个全局唯一的递增的事务 ID(ZXID)，之后再对其进行广播。 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 分布式事务 常见的分布式事务协议有哪些 两阶段提交、三阶段提交 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 概述两阶段提交的流程 一阶段 ：投票 二阶段 ：提交 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 两阶段提交有哪些缺点 * 同步阻塞 ： 执行过程中，所有参与节点都是事务阻塞型的。当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态 * 协调者故障 ：由于协调者的重要性，一旦协调者发生故障，参与者会一直阻塞下去 * 参与者故障导致的数据不一致 ： 在二阶段提交的阶段二中，当协调者向参与者发送commit请求之后，发生了局部网络异常或者在发送commit请求过程中协调者发生了故障，这回导致只有一部分参与者接受到了commit请求。而在这部分参与者接到commit请求之后就会执行commit操作。但是其他部分未接到commit请求的机器则无法执行事务提交。于是整个分布式系统便出现了数据不一致性的现象 * 协调者与参与者故障导致的事务状态不确定 ：协调者再发出commit消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 概述三阶段提交的流程 与两阶段提交不同的是，三阶段提交有两个改动点。 1、引入超时机制。同时在协调者和参与者中都引入超时机制。 2、在第一阶段和第二阶段中插入一个准备阶段。保证了在最后提交阶段之前各参与节点的状态是一致的。 共分为三个阶段 ：canCommit、preCommit、doCommit .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 常见的分布式事务解决方案有哪些 * 全局事务XA协议 * 需要三种角色：AP(业务系统)、TM(事务管理器)、RM(资源管理器),这只是一种规范，具体的实现包括两阶段提交、三阶段提交等，例如MySQL支持外部的XA接口以及MySQL支持内部的两阶段提交(bin log 与redo log) * 基于消息的分布式事务 * 假定存在业务系统A、业务系统B、消息中间件。系统A成功处理后通过消息中间件发出消息，系统B接收消息并处理 * 最大努力通知事务 * 在基于消息的分布式事务基础上，定时处理发送失败的消息 + 定时校对系统AB * TCC两阶段补偿事务 * 分为三个部分 ：Try(检查待执行的业务方，预留资源)、Confirm(执行业务)、Cancel(若前阶段执行失败则回滚) (模仿数据库本地事务，将其逻辑从数据库层迁移到服务层) .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; }</content></entry><entry><title>网络常见面试题</title><url>https://www.zyg-tech.me/post/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/</url><categories><category>网络</category><category>面试题</category></categories><tags><tag>网络</tag><tag>面试题</tag></tags><content type="html"> .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 网络分层 网络模型分为哪几类 1. OSI七层模型 ： 物理层、链路层、网络层、传输层、会话层、表示层、应用层 2. TCP/IP四层模型 ： 接口层、网际层、传输层、应用层 3. 五层模型 ： 物理层、链路层、网络层、传输层、应用层 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 概述OSI七层模型各层的作用及各层常见协议 自下而上依次为 : 物理层、链路层、网络层、传输层、会话层、表示层、应用层 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 分层 作用 协议 设备 关键字 应用层 负责顶层协议，例如数据封装、分配IP、DNS解析 HTTP、FTP、Telnet 浏览器、APP 表示层 转换、压缩、加密数据 ASCII、PNG、JPEG 浏览器、APP 会话层 负责两个应用进程之间的逻辑连接 SSL、TLS、、SQL、RPC 浏览器、APP 传输层 传输数据，确保数据包按顺序接收且没有被破坏 TCP、UDP 计算机 流量控制、拥塞控制 网络层 为网络上的不同主机提供通信 IPv4、IPv6、ARP、ICMP 链路层 采用差错检测、差错控制等方法，以帧为单位向网络层提供高质量的数据传输服务 点对点协议PPP、广播协议 交换机、路由器 MAC、MTU、CRC、滑动窗口 物理层 利用传输介质为相邻的计算机节点完成比特流的透明传送 IEEE802.X、Bluetooth、WI-FI协议、USB接口协议 网卡、网线 全双工通信、信道复用 三次握手和四次挥手 这里先放一张TCP状态变迁图
简述HTTP三次握手的流程 为什么需要三次握手 三次握手的目的是建立可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，而三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的。简单来说，基本思想就是**“让我知道你已经知道”**了 第一次握手：Client 什么都不能确认；Server 确认了对方发送正常，自己接收正常 第二次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：对方发送正常，自己接收正常 第三次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送、接收正常 所以三次握手就能确认双发收发功能都正常，缺一不可。 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 第二次握手为什么回传SYN SYN用于建立并确认从服务端到客户端的通信。 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 什么是半连接队列 服务器第一次收到客户端的 SYN 之后，就会处于 SYN_RCVD 状态，此时双方还没有完全建立其连接，服务器会把此种状态下请求连接放在一个**队列**里，我们把这种队列称之为**半连接队列** .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 什么是全连接队列 已经完成三次握手，建立起连接的就会放在全连接队列中。如果队列满了就有可能会出现丢包现象 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 三次握手过程中可以携带数据吗 **第一次、第二次握手不可以携带数据**，但是第三次可以。 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 什么是SYN攻击，如何防范 SYN攻击就是Client在短时间内伪造大量不存在的IP地址，并向Server不断地发送SYN包，Server则回复确认包，并等待Client确认，由于源地址不存在，因此Server需要不断重发直至超时，这些伪造的SYN包将长时间占用未连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络拥塞甚至系统瘫痪 常见的防御 SYN 攻击的方法有如下几种： - 缩短超时（SYN Timeout）时间 - 增加最大半连接数 - 过滤网关防护 - SYN cookies技术 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 简述四次挥手的流程 四次挥手时为什么客户端最后还要等待2MSL 第一，保证客户端发送的最后一个ACK报文能够到达服务器，因为这个ACK报文可能丢失，站在服务器的角度看来，我已经发送了FIN+ACK报文请求断开了，客户端还没有给我回应，应该是我发送的请求断开报文它没有收到，于是服务器又会重新发送一次，而客户端就能在这个2MSL时间段内收到这个重传的报文，接着给出回应报文，并且会重启2MSL计时器。 第二，防止类似与“三次握手”中提到了的“已经失效的连接请求报文段”出现在本连接中。客户端发送完最后一个确认报文后，在这个2MSL时间中，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样新的连接中不会出现旧连接的请求报文 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 为什么建立连接是三次握手，关闭连接确是四次挥手呢 简单来说，建立连接时服务器端的ACK/SYN一次性发送给客户端，但关闭连接时ACK/FIN一般分为两次发送给客户端(目的是使得服务端传送完毕数据)。详细来说, * 建立连接的时候， 服务器在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。 * 关闭连接时，服务器收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，而自己也未必全部数据都发送给对方了，所以己方可以立即关闭，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN一般都会分开发送，从而导致多了一次。 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 如果已经建立了连接，但是客户端突然出现故障了怎么办 与UDP相比，TCP还设有一个保活计时器，服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。相对应的配置项为net.ipv4.tcp_keepalive_time、net.ipv4.tcp_keepalive_intvl、net.ipv4.tcp_keepalive_probes。 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } TCP/UDP TCP和UDP的区别 TCP如何保证可靠传输 * 分块 ：应用数据被分割成 TCP 认为最适合发送的数据块。 * 编号 ：TCP 给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。 * 校验和 ： TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。 * 去重 ：TCP 的接收端会丢弃重复的数据。 * 流量控制 ： TCP 连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制） * 拥塞控制 ：当网络拥塞时，减少数据的发送。 * ARQ协议 ：也是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。 * 超时重传 ：当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } HTTP/HTTPS HTTP1.0与HTTP1.1有什么区别 * 长连接 ： 1.0默认短连接，1.1默认长连接，并且1.1支持流水线，可以多个HTTP连接共用同一个TCP连接 * 缓存机制 ：1.0使用header中的If-Modified-Since,Expires控制缓存，1.1更加丰富，如Entity tag，If-Unmodified-Since, If-Match, If-None-Match * 带宽优化 ：1.1支持通过header中指定range来获取资源的某个部分 * 错误码 ：1.1相比1.0增加了24个错误码 * Host处理 ：1.0并没有host，而1.1强制必须存在host .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } HTTP1.1和HTTP2.0有什么区别 * 本质区别 ：1.1基于文本分割, 2.0基于二进制 * 多路复用 ：2.0支持在同一个TCP中存在多个流，也就是可以发送多个请求，对端可以通过帧中的标识知道属于哪个请求 * header压缩 ：1.1每次都需要发送header，2.0将header压缩，同时通信的两端各自维护了header键名索引 * 服务端推送 ：2.0可以在服务端主动推送数据到客户端 * 流量控制 ：2.0中的通信双方可以在请求时声明需要的数据字节大小 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } QUIC相对HTTP2有什么区别 * 传输层协议 ：QUIC基于UDP，HTTP2基于TCP * 连接建立时间 ：QUIC可以实现0-RTT建立连接，而TCP与SSL/TLS(1.0,1.1,1.2)每次建连需要TCP三次握手+安全握手，需要4~5个RRT * 拥塞控制 ：多个数据在TCP连接上传输时，若一个数据包出现问题，TCP需要等待该包重传后，才能继续传输其它数据包。但在QUIC中，因为其基于UDP协议，UDP数据包在出问题需要重传时，并不会对其他数据包传输产生影响 * 重传机制 ：QUIC协议的每个数据包除了本身的数据以外，会带有其他数据包的部分数据，在少量丢包的情况下，可以使用其他数据包的冗余数据完成数据组装而无需重传 * 重启会话 ：TCP是基于两端的ip和端口和协议来建立连接，而QUIC基于特有的Connection ID 来建立连接 * 头部加密 ：TCP 协议头部未经过加密和认证，但 QUIC 所有的头部信息均经过认证，并且对所有信息进行加密，可有效避免数据传输过程中被中间设备截取并篡改 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } HTTP和HTTPS的区别 * 端口 ：http默认80端口，https默认443端口 * 安全性 ：http明文传输，https加密传输，安全性高 * 连接建立时间与响应时间 ：http无需加密，只需要三次握手，建立连接时间短，https需要先三次握手再ssl握手，建立连接时间长 * 消耗资源 ：https需要额外加解密，相比http更加消耗资源 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } SSL和TLS什么关系 TLS是SSL标准化的产物。早期SSL分为1.0、2.0、3.0版本，SSL3.0 = TLS1.0，TLS后续又产生了1.1、1.2版本等 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 概述ssl握手流程 1.客户端通知加密算法,双方根据加密算法来交换加密所需的证书、随机数、配置参数等信息 2.根据上一步的加密算法及相关参数计算出预主密钥 3.根据预主密钥生成主密钥 4.双方互相发送握手完成信息，后续根据主密钥来加密通信数据 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 给出基于RSA的SSL握手流程和基于DH的SSL握手流程 RSA的SSL握手流程
DH的SSL握手流程
概述给予RSA和DH算法的SSL握手流程的区别 区别就在于密钥交换与身份认证 * RSA非对称算法，利用客户端利用公钥加密预主密钥发送给服务端完成密钥交换，服务端利用私钥解密完成身份认证 * DH对称算法，利用各自发送DH参数完成密钥交换，服务器私钥签名数据，客户端公钥验签完成身份认证 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } SSL握手阶段连接意外中断后的恢复方法有哪些，并比较它们的优缺点 * session id * 流程 ：当 Client 通过一次完整的握手，与 Server 建立了一次完整的 Session，Server 会记录这次 Session 的信息，以备恢复会话的时候使用，其中就包含session id * 优点 ：将握手耗时从2-RTT减少为1-RTT；减少双方的负载，不需要再次消耗CPU计算 * 缺点 ：session id仅存在于单机中 * session ticket * 流程 ：服务器取出它的所有会话数据（状态）并进行加密 (密钥只有服务器知道)，再以票证的方式发回客户端；客户端恢复会话时在 ClientHello 的扩展字段 session_ticket 中携带加密信息将票证提交回服务器，由服务器检查票证的完整性，解密其内容，再使用其中的信息恢复会话 * 优点 ：可用于多台机器 * 缺点 ：存储ticket需要消耗内存 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } TLS1.3 相比TLS1.2有什么区别 * 密钥协商机制 ：引入新的密钥协商机制PSK * 连接建立时间 ：支持 0-RTT 数据传输，在建立连接时节省了往返时间 * 加密算法 ：废弃了 3DES、RC4、AES-CBC 等加密组件，废弃了 SHA1、MD5 等哈希算法 * 安全性 ：ServerHello 之后的所有握手消息采取了加密操作，可见明文大大减少 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 概述QUIC的握手流程</content></entry><entry><title>MyBatis常见面试题</title><url>https://www.zyg-tech.me/post/mybatis%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/</url><categories><category>面试题</category><category>框架</category><category>MyBatis</category></categories><tags><tag>面试题</tag><tag>框架</tag><tag>MyBatis</tag></tags><content type="html"> 基础篇 # 和$的区别 - `${}`是 Properties 文件中的变量占位符，它可以用于标签属性值和 sql 内部，属于静态文本替换，比如${driver}会被静态替换为`com.mysql.jdbc.Driver`。 - `#{}`是 sql 的参数占位符，MyBatis 会将 sql 中的`#{}`替换为?号，在 sql 执行前会使用 PreparedStatement 的参数设置方法，按序给 sql 的?号占位符设置参数值，比如 ps.setInt(0, parameterValue)，`#{item.name}` 的取值方式为使用反射从参数对象中获取 item 对象的 name 属性值，相当于 `param.getItem().getName()`。 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } Xml映射文件中，除了常见的select|insert|updae|delete标签之外，还有哪些标签 、、、、 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } MyBatis的动态SQL是什么 Mybatis动态sql可以让我们在Xml映射文件内，以标签的形式编写动态sql，完成逻辑判断和动态拼接sql的功能，Mybatis提供了9种动态sql标签trim|where|set|foreach|if|choose|when|otherwise|bind。 其执行原理为，使用OGNL从sql参数对象中计算表达式的值，根据表达式的值动态拼接sql，以此来完成动态sql的功能 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } Mybatis是如何将sql执行结果封装为目标对象并返回的？都有哪些映射形式 第一种是使用标签，逐一定义列名和对象属性名之间的映射关系。第二种是使用sql列的别名功能，这种方式原理是反射。 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 为什么说Mybatis是半自动ORM映射工具？它与全自动的区别在哪里 Hibernate属于全自动ORM映射工具，使用Hibernate查询关联对象或者关联集合对象时，可以根据对象关系模型直接获取，所以它是全自动的。而Mybatis在查询关联对象或关联集合对象时，需要手动编写sql来完成，所以，称之为半自动ORM映射工具 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } TypeHandler的作用有哪些 * 完成javaType至jdbcType的转换 * 完成javaType至jdbcType的转换 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 核心原理篇 MyBatis有哪些主要组件 * Transaction ：事务接口，所有操作最终由该接口 * TransactionFactory ： 负责Transaction的创建、销毁 * SqlSessionFactory：负责SqlSession的创建、销毁 * SqlSession ： 负责提供给用户可以操作的api，如insert(),insertBatch()等，它的生命周期限定在线程之内 * Executor ： 负责执行对数据库的操作 * StatementHandler ：Executor将工作委托给StatementHandler执行（实际干活的老实人） .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } Mybatis的执行流程 简述SQL在Myabtis中的执行流程 简述各Executor子类的作用 * SimpleExecutor ：简单Executor，每执行一次update或select，就开启一个Statement对象，用完立刻关闭Statement对象 * ReuseExecutor ： 重用Executor，执行update或select，以sql作为key查找Statement对象，存在就使用，不存在就创建，用完后，不关闭Statement对象，而是放置于Map内，供下一次使用。在执行commit、rollback等动作前，将会执行flushStatements()方法，将Statement对象逐一关闭 * BatchExecutor ：批量Executor，将所有sql都添加到批处理中（addBatch()），缓存了多个Statement对象，sql添加完成后统一执行（executeBatch()） * CachingExecutor ： 缓存Executor，装饰模式的应用，先从缓存中获取查询结果，存在就返回，不存在，再委托给Executor delegate去数据库取，delegate可以是上面任一的SimpleExecutor、ReuseExecutor、BatchExecutor .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 简述各StatementHandler子类的作用 * SimpleStatementHandler：用于处理**Statement**对象的数据库操作 * PreparedStatementHandler：用于处理**PreparedStatement**对象的数据库操作。 * CallableStatementHandler：用于处理存储过程 * RoutingStatementHandler ： 根据statementType来创建其他三个StatementHandler对象 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 简述KeyGenerator各子类的作用 * NoKeyGenerator : 空实现，不需要处理主键 * Jdbc3KeyGenerator : 用于处理数据库支持自增主键的情况，如MySQL的auto_increment * SelectKeyGenerator : 用于处理数据库不支持自增主键的情况，比如Oracle的sequence序列 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 简述设计模式在MyBatis中的运用 * 工厂模式 ： TransactionFactory负责Transaction的生产、销毁；SqlSessionFactory负责SqlSession的生产、销毁 * 装饰器模式 ： CachingExecutor在SimpleExecutor/ReuseExecutor/BatchExecutor的基础上提供了缓存功能 * 模版模式 ： Executor通过调用StatementHandler的模版方法来完成对数据库的操作 * 适配器模式 ： BaseStatementHandler抽象类分别有三个实现类：SimpleStatementHandler、PreparedStatementHandler、CallableStatementHandler * 策略模式 ： RoutingStatementHandler根据statementType的不同来创建不同的StatementHandler * 责任链模式 ： MyBatis中存在一些插件，它们都会以责任链的方式逐一执行 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 简述一级缓存和二级缓存的原理 * 一级缓存 ： 在CachingExecutor中针对query操作的结果，将其放置在HashMap中，有效范围为同一个SqlSession(默认)/Statement * 二级缓存 ： 在CachingExecutor中实现，有效范围为全局Configuration，在所有SqlSession中均有效 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 一级缓存在哪些情况下失效 * sqlsession变了 缓存失效 * sqlsession不变,查询条件不同，一级缓存失效 * sqlsession不变,中间发生了增删改操作，一级缓存失败 * sqlsession不变,手动清除缓存，一级缓存失败 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 缓存清空策略有哪些 * LRU ：最近最少使用算法，即如果缓存中容量已经满了，会将缓存中最近做少被使用的缓存记录清除掉，然后添加新的记录 * FIFO ：先进先出算法，如果缓存中的容量已经满了，那么会将最先进入缓存中的数据清除掉 * Scheduled ：指定时间间隔清空算法，该算法会以指定的某一个时间间隔将Cache缓存中的数据清空 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } Mybatis是否支持延迟加载？如果支持，它的实现原理是什么 Mybatis仅支持association关联对象和collection关联集合对象的延迟加载，association指的就是一对一，collection指的就是一对多查询。在Mybatis配置文件中，可以配置是否启用延迟加载lazyLoadingEnabled=true|false。 它的原理是，使用CGLIB创建目标对象的代理对象，当调用目标方法时，进入拦截器方法，比如调用a.getB().getName()，拦截器invoke()方法发现a.getB()是null值，那么就会单独发送事先保存好的查询关联B对象的sql，把B查询上来，然后调用a.setB(b)，于是a的对象b属性就有值了，接着完成a.getB().getName()方法的调用。这就是延迟加载的基本原理 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 实战篇 通常一个Xml映射文件都有一个Dao接口与之对应，请问，这个Dao接口的工作原理是什么？Dao接口里的方法，参数不同时，方法能重载吗 * Mapper接口是没有实现类的，当调用接口方法时，接口全限名+方法名拼接字符串作为key值，可唯一定位一个MappedStatement，举例：com.mybatis3.mappers.StudentDao.findStudentById，可以唯一找到namespace为com.mybatis3.mappers.StudentDao下面id = findStudentById的MappedStatement * Dao接口的工作原理是JDK动态代理，Mybatis运行时会使用JDK动态代理为Dao接口生成代理proxy对象，代理对象proxy会拦截接口方法，转而执行MappedStatement所代表的sql，然后将sql执行结果返回 * 因此，Dao接口里的方法，是不能重载的，因为是全限名+方法名的保存和寻找策略 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } Mybatis的Xml映射文件中，不同的Xml映射文件，id是否可以重复 不同的Xml映射文件，如果配置了namespace，那么id可以重复；如果没有配置namespace，那么id不能重复；毕竟namespace不是必须的 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } Mybatis是如何进行分页的？分页插件的原理是什么 Mybatis使用RowBounds对象进行分页，它是针对ResultSet结果集执行的内存分页，而非物理分页，可以在sql内直接书写带有物理分页的参数来完成物理分页功能，也可以使用分页插件来完成物理分页。 分页插件的基本原理是使用Mybatis提供的插件接口，实现自定义插件，在插件的拦截方法内拦截待执行的sql，然后重写sql，根据dialect方言，添加对应的物理分页语句和物理分页参数。 举例：select * from student，拦截sql后重写为：select t.* from （select * from student）t limit 0，10 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } MyBatis单条数据插入如何返回主键 * MySQL ： 在中将useGeneratedKeys属性设置为true，并制定keyProperty为实体对象的id * Oracle ： ```xml SELECT SEQ_TEST.NEXTVAL FROM DUAL insert into category (name_zh, parent_id, show_order, delete_status, description ) values xxxx ``` .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } MyBatis批量插入如何返回主键列表 Xml ```xml INSERT INTO (relation_id, summary_id, relation_type) VALUES ( #{shopResource.relationId}, #{shopResource.summaryId}, #{shopResource.relationType} ) ``` Dao ```java public List batchinsertCallId(List shopResourceList) { this.getSqlSession().insert(getStatement(SQL_BATCH_INSERT_CALL_ID), shopResourceList); return shopResourceList;// 重点介绍 } ``` MyBatis需要在3.3.1以上，如果在Dao中使用@Param注解，需要MyBatis3.5以上 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 插件篇 插件存储于哪里 初始化时，会读取插件，保存于Configuration对象的InterceptorChain中 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 如何编写插件 * 实现org.apache.ibatis.plugin.Interceptor接口 * 配置@Intercepts注解 ：在该注解中配置对哪些Mapper的哪些方法进行拦截 * 重写setProperties()方法：给自定义的拦截器传递xml配置的属性参数 * 重写plugin()方法：决定是否触发intercept()方法 * 重写intercept()方法：执行拦截内容的地方 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 插件可以拦截哪些MyBatis核心对象 Executor、StatementHandler、ParameterHandler、ResultSetHandler .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } RowBounds分页插件的原理 org.apache.ibatis.executor.resultset.DefaultResultSetHandler.handleRowValuesForSimpleResultMap()方法 ： 对取到的结果集在内存中分页 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } PageHelper分页插件的原理 com.github.pagehelper.PageInterceptor ： 1.将分页参数等绑定在ThreadLocal中 2.查询总数 3.改写分页sql，添加limit或者rownum等 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 占 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; }</content></entry><entry><title>Java常见面试题</title><url>https://www.zyg-tech.me/post/java%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/</url><categories><category>面试题</category><category>Java</category></categories><tags><tag>面试题</tag><tag>Java</tag><tag>Java基础</tag></tags><content type="html"> 基础篇 Object都有哪些方法，各自作用是什么 对象相等的相关方法：equals()、hashcode(); 对象的基本方法 ： toString()、getClass()、clone()、finalize() 锁相关方法 : wait()、nofity()、notifyAll() .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } Java有哪些修饰符/作用域 private、default、protected、public .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 数据结构篇 HashCode为什么采用31作为乘数 1. 31 是一个奇质数，如果选择偶数会导致乘积运算时数据溢出 2. 使用 31、33、37、39 和 41 作为乘积，得到的碰撞几率较小 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } HashMap底层实现 1.7及以前是数组+链表，1.8以后是数组+链表+红黑树 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 为什么HashMap初始化时采用数组+链表而不是红黑树 * 时空平衡 ：数组+链表时间复杂度小,为O(1),插入方便，并且单个节点内存小；红黑树时间复杂度高,为O(n)，插入复杂，它需要通过旋转来平衡，并且单个节点内存大 * 数据分布 : 当hashCode算法足够好时，数据会尽量均匀分布，几乎不会出现单个链表元素数量超过8的情况；当hashCode算法不好时，本身hashmap做了一次hash扰动了，并且足够理想的情况下，随机数据分散程度遵循泊松分布，几率为0.0000006，也几乎不会出现单个链表元素数量超过8的情况 ## HashMap在1.8中为什么相比1.7增加了红黑树 防止恶意的hashcode导致数据分布不均匀，在某些链表中元素过多导致查询效率变低 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## HashMap在什么情况下会出现数组+链表 红黑树 的相互转换，为什么 * 链表长度为8时转换为红黑树 * 红黑树元素数量为6时转换为数组+链表 * 原因 ： 理想情况下随机hashCode算法下所有bin中节点的分布频率会遵循泊松分布，为6的概率为十万分之一，为7的概率为十万分之一的百分之七，为8的概率为十万分之一的万分之四。 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 链表和红黑树是否可能共存在同一个HashMap 是的，数组+链表/数组+红黑树，各个数组间互相不影响 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## HashMap的默认初始大小为什么是16，扩容阈值为什么是0.75 * 初始化大小为16 ： 分配过小容易扩容，分配过大浪费资源 * 扩容阈值为0.75 ： 经验所得 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## HashMap的put如何实现 1.对key的hashCode()做hash，然后再计算index; 2.校验桶数组是否被初始化 ： 如果未被初始化则进行初始化 3.校验某个桶中是否为空 : 如果为空，将本次待插入的数据放入该桶;如果桶非空 3.1 如果目前是红黑树,调用红黑树的插入方法，并将插入后的数据赋值给临时变量e 3.2 如果不是红黑树，并且当前桶的首个数据等于本次待插入的数据，将本次待插入的数据赋值给临时变量e 3.3 其他情况下遍历整个链表,查找待插入数据是否已存在于该Map，如果存在则赋值给临时变量e，如果不存在也将待插入的数据赋值给临时变量e 3.4 上边三步进行完之后，如果临时变量e非空，将Map中指定位置的值替换为本次待插入的数据，同时执行afterNodeAccess扩展方法 4.键值对数量超过阈值时，则进行扩容 5.执行afterNodeInsertion扩展方法 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## HashMap的插入方式在1.7和1.8有什么区别 1.7头插法并且会使得链表反转，1.8尾插法 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## HashMap扩容策略在1.7和1.8有什么区别 * 数据插入与扩容顺序 ： 1.7先扩容再插入数据，1.8先插入数据再扩容 * 插入方法 ： 1.7头插法，1.8尾插法 * 数据移动 ： 1.7重新计算rehash，1.8要么数据保留在原位要么固定向后移动n位(n指扩容前的hashmap大小) .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## HashMap是否是线程安全的，扩容时的锁在什么情况下会出现 * 不安全，导致不安全的情况包括以下几种 * 多线程put导致扩容时会形成环形结构从而导致死循环 * modCount的修改不是原子性的 * 扩容时由于插入数据导致判断的值不一定准确 * 锁 占位 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 如何实现线程安全的HashMap * 操作时采用 Synchronized * 改用ConcurrentHashMap .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } # IO篇 ## UNIX 系统有哪些常见的IO模型 UNIX 系统下， IO 模型一共有 5 种： **同步阻塞 I/O**、**同步非阻塞 I/O**、**I/O 多路复用**、**信号驱动 I/O** 和**异步 I/O** .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## Java中有哪些IO模型 IO流程实际上包括两个阶段： `发起调用`与`实际IO`，发起调用指的是用户态发起系统调用，内核态进行数据的准备(网络 I/O 的情况就是等待远端数据陆续抵达；磁盘I/O的情况就是等待磁盘数据从磁盘上读取到内核态内存中)，实际IO指的是内核态将数据拷贝到用户态。 阻塞/非阻塞指的是发起调用阶段，线程/调用者是否需要等待该阶段的完成，如果需要等待(阻塞)，那么在该阶段完成前一直等待，如果不需要等待(非阻塞)，在该阶段完成前调用者可以继续做其他事情； 同步/非同步指的是实际IO阶段，线程/调用者是否需要自己参与（即线程是否需要询问IO操作完成），如果需要参与(同步)，那么线程需要不断轮询实际IO是否完成，如果不需要参与(非同步)，那么就是内核态完成实际IO后主动通知/回调线程 BIO ： 同步阻塞 NIO ： 同步非阻塞 AIO/NIO2 ： 异步非阻塞 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } # 线程篇 ## 线程 - 线程和进程的区别 进程是资源分配的最小单位，线程是CPU调度的最小单位 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 线程 - 进程和线程中各自存储什么内容 | 进程 | 线程 | | ------------------ | ---------- | | 地址空间 | 程序计数器 | | 全局变量 | 寄存器 | | 打开文件 | 堆栈 | | 子进程 | 状态 | | 即将发生的报警 | | | 信号与信号处理程序 | | | 账户信号 | | | 同步、互斥信号量 | | .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 线程 - 线程有哪几种状态 ![java-线程状态图](https://gitee.com/1162492411/pic/raw/master/java-线程状态图.jpeg) ## 线程 - 线程的实现方式有哪些，这些方式之间有什么区别 * 继承Thread类、实现Runnable接口、实现Callback接口 * 实现Runnable/Callable接口相比继承Thread类的优势 * 适合多个线程进行资源共享 * 可以避免java中单继承的限制 * 增加程序的健壮性，代码和数据独立 * 线程池只能放入Runable或Callable接口实现类，不能直接放入继承Thread的类 * Callable和Runnable的区别 * call()方法执行后可以有返回值，run()方法没有返回值 * Callable重写的是call()方法，Runnable重写的方法是run()方法 * call()方法可以抛出异常，run()方法不可以 * 运行Callable任务可以拿到一个Future对象，表示异步计算的结果 。通过Future对象可以了解任务执行情况，可取消任务的执行，还可获取执行结果 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 线程 - Thread类包含start()和run()方法，它们的区别是什么 start() : 它的作用是启动一个新线程，新线程会执行相应的run()方法。start()不能被重复调用。 run() : run()就和普通的成员方法一样，可以被重复调用。单独调用run()的话，会在当前线程中执行run()，而并不会启动新线程 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 线程 - 为什么notify(), wait()等函数定义在Object中，而不是Thread中 notify(), wait()依赖于“同步锁”，而“同步锁”是对象锁持有，并且每个对象有且仅有一个 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 线程 - sleep() 与 wait()的比较 wait()的作用是让当前线程由“运行状态”进入“等待(阻塞)状态”的同时，也会释放同步锁。 而sleep()的作用是也是让当前线程由“运行状态”进入到“休眠(阻塞)状态”。 但是，wait()会释放对象的同步锁，而sleep()则不会释放锁 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 线程 - join()方法的作用和原理 作用是让“主线程”等待“子线程”结束之后才能继续运行，原理就是对应的native方法中先是主线程调用了wait然后在子线程threadA执行完毕之后，JVM会调用lock.notify_all(thread)来唤醒就是主线程 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 线程 - nofity和nofityAll的区别 notify()方法只随机唤醒一个 wait 线程，而notifyAll()方法唤醒所有 wait 线程 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 线程 - 如何实现线程安全，各个实现方法有什么区别 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 怎么唤醒一个阻塞的线程 * wait()、notify() ：在synchronized中调用wait来释放当前线程的锁，然后调用notify来随机唤醒其他线程 * await()、signal() ： 使用Condition对象提供的await()来释放当前线程的锁，然后调用signal()来随机唤醒其他线程 * park()、unpark() : 使用LockSupport提供的park获取许可证(如果许可证的状态是未被获取，那么将获取许可证；否则将会阻塞，该方法不支持重入，多次调用会导致阻塞，许可证默认状态是已被获取)，unpark释放许可证(该方法可多次调用，不会影响许可证的获取) .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 线程池 - JDK自带的有哪几种线程池 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 线程池 - 线程池的参数有哪些，各自作用是什么 ## 线程池 - 如何设计一个线程池 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 线程池的execute和submit的区别与联系 * 任务类型 ：execute只能提交Runnable类型的任务，而submit既能提交Runnable类型任务也能提交Callable类型任务 * 异常 ： execute直接抛出异常，submit会吃掉异常，可用future的get捕获 * 顶层接口 ：execute所属顶层接口是Executor,submit所属顶层接口是ExecutorService .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 理论 - Java的线程模型 线程又分为用户线程和内核线程。 * 用户线程：语言层面创建的线程，比如 java语言中多线程技术，通过语言提供的线程库来创建、销毁线程。 * 内核线程：内核线程又称为守护线程 Daemon线程，用户线程的运行必须依赖内核线程，通过内核线程调度器来分配到相应的处理器上。 Java的线程模型采用的是一对一，即一个内核线程对应一个用户线程。 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } # 并发篇 ## 理论 - 并发与并行的区别 * 并发 ： 同**一个时间段内**多个任务都在执行 * 并行 ： 在**单位时间内**多个任务都在执行 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 理论 - 主内存和工作内存各自存储什么 * 主内存 —— 即*main memory*。在java中，实例域、静态域和数组元素是线程之间共享的数据，它们存储在**主内存**中。 * 本地内存 —— 即*local memory*。 局部变量，方法定义参数 和 异常处理器参数是不会在线程之间共享的，它们存储在线程的**本地内存**中。 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 理论 - 并发编程三要素 * 原子性 ：不可分割，一个或多个操作要么全部执行成功要么全部执行失败。它们不会被线程打断 * 有序性 ：程序执行的顺序按照代码的先后顺序执行 * 可见性 ：一个线程对共享变量的修改,另一个线程能够立刻看到 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 理论 - 为什么会产生原子性问题 对于 64 位的数据，如 long 和 double，允许虚拟机实现选择可以不保证 64 位数据类型的 load、store、read 和 write 这四个操作的原子性，即如果有多个线程共享一个并未声明为 volatile 的 long 或 double 类型的变量，并且同时对它们进行读取和修改操作，那么某些线程可能会读取到一个既非原值，也不是其他线程修改值的代表了“半个变量”的数值 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 理论 - 为什么会产生有序性问题 “编译器和处理器”为了提高性能，在程序执行时会对程序进行重排序，这打破了有序性 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 理论 - 为什么会产生可见性问题 * 线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存中的变量。 * 线程之间无法直接访问对方的工作内存中的变量，线程间变量的传递均需要通过主内存来完成。 * 简言之，只要直接采用了多线程的并发模型，并采用共享内存的方式作为数据的通讯方式，就一定有可见性问题 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 理论 - 什么是上下文切换 * 含义 ：CPU从一个进程或线程切换到另一个进程或线程 * 内容 ：上下文是指某一时间点 CPU 寄存器和程序计数器的内容 * 切换种类 ： * 线程切换 : 同一进程中的两个线程之间的切换 * 进程切换 : 两个进程之间的切换 * 模式切换 : 在给定线程中，用户模式和内核模式的切换 * 地址空间切换 : 将虚拟内存切换到物理内存 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 理论 - 概述进程切换的步骤 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 理论 - 概述线程切换的步骤 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 理论 - 线程切换的原因有哪些 引起线程上下文切换的原因，主要存在三种情况如下： 1. **中断处理**：在中断处理中，其他程序”打断”了当前正在运行的程序。当CPU接收到中断请求时，会在正在运行的程序和发起中断请求的程序之间进行一次上下文切换。**中断分为硬件中断和软件中断**，软件中断包括因为IO阻塞、未抢到资源或者用户代码等原因，线程被挂起。 2. **多任务处理**：在多任务处理中，CPU会在不同程序之间来回切换，每个程序都有相应的处理时间片，CPU在两个时间片的间隔中进行上下文切换。 3. **用户态切换**：对于一些操作系统，当进行用户态切换时也会进行一次上下文切换，虽然这不是必须的。 对于我们经常 **使用的抢占式操作系统** 而言，引起线程上下文切换的原因大概有以下几种： 1. 当前执行任务的时间片用完之后，系统CPU正常调度下一个任务； 2. 当前执行任务碰到IO阻塞，调度器将此任务挂起，继续下一任务； 3. 多个任务抢占锁资源，当前任务没有抢到锁资源，被调度器挂起，继续下一任务； 4. 用户代码挂起当前任务，让出CPU时间； 5. 硬件中断； .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 理论 - 上下文切换有哪些损耗 1. **直接消耗**：指的是CPU寄存器需要保存和加载, 系统调度器的代码需要执行, TLB实例需要重新加载, CPU 的pipeline需要刷掉； 2. **间接消耗**：指的是多核的cache之间得共享数据, 间接消耗对于程序的影响要看线程工作区操作数据的大小 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 如何减少线程的上下文切换 * 无锁并发**：多线程竞争时，会引起上下文切换，所以多线程处理数据时，可以用一些办法来避免使用锁，如将数据的ID按照Hash取模分段，不同的线程处理不同段的数据； * CAS算法**：Java的Atomic包使用CAS算法来更新数据，而不需要加锁； * 最少线程**：避免创建不需要的线程，比如任务很少，但是创建了很多线程来处理，这样会造成大量线程都处于等待状态； * 使用协程**：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换(Java没有协程，线程模型限制所致) .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 理论 - 什么是happens-before原则 在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这2个操作之间必须要存在happens-before关系。 - 定义: 如果一个操作在另一个操作之前发生(happens-before),那么第一个操作的执行结果将对第二个操作可见, 而且第一个操作的执行顺序排在第二个操作之前。 - 两个操作之间存在happens-before关系，并不意味着一定要按照happens-before原则制定的顺序来执行。如果重排序之后的执行结果与按照happens-before关系来执行的结果一致，那么这种重排序并不非法。 - happens-before规则： 1. 程序次序规则：在一个线程内一段代码的执行结果是有序的。就是还会指令重排，但是随便它怎么排，结果是按照我们代码的顺序生成的不会变！ 2. 锁定规则：一个unLock操作先行发生于后面对同一个锁的lock操作；论是单线程还是多线程，必须要先释放锁，然后其他线程才能进行lock操作 3. volatile变量规则：就是如果一个线程先去写一个volatile变量，然后一个线程去读这个变量，那么这个写操作的结果一定对读的这个线程可见。 4. 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C 5. 线程启动规则：在主线程A执行过程中，启动子线程B，那么线程A在启动子线程B之前对共享变量的修改结果对线程B可见 6. 线程终止规则：在主线程A执行过程中，子线程B终止，那么线程B在终止之前对共享变量的修改结果在线程A中可见。 7. 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程代码检测到中断事件的发生，可以通过Thread.interrupted()检测到是否发生中断 8. 对象终结规则：这个也简单的，就是一个对象的初始化的完成，也就是构造函数执行的结束一定 happens-before它的finalize()方法。 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 理论 - 什么是as-if-serial语义 不管怎么重排序(编译器和处理器为了提高并行度做的优化),(单线程)程序的执行结果不会改变 - 有序性规则表现在以下两种场景: 线程内和线程间 1. 线程内: 指令会按照一种“串行”(as-if-serial)的方式执行，此种方式已经应用于顺序编程语言。 2. 线程间: 一个线程“观察”到其他线程并发地执行非同步的代码时，任何代码都有可能交叉执行。唯一起作用的约束是：对于同步方法，同步块以及volatile字段的操作仍维持相对有序。 - As-if-serial只是保障单线程不会出问题，所以有序性保障，可以理解为把As-if-serial扩展到多线程，那么在多线程中也不会出现问题 - 从底层的角度来看，是借助于处理器提供的相关指令内存屏障来实现的 - 对于Java语言本身来说，Java已经帮我们与底层打交道，我们不会直接接触内存屏障指令，java提供的关键字synchronized和volatile，可以达到这个效果，保障有序性（借助于显式锁Lock也是一样的，Lock逻辑与synchronized一致） .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 理论 - JMM有哪八个原子操作指令 * **read** 读取：作用于主内存，将共享变量从主内存传动到线程的工作内存中，供后面的 load 动作使用。 * **load** 载入：作用于工作内存，把 read 读取的值放到工作内存中的副本变量中。 * **store** 存储：作用于工作内存，把工作内存中的变量传送到主内存中，为随后的 write 操作使用。 * **write** 写入：作用于主内存，把 store 传送值写到主内存的变量中。 * **use** 使用：作用于工作内存，把工作内存的值传递给执行引擎，当虚拟机遇到一个需要使用这个变量的指令，就会执行这个动作。 * **assign** 赋值：作用于工作内存，把执行引擎获取到的值赋值给工作内存中的变量，当虚拟机栈遇到给变量赋值的指令，执行该操作。比如 `int i = 1;` * **lock（锁定）** 作用于主内存，把变量标记为线程独占状态。 * **unlock（解锁）** 作用于主内存，它将释放独占状态 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ![jmm八种指令](https://gitee.com/1162492411/pic/raw/master/Java-JMM-jmm八种指令.png) ## 理论 - 如何实现可见性 - 通过**volatile关键字**标记内存屏障保证可见性。 - 通过**synchronized关键字**定义同步代码块或者同步方法保障可见性。 - 通过**Lock接口**保障可见性。 - 通过**Atomic类型**保障可见性。 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 理论 - 为了实现可见性，volatile和synchronized所使用的方法有何不同 volatile通过内存屏障来实现，而synchronized通过系统内核互斥实现，相当于JMM中的lock、unlock，退出代码块时刷新变量到主内存 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 理论 - volatile、synchronized、Lock、Atomic对原子性、一致性、有序性的保障情况 | 特性 | volatile关键字 | synchronized关键字 | Lock接口 | Atomic变量 | | ------ | -------------- | ------------------ | -------- | ---------- | | 原子性 | 无法保障 | 可以保障 | 可以保障 | 可以保障 | | 可见性 | 可以保障 | 可以保障 | 可以保障 | 可以保障 | | 有序性 | 一定程度保障 | 可以保障 | 可以保障 | 无法保障 | .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 实现可见性的方法有哪些？ 常用的并发工具类有哪些？ CyclicBarrier 和 CountDownLatch 的区别 synchronized 的作用？ volatile 关键字的作用 sleep 方法和 wait 方法有什么区别? 什么是 CAS CAS 的问题 什么是 Future？ 什么是 AQS AQS 支持两种同步方式 ReadWriteLock 是什么 FutureTask 是什么 synchronized 和 ReentrantLock 的区别 线程 B 怎么知道线程 A 修改了变量 synchronized、volatile、CAS 比较 为什么 wait()方法和 notify()/notifyAll()方法要在同步块中被调用 多线程同步有哪几种方法？ 线程的调度策略 ConcurrentHashMap 的并发度是什么？ 如果你提交任务时，线程池队列已满，这时会发生什么？ Java 中用到的线程调度算法是什么？ 什么是线程调度器(Thread Scheduler)和时间分片(TimeSlicing)？ 什么是自旋？ Java Concurrency API 中的 Lock 接口(Lock interface)是什么？对比同步它有什么优势？ ConcurrentHashMap为什么比HashMap安全又高效 jdk7分段锁，jdk8cas .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 理论 - volatile关键字的作用 1.保证线程间的可见性 2.禁止CPU进行指令重排 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 理论 - 简述volatile的内存语义 * volatile****写**：当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存。 * volatile****读**：当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量。 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 理论 - JMM如何实现volatile的禁止指令重排 首先要讲一下内存屏障，内存屏障可以分为以下几类： - LoadLoad 屏障：对于这样的语句Load1，LoadLoad，Load2。在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。 - StoreStore屏障：对于这样的语句Store1， StoreStore， Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。 - LoadStore 屏障：对于这样的语句Load1， LoadStore，Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。 - StoreLoad 屏障：对于这样的语句Store1， StoreLoad，Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。 在每个volatile读操作后插入LoadLoad屏障，在读操作后插入LoadStore屏障 在每个volatile写操作的前面插入一个StoreStore屏障，后面插入一个SotreLoad屏障。 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 理论 - 什么是MESI ​ 在多核CPU中某核发生修改，可能产生数据不一致，一致性协议正是为了保证多个CPU cache之间的缓存共享数据的一致性。其中MESI对应modify(修改)、exclusive(独占)、shared(共享)、invalid（失效）。 | 状态 | 描述 | | ------------ | ------------------------------------------------------------ | | M(modify) | 该缓存行中的内容被修改了，并且该缓存行只缓存在该CPU中,而且和主存数据不一致 | | E(exclusive) | 只有当前CPU中有数据，其他CPU中没有该数据，当前CPU和主存的数据一致 | | S(shared) | 当前CPU和其他CPU中都有共同的数据，并且和主存中的数据一致 | | I(invalid) | 当前CPU中的数据失效，数据应该从主存中获取 | - 目前CPU的写，主要是2种策略 - 1、write back：即CPU向内存写数据时，先把数据写入store buffer中，后续某个时间点会将store buffer中的数据刷新到内存 - 2、write through：即CPU向内存写数据，同步完成写store buffer与内存 - CPU大多采用write back策略 ```markdown 1、CPU异步完成写内存产生的延时是可以接受的，而且延迟很短，只有在多线程环境下需要严格保证内存可见等极少数特殊情况下才需要保证CPU的写在外界看来是同步完成的。 2、编译器和CPU可以保证输出结果一样的情况下对指令重排序。插入内存屏障，相当于告诉CPU和编译器先于这个命令的先执行，后于的命令必须后执行。 3、使用Lock前缀指令，会使多核心CPU互斥使用这个内存地址。当指令执行完，这个锁定动作也消失。 ``` .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 理论 - 有了MESI为什么还要有volatile CPU的MESI能够保证缓存一致性，但是不能保证一个线程对变量修改后其他线程立即可见。 想象下：一个CPU0中的变量所在的cache line已经是invalid，但是在CPU1中缓存的该变量最新值还没有刷新到内存中。那么CPU0需要使用该变量，会从主存中读取到旧的值。 使用volatile可以保证可见性，该CPU该volatile修饰的变量的写操作立即同步到主存。而且volatile内存屏障的作用，也会将之前的发生的数据更新刷新到内存中。 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 简述final的特性 对于**基本类型**的final域，编译器和处理器要遵守两个重排序规则： (01) final写：“构造函数内对一个final域的写入”，与“随后把这个被构造对象的引用赋值给一个引用变量”，这两个操作之间不能重排序。 (02) final读：“初次读一个包含final域的对象的引用”，与“随后初次读对象的final域”，这两个操作之间不能重排序。 对于**引用类型**的final域，除上面两条之外，还有一条规则： (03) final写：在“构造函数内对一个final引用的对象的成员域的写入”，与“随后在构造函数外把这个被构造对象的引用赋值给一个引用变量”，这两个操作之间不能重排序。 注意： 写final域的重排序规则可以确保：在引用变量为任意线程可见之前，该引用变量指向的对象的final域已经在构造函数中被正确初始化过了。其实要得到这个效果，还需要一个保证：在构造函数内部，不能让这个被构造对象的引用为其他线程可见，也就是对象引用不能在构造函数中“逸出”。 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 实践 - JMM如何实现final的特性 通过“内存屏障”实现。 在final域的写之后，构造函数return之前，插入一个StoreStore障屏。在读final域的操作前面插入一个LoadLoad屏障。 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } # 锁篇 ## 可重入锁是什么，synchronized是不是可重入锁，如果是，那么它是如何实现的 1.允许一个线程二次请求自己持有对象锁的临界资源， 2.synchronized是可重入锁 3.synchronized 锁对象有个计数器，会随着线程获 取锁后 +1 计数，当线程执行完毕后 -1，直到清零释放锁 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 公平锁和非公平锁的区别，为什么公平锁效率低于非公平锁 ## 同步队列器AQS思想，以及基于AQS实现的lock ## 偏向锁、轻量级锁、重量级锁三者各自的应用场景 偏向锁：只有一个线程进入临界区； 轻量级锁：多个线程交替进入临界区； 重量级锁：多个线程同时进入临界区 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## Java中对锁有哪些优化 1. 减少锁持有时间 - 不需要同步执行的代码，能不放在同步快里面执行就不要放在同步快内，可以让锁尽快释放； 2. 减少锁的粒度 - 它的思想是将物理上的一个锁，拆成逻辑上的多个锁，增加并行度，从而降低锁竞争。它的思想也是用空间来换时间； - java中很多数据结构都是采用这种方法提高并发操作的效率： - ConcurrentHashMap: 使用Segment数组,Segment继承自ReenTrantLock，所以每个Segment就是个可重入锁，每个Segment 有一个HashEntry数组用来存放数据，put操作时，先确定往哪个Segment放数据，只需要锁定这个Segment，执行put，其它的Segment不会被锁定；所以数组中有多少个Segment就允许同一时刻多少个线程存放数据，这样增加了并发能力。 - LongAdder:实现思路也类似ConcurrentHashMap，LongAdder有一个根据当前并发状况动态改变的Cell数组，Cell对象里面有一个long类型的value用来存储值;开始没有并发争用的时候或者是cells数组正在初始化的时候，会使用cas来将值累加到成员变量的base上，在并发争用的情况下，LongAdder会初始化cells数组，在Cell数组中选定一个Cell加锁，数组有多少个cell，就允许同时有多少线程进行修改，最后将数组中每个Cell中的value相加，在加上base的值，就是最终的值；cell数组还能根据当前线程争用情况进行扩容，初始长度为2，每次扩容会增长一倍，直到扩容到大于等于cpu数量就不再扩容，这也就是为什么LongAdder比cas和AtomicInteger效率要高的原因，后面两者都是volatile+cas实现的，他们的竞争维度是1，LongAdder的竞争维度为“Cell个数+1”为什么要+1？因为它还有一个base，如果竞争不到锁还会尝试将数值加到base上； - 拆锁的粒度不能无限拆，最多可以将一个锁拆为当前CPU数量即可； 3. 锁粗化 - 大部分情况下我们是要让锁的粒度最小化，锁的粗化则是要增大锁的粒度(如:循环内的操作); 4. 锁分离 - 使用读写锁: ReentrantReadWriteLock 是一个读写锁，读操作加读锁，可以并发读，写操作使用写锁，只能单线程写； - 读写分离: CopyOnWriteArrayList 、CopyOnWriteArraySet - CopyOnWrite容器即写时复制的容器。通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。这样做的好处是我们可以对CopyOnWrite容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以CopyOnWrite容器也是一种读写分离的思想，读和写不同的容器 - CopyOnWrite并发容器用于读多写少的并发场景，因为，读的时候没有锁，但是对其进行更改的时候是会加锁的，否则会导致多个线程同时复制出多个副本，各自修改各自的； - LinkedBlockingQueue: LinkedBlockingQueue也体现了这样的思想，在队列头入队，在队列尾出队，入队和出队使用不同的锁，相对于LinkedBlockingArray只有一个锁效率要高； 5. 锁消除 - 在即时编译时,如果发现不可能被共享的对象,则可以消除对象的锁操作 6. 无锁 (如CAS) - 如果需要同步的操作执行速度非常快，并且线程竞争并不激烈，这时候使用CAS效率会更高，因为加锁会导致线程的上下文切换，如果上下文切换的耗时比同步操作本身更耗时，且线程对资源的竞争不激烈，使用volatiled+CAS操作会是非常高效的选择； 7. 消除缓存行的伪共享 - 除了我们在代码中使用的同步锁和jvm自己内置的同步锁外，还有一种隐藏的锁就是缓存行，它也被称为性能杀手。在多核cup的处理器中，每个cup都有自己独占的一级缓存、二级缓存，甚至还有一个共享的三级缓存，为了提高性能，cpu读写数据是以缓存行为最小单元读写的；32位的cpu缓存行为32字节，64位cup的缓存行为64字节，这就导致了一些问题。 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 死锁的条件有哪些 * 互斥条件(Mutual exclusion) ：资源不能被共享，只能由一个进程使用。 * 请求与保持条件(Hold and wait)：进程已获得了一些资源，但因请求其它资源被阻塞时，对已获得的资源保持不放。 * 不可抢占条件(No pre-emption) ：有些系统资源是不可抢占的，当某个进程已获得这种资源后，系统不能强行收回，只能由进程使用完时自己释放。 * 循环等待条件(Circular wait) ：若干个进程形成环形链，每个都占用对方申请的下一个资源 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 死锁产生的原因 * 系统资源的竞争 * 进程推进的顺序不当 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 处理死锁的策略有哪些 (1) 死锁预防：破坏导致死锁必要条件中的任意一个就可以预防死锁。例如，要求用户申请资源时一次性申请所需要的全部资源，这就破坏了保持和等待条件；将资源分层，得到上一层资源后，才能够申请下一层资源，它破坏了环路等待条件。预防通常会降低系统的效率。 (2) 死锁避免：避免是指进程在每次申请资源时判断这些操作是否安全，例如，使用银行家算法（如果申请资源会导致死锁，那么拒绝申请；如果申请不会导致死锁，那么允许申请）。死锁避免算法的执行会增加系统的开销。 (3) 死锁检测：死锁预防和避免都是事前措施，而死锁的检测则是判断系统是否处于死锁状态，如果是，则执行死锁解除策略。 (4) 死锁解除：这是与死锁检测结合使用的，它使用的方式就是剥夺。即将某进程所拥有的资源强行收回，分配给其他的进程。 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } # JVM篇 JVM的内存区域分为哪几块，其中哪几块是线程共享的，每一块存储什么 ![img](https://gitee.com/1162492411/pic/raw/master/Java-JVM内存结构.png) * 堆 ： 存放实际对象，堆中一般分代，线程共享 * 方法区 ： 存储虚拟机加载的类信息、常量、静态变量以及即时编译器编译后的代码等数据，永久代就是方法区的具体实现，线程共享 * 常量池 ： 字符串常量池存放字面量，类常量池存放各种class，class被加载解析后的内容存放在运行时常量池 * 程序计数器 ：主要存储字节码的行号指示器，控制程序的执行，线程不共享 * 虚拟机栈 ：以栈帧为单位，每个栈帧对应一个被调用的Java方法，存放基本数据类型、对象引用、方法参数、操作数栈、方法出口等，线程不共享 * 本地方法栈 ：与虚拟机栈类似，区别在于它对应的是native本地方法，线程不共享 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 内存溢出和内存泄露的区别 * 内存溢出 out of memory，是指**程序在申请内存时，没有足够的内存空间供其使用**，出现out of memory； * 内存泄露 memory leak，是指**程序在申请内存后，无法释放已申请的内存空间**，一次内存泄露危害可以忽略，但内存泄露堆积后果很严重，无论多少内存，迟早会被占光。 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 如何判断哪些对象需要被GC * 引用计数法 ： 引用计数为0的需要被回收 * 可达性分析 ： 从GC Roots出发的不可达对象需要被回收 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 什么是GC Roots * 方法区中的类静态属性引用的对象； * 方法区中常量引用的对象； * 虚拟机栈（栈帧中的本地变量表）中引用的对象； * 本地方法栈中JNI（即一般说的Native方法）中引用的对象 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 对象的访问定位方式 * 使用句柄 * 直接指针 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 强引用、软引用、弱引用、虚引用是什么 * 强引用 ： 正常的对象引用 * 软引用 ： 维护一些可有可无的对象。只有在内存不足时，系统则会回收软引用对象，如果回收了软引用对象之后仍然没有足够的内存，才会抛出内存溢出异常 * 弱引用 ：比较软引用，要更加无用一些，它拥有更短的生命周期。当JVM进行垃圾回收时，无论内存是否充足，都会回收被弱引用关联的对象 * 虚引用 ：形同虚设的引用，主要用来跟踪对象被垃圾回收的活动 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## GC的方法 * 标记-清除 * 标记-整理 * 复制 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 对象在哪些情况下会从新生代进入老年代 * 达到回收年龄，默认15 * 动态对象年龄判断 * 分配担保时新生代不够用会直接分配到老年代 * 对象超出一定大小时直接分配到老年代 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 优化时调整过JVM的哪些参数 * **Xms** ： 初始堆内存大小 * **Xmx** ：最大堆内存大小 * **Xmn** ：年轻代大小 * **Xss** ：每个线程的内存大小 * **XX:NewRatio** ：设置新生代和老年代的比值 * **XX:SurvivorRatio** ： 新生代中Eden区与两个Survivor区的比值 * **XX:+UseG1GC** : 使用G1垃圾收集器 * **XX:+PrintGC** ：统计垃圾回收信息 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 内存溢出是什么，有哪些原因，如何解决 * 定义 ： 分配的内存空间超过系统内存 * 原因 ： * 使用了大量的递归或无限递归 * 在循环内大量创建对象 * 使用了大量的static修饰变量，或者用static修饰了过大的数据 * 有数组，List，Map中存放的是大量对象的引用而不是对象 * 没有重新equals()和hashCode()方法，从而导致向数组/List/Map中添加时导致重复添加 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 内存泄漏是什么，有哪些原因，如何解决 * 定义 ：系统分配的内存没有被回收 * 原因 ： * 连接未关闭 * finalize方法没有被执行从而导致jvm认为对象还无法被回收 * ThreadLocal的错误使用，使用完之后未及时remove .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## MinorGC，MajorGC、FullGC都什么时候发生 MinorGC在年轻代空间不足的时候发生，MajorGC指的是老年代的GC，出现MajorGC一般经常伴有MinorGC。 FullGC有三种情况。 1. 当老年代无法再分配内存的时候 2. 元空间不足的时候 3. 显示调用System.gc的时候。另外，像CMS一类的垃圾回收器，在MinorGC出现promotion failure的时候也会发生FullGC .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 类加载的过程 加载、验证、准备、解析、初始化 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } MinGC与FullGC各自指什么 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } HotSpot的GC算法以及7种垃圾回收期 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } # 设计模式篇 ## 简要介绍各设计模式中的关键点 单例模式：某个类只能有一个实例，提供一个全局的访问点。 简单工厂：一个工厂类根据传入的参量决定创建出那一种产品类的实例。 工厂方法：定义一个创建对象的接口，让子类决定实例化那个类。 抽象工厂：创建相关或依赖对象的家族，而无需明确指定具体类。 建造者模式：封装一个复杂对象的构建过程，并可以按步骤构造。 原型模式：通过复制现有的实例来创建新的实例。 适配器模式：将一个类的方法接口转换成客户希望的另外一个接口。 组合模式：将对象组合成树形结构以表示“”部分-整体“”的层次结构。 装饰模式：动态的给对象添加新的功能。 代理模式：为其他对象提供一个代理以便控制这个对象的访问。 亨元（蝇量）模式：通过共享技术来有效的支持大量细粒度的对象。 外观模式：对外提供一个统一的方法，来访问子系统中的一群接口。 桥接模式：将抽象部分和它的实现部分分离，使它们都可以独立的变化。 模板模式：定义一个算法结构，而将一些步骤延迟到子类实现。 解释器模式：给定一个语言，定义它的文法的一种表示，并定义一个解释器。 策略模式：定义一系列算法，把他们封装起来，并且使它们可以相互替换。 状态模式：允许一个对象在其对象内部状态改变时改变它的行为。 观察者模式：对象间的一对多的依赖关系。 备忘录模式：在不破坏封装的前提下，保持对象的内部状态。 中介者模式：用一个中介对象来封装一系列的对象交互。 命令模式：将命令请求封装为一个对象，使得可以用不同的请求来进行参数化。 访问者模式：在不改变数据结构的前提下，增加作用于一组对象元素的新功能。 责任链模式：将请求的发送者和接收者解耦，使的多个对象都有处理这个请求的机会。 迭代器模式：一种遍历访问聚合对象中各个元素的方法，不暴露该对象的内部结构。 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } # 实战排查 ## 如何查找哪个线程使用 CPU 最长 （1）获取项目的pid，jps或者ps -ef | grep java （2）top -H -p pid，顺序不能改变 这样可以打印出当前的项目进程，每条线程占用CPU时间的百分比 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 如何排查CPU问题过高 * top -H查看CPU使用最高的进程，将其转换为十六进制，例如pid为67136，转换为16进制的1065b * `jstack`命令获取应用的栈信息，搜索这个16进制 ，例如`jstack -l 67136|grep 1065b`,-l作用是查询锁信息 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ## 如何排查堆外内存 进程占用的内存，可以使用top命令，看RES段占用的值。如果这个值大大超出我们设定的最大堆内存，则证明堆外内存占用了很大的区域。 使用gdb可以将物理内存dump下来，通常能看到里面的内容。更加复杂的分析可以使用perf工具，或者谷歌开源的gperftools。那些申请内存最多的native函数，很容易就可以找到。 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 如何排查线上出现的JVM问题 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; }</content></entry><entry><title>Spring常见面试题</title><url>https://www.zyg-tech.me/post/spring%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/</url><categories><category>面试题</category><category>Spring</category></categories><tags><tag>面试题</tag><tag>Spring</tag></tags><content type="html"> .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } IOC Spring如何解决setter方式的循环依赖
singletonFactories ： 单例对象工厂的cache； earlySingletonObjects ：提前暴光的单例对象的Cache； singletonObjects：单例对象的cache； 1. 实例化a，先把beanName放到singletonsCurrentlyInCreation中，然后调用无参构造方法实例化bean,然后构造一个singletonFactory对象放到singletonFactories中，暴露给其它可能的依赖; 2. 最后装配属性时，发现需要注入b,那么就开始构造b,构造b的流程和上一步一致 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } Spring中Bean的生命周期
@Autowired和@Resources注解的异同
1.autowired默认按类型查找对象，resources默认按照名称查找对象 2.autowired是spirng提供的注解，resouces是j2ee提供的注解，但是二者都是jsr标准下的注解 3.两个注解都可以用在字段上 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 同样的接口存在多个实现时如何指定某一个实现
1.@Qualifer 2.@Primary .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 创建IOC容器的过程
以最原始的XmlBeanFactory为例讲解, 1.创建Ioc配置文件的抽象资源，这个抽象资源包含了BeanDefinition的定义信息 ； 2.创建一个BeanFactory，这里使用了DefaultListableBeanFactory ； 3.创建一个载入BeanDefinition的读取器，这里使用XmlBeanDefinitionReader来载入XML文件形式的BeanDefinition ； 4.然后将上面定位好的Resource，通过一个回调配置给BeanFactory ； 5.从定位好的资源位置读入配置信息，具体的解析过程由XmlBeanDefinitionReader完成 ； 6.完成整个载入和注册Bean定义之后，需要的Ioc容器就初步建立起来了 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } Spring bean的初始化顺序
1. Constructor; 2. @PostConstruct; 3. InitializingBean; 4. init-method .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } AOP aop的底层实现
动态代理有哪些实现方式，有什么区别
事务 Spring事务底层如何实现
Spring事务的七个传播级别，默认是哪个
.spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 拷贝 什么是浅拷贝和深拷贝，有什么区别 常用的实体拷贝有哪几种方式，各自是如何实现的 Spring的BeanUtils拷贝存在哪些细节问题 SpringBoot 简述SpringBoot的配置文件加载顺序 由高到低依次为： 命令行参数。所有的配置都可以在命令行上进行指定； 来自java:comp/env的JNDI属性； Java系统属性（System.getProperties()）； 操作系统环境变量 ； jar包外部的application-{profile}.properties或application.yml(带spring.profile)配置文件 jar包内部的application-{profile}.properties或application.yml(带spring.profile)配置文件 再来加载不带profile jar包外部的application.properties或application.yml(不带spring.profile)配置文件 jar包内部的application.properties或application.yml(不带spring.profile)配置文件 @Configuration注解类上的@PropertySource .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; }</content></entry><entry><title>Linux常见面试题</title><url>https://www.zyg-tech.me/post/linux%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/</url><categories><category>Linux</category><category>面试题</category></categories><tags><tag>Linux</tag><tag>面试题</tag></tags><content type="html"> .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 内存 如何查看系统内存
free .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 如何清理系统内存
```shell # 仅清除页面缓存（PageCache） echo 1 /proc/sys/vm/drop_caches # 清除目录项和inode echo 2 /proc/sys/vm/drop_caches # 清除页面缓存，目录项和inode echo 3 /proc/sys/vm/drop_caches ``` .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 内核 用户态如何切换到内核态 1. 系统调用，例如fork() 2. 异常 3. 外围设备的中断 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; }
系统函数 select和epoll的区别
CPU cpu的load值不同时，cpu有哪几种模式(空闲，轻度负载，高负载)
文件系统 Linux，查找磁盘上最大的文件的命令
常用命令 如何查看系统负载 使用top命令 ，执行后效果如下 ``` top - 01:06:48 up 1:22, 1 user, load average: 0.06, 0.60, 0.48 Tasks: 29 total, 1 running, 28 sleeping, 0 stopped, 0 zombie Cpu(s): 0.3% us, 1.0% sy, 0.0% ni, 98.7% id, 0.0% wa, 0.0% hi, 0.0% si Mem: 191272k total, 173656k used, 17616k free, 22052k buffers Swap: 192772k total, 0k used, 192772k free, 123988k cached PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1379 root 16 0 7976 2456 1980 S 0.7 1.3 0:11.03 sshd 14704 root 16 0 2128 980 796 R 0.7 0.5 0:02.72 top 1 root 16 0 1992 632 544 S 0.0 0.3 0:00.90 init 2 root 34 19 0 0 0 S 0.0 0.0 0:00.00 ksoftirqd/0 3 root RT 0 0 0 0 S 0.0 0.0 0:00.00 watchdog/0 ``` 第一行是任务队列信息 ：分别表示系统当前时间、系统运行时间、当前登陆用户数量、系统负载(即任务队列的平均长度,三个数值分别为 1分钟、5分钟、15分钟前到现在的平均值) 第二、三行是进程和CPU的信息 ： ``` total 进程总数 running 正在运行的进程数 sleeping 睡眠的进程数 stopped 停止的进程数 zombie 僵尸进程数 Cpu(s): 0.3% us 用户空间占用CPU百分比 1.0% sy 内核空间占用CPU百分比 0.0% ni 用户进程空间内改变过优先级的进程占用CPU百分比 98.7% id 空闲CPU百分比 0.0% wa 等待输入输出的CPU时间百分比 0.0%hi：硬件CPU中断占用百分比 0.0%si：软中断占用百分比 0.0%st：虚拟机占用百分比 ``` 第四、五行是内存信息 ``` Mem: 191272k total 物理内存总量 173656k used 使用的物理内存总量 17616k free 空闲内存总量 22052k buffers 用作内核缓存的内存量 Swap: 192772k total 交换区总量 0k used 使用的交换区总量 192772k free 空闲交换区总量 123988k cached 缓冲的交换区总量 ``` 剩下的是进程信息区统计信息区域，它显示了各个进程的详细信息，各列的含义如下 ``` 序号 列名 含义 a PID 进程id b PPID 父进程id c RUSER Real user name d UID 进程所有者的用户id e USER 进程所有者的用户名 f GROUP 进程所有者的组名 g TTY 启动进程的终端名。不是从终端启动的进程则显示为 ? h PR 优先级 i NI nice值。负值表示高优先级，正值表示低优先级 j P 最后使用的CPU，仅在多CPU环境下有意义 k %CPU 上次更新到现在的CPU时间占用百分比 l TIME 进程使用的CPU时间总计，单位秒 m TIME+ 进程使用的CPU时间总计，单位1/100秒 n %MEM 进程使用的物理内存百分比 o VIRT 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES p SWAP 进程使用的虚拟内存中，被换出的大小，单位kb。 q RES 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA r CODE 可执行代码占用的物理内存大小，单位kb s DATA 可执行代码以外的部分(数据段+栈)占用的物理内存大小，单位kb t SHR 共享内存大小，单位kb u nFLT 页面错误次数 v nDRT 最后一次写入到现在，被修改过的页面数。 w S 进程状态(D=不可中断的睡眠状态,R=运行,S=睡眠,T=跟踪/停止,Z=僵尸进程) x COMMAND 命令名/命令行 y WCHAN 若该进程在睡眠，则显示睡眠中的系统函数名 z Flags 任务标志，参考 sched.h ``` .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } vmstat命令各字段含义 - r: 运行队列中进程数量（当数量大于CPU核数表示有阻塞的线程） - b: 等待IO的进程数量 - swpd: 使用虚拟内存大小 - free: 空闲物理内存大小 - buff: 用作缓冲的内存大小(内存和硬盘的缓冲区) - cache: 用作缓存的内存大小（CPU和内存之间的缓冲区） - si: 每秒从交换区写到内存的大小，由磁盘调入内存 - so: 每秒写入交换区的内存大小，由内存调入磁盘 - bi: 每秒读取的块数 - bo: 每秒写入的块数 - in: 每秒中断数，包括时钟中断。 - cs: 每秒上下文切换数。 - us: 用户进程执行时间百分比(user time) - sy: 内核系统进程执行时间百分比(system time) - wa: IO等待时间百分比 - id: 空闲时间百分比 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; }</content></entry><entry><title>数据库常见面试题</title><url>https://www.zyg-tech.me/post/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/</url><categories><category>数据库</category><category>面试题</category></categories><tags><tag>MySQL</tag><tag>面试题</tag></tags><content type="html"> 基础篇 1NF、2NF、3NF是什么 * 1NF ： 表中每一列的属性都不可再分 * 2NF ： 表中每一列的属性都不可再分，且非主属性完全依赖于主属性 * 3NF ：在2NF的基础上，每个非主属性之间都不传递函数依赖于其他非主属性 * BC NF ： 在3NF基础上，任何非主属性不能对主键子集依赖（在3NF基础上消除对主码子集的依赖），BCNF是3NF的一个子集 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } InndoDB相比MyISAM有什么优点 * 支持行锁 * 支持事务 * 支持外键 * 支持崩溃后的数据恢复 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } delete、truncate、drop区别 * delete属于DML语言；每次删除一行，都在事务日志中为所删除的每行记录一项；删除数据，不释放空间，不删除表结构 * truncate属于DDL语言；通过释放数据页来删除数据，并且只在事务日志中记录页的释放；删除数据，释放空间，不删除表结构 * drop数据数据DDL语言；删除表的结构，以及被依赖的约束、触发器、索引；删除数据，删除空间，删除表结构 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 事务篇 事务有哪些特性 1. **原子性（Atomicity）：** 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用； 2. **一致性（Consistency）：** 执行事务后，数据库从一个正确的状态变化到另一个正确的状态； 3. **隔离性（Isolation）：** 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的； 4. **持久性（Durability）：** 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 并发事务会带来哪些问题 - **脏读（Dirty read）:** 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。 - **丢失修改（Lost to modify）:** 指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。 例如：事务1读取某表中的数据A=20，事务2也读取A=20，事务1修改A=A-1，事务2也修改A=A-1，最终结果A=19，事务1的修改被丢失。 - **不可重复读（Unrepeatableread）:** 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。 - **幻读（Phantom read）:** 幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 事务的隔离级别有哪些 - **READ-UNCOMMITTED(读取未提交)：** 最低的隔离级别，允许读取尚未提交的数据变更，**可能会导致脏读、幻读或不可重复读**。 - **READ-COMMITTED(读取已提交)：** 允许读取并发事务已经提交的数据，**可以阻止脏读，但是幻读或不可重复读仍有可能发生**。 - **REPEATABLE-READ(可重复读)：** 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，**可以阻止脏读和不可重复读，但幻读仍有可能发生**。 - **SERIALIZABLE(可串行化)：** 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，**该级别可以防止脏读、不可重复读以及幻读**。 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 事务的隔离级别都能解决哪些并发事务问题 | 隔离级别 | 脏读 | 不可重复读 | 幻影读 | | ---------------- | ---- | ---------- | ------ | | READ-UNCOMMITTED | √ | √ | √ | | READ-COMMITTED | × | √ | √ | | REPEATABLE-READ | × | × | √ | | SERIALIZABLE | × | × | × | .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } MySQL默认的隔离级别是哪个 REPEATABLE-READ，但是因为MySQL的REPEATABLE-READ采用的是next-key lock,因此事实上实现了SERIALIZABLE的效果 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 如何修改隔离级别 * 全局修改 ： 修改mysql.ini,添加以下配置项 * ``` #可选参数有：READ-UNCOMMITTED, READ-COMMITTED, REPEATABLE-READ, SERIALIZABLE. [mysqld] transaction-isolation = REPEATABLE-READ ``` * 修改会话级别 ： set session transaction isolation level read uncommitted; * 在代码中修改 ： 如Spring事务可以在@Transactional注解中指定Isolation为READ-UNCOMMITTED/READ-COMMITTED/REPEATABLE-READ/SERIALIZABLE，这样可以实现会话级别的修改 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 连接篇 内连接和外连接什么区别 内连接（inner join）：取出两张表中匹配到的数据，匹配不到的不保留 外连接（outer join）：取出连接表中匹配到的数据，匹配不到的也会保留，其值为NULL .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 左连接和右连接什么区别 左连接 ： 以左边的表为主表 右连接 ： 以右边的表为主表 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } MySQL有哪些Join算法 1.**Simple Nested-Loop Join** (MySQL并没有实现这种)： 简单的嵌套循环连接，流程如下 ![数据库-MySQL-Join-nlj](https://gitee.com/1162492411/pic/raw/master/数据库-MySQL-Join-nlj.png) 2.**Block Nested-Loop Join** `Block Nested-Loop(BNL)`算法缓冲在外循环中读取的行，来减少读取内循环表的次数。例如，如果将10行数据读取到缓冲区中，然后将缓冲区传入到内循环，内循环中读取的行可以一次与缓冲区中的10行数据进行对比，这可以减少读取内循环中的表的次数。 该算法的流程是： 1. 把表A的数据读入线程内存join_buffer中 2. 扫描表B，把表B的每一行取出来，跟join_buffer中的数据进行对比，满足join条件则作为结果集的一部分返回 ![block join](https://gitee.com/1162492411/pic/raw/master/数据库-MySQL-Join-BlockNestedLoopJoin.jpg) 3.**Index Nested-Loop Join** Index Nested-Loop Join是基于索引进行连接，驱动表通过被驱动表上的索引进行匹配，避免与被驱动表的每条记录都进行对比，减少对比次数，提升Join性能.执行过程如下： 1. 从表t1中读取一行记录A1 2. 从数据行A1中取出字段a到t2里去查找 3. 取出t2中满足条件的行，与A1组成一行作为结果集 4. 重复上述3个步骤，直到t1遍历完成 ![index join](https://gitee.com/1162492411/pic/raw/master/数据库-MySQL-Join-IndexNestedLoopJoin.jpg) 4. **Hash Join** Hash join 不需要索引的支持。大多数情况下，hash join 比之前的 BNL 算法在没有索引时的等值连接更加高效。这种算法自MySQL8.0开始支持 具体步骤： - 1）把驱动表相关字段存入Join Buffer，这一步和BNL套路相同。 - 2）（build）把Join Buffer中对应的字段值生成一个散列表，保存在内存中。 - 3）（probe）扫描被驱动表，对被驱动表中的相关字段进行散列并比较。 ![2019-11-yamin-hash-join.jpg](https://gitee.com/1162492411/pic/raw/master/数据库-MySQL-Join-HashJoin.jpg) 5. **Batched Key Access Join** MySQL 5.6推出了 `Batched Key Access Join`，该算法通过常见的空间换时间，随机I/O转顺序I/O，以此来极大的提升Join的性能。 ![BKA Join](https://gitee.com/1162492411/pic/raw/master/数据库-MySQL-Join-BKA.png) .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 索引篇 MySQL支持的索引类型 * B+树 * 全文索引 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 索引的优缺点 优势：可以快速检索，减少I/O次数，加快检索速度；根据索引分组和排序，可以加快分组和排序； 劣势：索引本身也是表，因此会占用存储空间，一般来说，索引表占用的空间的数据表的1.5倍；索引表的维护和创建需要时间成本，这个成本随着数据量增大而增大；构建索引会降低数据表的修改操作（删除，添加，修改）的效率，因为在修改数据表的同时还需要修改索引表 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 索引的分类 * 主键索引：即主索引，根据主键pk_clolum（length）建立索引，**不允许重复，不允许空值** * 唯一索引：用来建立索引的列的值必须是**唯一的，允许空值** * 普通索引：用表中的普通列构建的索引，没有任何限制 * 组合索引：用多个列组合构建的索引，这多个列中的值不允许有空值 * 全文索引：用大文本对象的列构建的索引 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 什么是聚簇索引？什么是非聚簇索引 * 聚簇索引 ：索引与数据存储在一起，如主键索引 * 非聚簇索引 ：索引与数据分离 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 什么时候适合使用索引 * 经常作为查询条件在WHERE或者ORDER BY 语句中出现的列要建立索引； * 作为排序的列要建立索引； * 查询中与其他表关联的字段，外键关系建立索引 * 高并发条件下倾向组合索引； * 用于聚合函数的列可以建立索引，例如使用了max(column_1)或者count(column_1)时的column_1就需要建立索引 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 什么时候不适合使用索引 * 经常增删改的列不要建立索引； * 有大量重复的列不建立索引； * 表记录太少不要建立索引 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 索引什么时候失效 * 在索引的列上使用表达式或者函数会使索引失效 * 在查询条件中使用IS NULL或者IS NOT NULL会导致索引失效 * LIKE操作中，'%aaa%'不会使用索引，'%aaa'不会使用索引 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 三星索引是什么 * 第一颗星： * 定义 ： 如果与一个查询相关的索引行是相邻的(where匹配出的结果之间物理距离近)，或者至少相距足够靠近的话，那这个索引就可以标记上一颗星 * 收益 ： 它最小化了必须扫描的索引片的宽度 * 实现 ： 把 WHERE 后的等值条件列作为索引最开头的列，如此，必须扫描的索引片宽度就会缩至最短 * 第二颗星： * 定义：如果索引行的顺序与查询语句的需求一致，则索引可以标记上第二颗星。 * 收益：它排除了排序操作 * 实现：将 ORDER BY 列加入到索引中，保持列的顺序 * 第三颗星： * 定义：如果索引行中包含查询语句中的所有列，那么这个索引就可以标记上第三颗星。 * 收益：这避免了访问表的操作（避免了回表操作），只访问索引就可以满足了。 * 实现：将查询语句中剩余的列都加入到索引中/仅查询包含索引的列 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 锁篇 MySQL的InnoDB引擎中有哪些锁 1）按照锁的粒度划分 * 表级锁 * 行级锁 * Record lock：单个行记录上的锁 * Gap lock：间隙锁，锁定一个范围，不包括记录本身 * Next-key lock：record+gap 锁定一个范围，包含记录本身 2）按照是否可写划分 * 共享锁(S锁) ： 读锁，其他用户可以并发读取数据，但任何事务都不能获取数据上的排他锁，直到已释放所有共享锁 * 排它锁(X锁) ：写锁，若事务T对数据对象A加上X锁，则只允许T读取和修改A，其它任何事务都不能再对A加任何类型的锁，直到T释放A上的锁 3） 意向锁 * 意向共享锁(IS) ：表示事务准备给数据行记入共享锁，事务在一个数据行加共享锁前必须先取得该表的IS锁 * 意向排它锁(IX) ：表示事务准备给数据行加入排他锁，事务在一个数据行加排他锁前必须先取得该表的IX锁 意向锁是表级锁，**仅仅表示事务正在读或写某一行记录，在真正加行锁时才会判断是否冲突**，意向锁由数据库自动加载，无需用户干预。意向锁不会和行级别的X锁、S锁发生冲突，会和表级别的X锁、S锁发生冲突 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 概述MyQSQL的InnoDB中锁的兼容情况 ps:个人存在疑问 | | 共享锁 | 排它锁 | 意向共享锁 | 意向排它锁 | | ---------- | ------ | ------ | ---------- | ---------- | | 共享锁 | 👌 | ❌ | 👌 | ❌ | | 排它锁 | ❌ | ❌ | ❌ | ❌ | | 意向共享锁 | 👌 | ❌ | 👌 | 👌 | | 意向排它锁 | ❌ | ❌ | 👌 | 👌 | .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 日志篇 优化篇 什么是Multi-Range Read，解决的什么问题？ 它的原理是，将多个需要回表的二级索引根据主键进行排序，然后一起回表，将原来的回表时进行的随机IO，转变成顺序IO MRR 仅仅针对 **二级索引 的范围扫描** 和 **使用二级索引进行 join** 的情况。 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 实战篇 一条sql的执行流程 一条sql的解析顺序 * from * join * on * where * group by(开始使用select中的别名，后面的语句中都可以使用) * avg,sum.... * having * select * distinct * order by * limit .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 一条SQL语句执行慢的原因有哪些 * 偶尔很慢的情况 * 数据库在刷新脏页(flush) ，flush有四种场景：redo log写满了；内存不够用了；MySQL认为服务器空闲了；MySQL正常关闭时刻 * 数据可能被其他连接加锁了 * 一直很慢的情况 * 服务器压力大 * 磁盘转速过低或者IO被其他服务大量使用 * SQL未正确使用索引导致全表扫描或者大范围锁表 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 如何查看SQL执行计划 在执行的语句前加上`explain`关键字 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 如何查看被优化器优化后的SQL ```mysql EXPLAIN ; SHOW WARNINGS; ``` .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 执行计划中的select type有哪几种 * simple：表示不需要union操作或者不包含子查询的简单查询。 * primary：表示最外层查询。 * union：union操作中第二个及之后的查询。 * dependent union：union操作中第二个及之后的查询，并且该查询依赖于外部查 * subquery：子查询中的第一个查询。 * dependent subquery：子查询中的第一个查询，并且该查询依赖于外部查询。 * derived：派生表查询，既from字句中的子查询。 * materialized：物化查询。 * uncacheable subquery：无法被缓存的子查询，对外部查询的每一行都需要重新进行查询 * uncacheable union：union操作中第二个及之后的查询，并且该查询属于uncacheable subquery。 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 执行计划中的type有哪些 按照性能从高到低依次为： * NULL：无需访问表或者索引，比如获取一个索引列的最大值或最小值。 * system/const：当查询最多匹配一行时，常出现于where条件是＝的情况。system是const的一种特殊情况，既表本身只有一行数据的情况。 * eq_ref：多表关联查询时，根据唯一非空索引进行查询的情况。 * ref：多表查询时，根据非唯一非空索引进行查询的情况。 * range：在一个索引上进行范围查找。 * index：遍历索引树查询，通常发生在查询结果只包含索引字段时。 * ALL：全表扫描，没有任何索引可以使用时。这是最差的情况，应该避免 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } select(*)、select(1)、select(列名)有什么区别 Count(列名)表示的是该列的值不为空的总行数 count(*) = count(1),它们会统计所有行数(即使列的值为空)，具体的执行效率由优化器根据成本优化，默认选择最小成本的辅助索引(不选择主键索引是因为mysql的主键是聚簇的，主键与该行数据存储在一起，这时候辅助索引反而文件更小效率更高成本更低) .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 高可用篇 MySQL的主从复制有哪几种模式 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; }</content></entry><entry><title>Redis常见面试题</title><url>https://www.zyg-tech.me/post/redis%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/</url><categories><category>Redis</category><category>NoSQL</category><category>数据库</category></categories><tags><tag>Redis</tag><tag>中间件</tag><tag>NoSQL</tag><tag>数据库</tag></tags><content type="html"> 原理篇 如何理解Redis的通讯协议resp协议 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 如何理解Redis的cluster bus的gossip协议 1）用于节点间进行高效的数据交换，占用更少的网络带宽和处理时间； 2）gossip 协议包含多种消息，包含 ping、pong、meet、fail 等等； 3）ping ： 每个节点都会频繁给其它节点发送 ping，其中包含自己的状态还有自己维护的集群元数据，互相通过 ping 交换元数据； 4）meet ： 某个节点发送 meet 给新加入的节点，让新节点加入集群中； 5）pong ： 返回meet和ping； 6）fail ： 节点停止后发送fail告知其他节点； .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 为什么早期版本Redis是单线程的 Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } Redis为什么速度快 1）绝大部分操作为基于内存的操作 2）数据结构和对数据的操作简单 3）采用单线程减少上下文切换和竞争，不需要考虑锁的问题 4）使用多路I/O复用模型，非阻塞IO，多个网络连接使用同一个线程 5）通过队列将访问串形化，减少传统关系型数据的串行控制开销 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } Redis的主从复制原理是什么 从节点连接主节点，向主节点发起同步请求，接收主节点的rdb文件 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } Redis如何划分内存 1）used_memory ：Redis分配器分配的内存总量； 2）used_memory_rss ：进程占据操作系统的内存； 3）mem_fragmentation_ratio ： 内存碎片率，used_memory_rss / used_memory； 4）mem_allocator ： 使用的内存分配器 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } Redis的存储细节 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } Redis如何实现渐进式hash进行扩容 1）申请旧hash两倍的内存空间，使得原有的字典同时持有旧hash表和新hash表 2）维护一个标志变量rehashindex用于记录进度 3）访问字典时将旧hash表中位于rehashindex这个桶中的key全部转移到新hash表中 4）全部转移完时修改记录进度rehashindex .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } Redis事务的CAS .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } string如何扩容 小于1m时每次加倍扩容，大于1m时每次增加1m，最大为512m .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } redis的文件事件处理器都包含哪些部分 1）多个 socket用来完成请求的接收与响应信息的发送 2）IO 多路复用程序 3）文件事件分派器用来协调调度 4）事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）用来真正干活 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 基础篇 Redis都有哪些基础的数据结构，他们各自的底层是如何实现的，对应的使用场景是什么 1）String ： 类似Java的动态数组，在内部预先分配一定空间，场景为存储键值对； 2）Hash ： 类似Java的HashMap，数据+链表结构，发生 hash 碰撞时将会把元素追加到链表上，场景为存储购物车信息或者对象； 3）List ： 类似Java的LinkedList，插入与删除数据的复杂度为O(1),数据量少时为一块内存连续的ziplist，数据量多时采用有前后指针的quicklist，redis3.2以后是ziplist+quicklist，场景为点赞列表、评论列表； 4）Set ： 类似Java的HashSet，键无序且唯一，value为null，场景为好友、关注、粉丝、感兴趣的人集合； 5）SortedSet ：有序集合，内部实现为ziplist或者skiplist，场景为排行榜 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } Redis有哪些高级的数据结构，对应的使用场景是什么 1)BitMaps : 位图,面向bit进行操作,每个bit位为一个值,极度节省空间,经典使用场景是用户的每日签到记录 2)HyperLogLog : 基数统计,基数是数据集去重后元素个数,经典使用场景是统计用户UV 3)GEO : 处理地理位置 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } Redis如何做到数据持久化，这些方式各自有什么优缺点 RDB保存快照，AOF保存执行命令的记录并合并命令； 1) RDB有两种方式：同步save模式和异步bgsave模式，同步save模式可以保证数据一致性； save会导致redis阻塞，bgsave在大数据量时fork会引起抖动，导致短暂时间内redis响应变慢，且fork需要一定的内存开销； rdb文件默认每次rdb时进行替换并压缩； rdb优点：文件紧凑，体积小，适合全量备份与复制，且加载rdb文件的速度比加载aof文件的速度快 rdb缺点：无法秒级别持久化，老版本redis无法兼容新版本的rdb 2) aof是目前主流的持久数据的方式，aof每次都会将写命令保存到缓冲区然后追加输出到aof文件中， .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } Redis慢查询如何开启 设置slowlog-log-slower-than属性来配置慢查询时间的阈值，设置slowlog-max-len属性来配置存储多少条慢查询命令 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } Redis的默认内存为多大 32位机器默认3个G，64位机器默认不限制 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } Redis的淘汰策略有哪些 1）noeviction ： 不删除 2）allkeys-lru ： 从所有key中删除最近最少使用的key 3）volatile-lru ： 从设置了过期时间的key中删除最近最少使用的key 4）allkeys-random ： 从所有key中随机删除 5）volatile-random ： 从设置了过期时间的key中随机删除 6）volatile-ttl ： 从设置了过期时间的key中删除剩余时间最短的 7）allkeys-lfu ：淘汰访问频率最低的key 8）volatile-lfu ：只淘汰访问频率最低的过期key .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } Redis的删除策略有哪些，这些删除策略各自有什么优缺点 1）定时删除 ： 在设置键的过期时间的同时，创建一个定时任务，当键达到过期时间时，立即执行对键的删除操作，优点是对内存友好可以即时释放，缺点是对cpu不友好可能大量key同时删除； 2）定期删除 ： 每隔一定时间删除过期的键，优点是对cpu友好，缺点是对内存不友好； 3）惰性删除 ： 放任键过期不管，但在每次获取键时，判断是否过期，若过期再删除，优点是对cpu友好，缺点是对内存不友好 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } Redis的Pipeline如何理解 将多个命令一次性发送并执行，节省网络消耗，虽然命令执行时可能被其他命令穿插 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } Redis如何设置过期时间 1）expire key milliseconds在指定毫秒后过期； 2）expire key seconds在指定秒后过期； 3）expire at key timestamp 在指定的时间戳（秒级别）后过期； 4）expire at key millisecondsTimestamp 在指定的时间戳（毫秒）后过期 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } Redis支持哪些集群模式 1）主从复制模式；2）Sentinel哨兵模式；3）cluster模式 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } Redis的事务是否支持回滚 Redis的事务有哪些相关命令 Redis有哪些常用的缓存更新策略 实战篇 Redis有哪些常用场景 1）缓存 2）Session共享 3）简单的消息队列 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 如何理解缓存穿透、缓存击穿、缓存雪崩、缓存预热，如何解决 1）缓存穿透 ： 查询一个在redis中不存在的值，比如空值或者特殊的值，解决方案：将一些不存在的值也放入redis中；采用布隆过滤器； 2）缓存击穿 ：说某个key非常热点，当这个key在失效的瞬间，大量的请求直接请求数据库，解决方案：热点数据设置为永远不过期，或者加入互斥锁 3）缓存雪崩 ： 大批量的缓存集中在某个时刻失效，解决方案：设置过期时间不一致，或者加锁排队，或者建立备份缓存或者 事前：redis 高可用，主从+哨兵，redis cluster，避免全盘崩溃。 - 事中：本地 ehcache 缓存 + hystrix 限流&amp;降级，避免 MySQL 被打死。 - 事后：redis持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据； 4）缓存预热： 提前将常用数据加入到缓存中以提高速度 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } Redis内存使用满会出现什么现象 无法写入只能读取 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 主从结构下，数据一致性问题如何解决 1）分析业务场景，若允许不一致，则无需处理 2）选择性读主：核心思路是将变动的情况写入在一个cache中，从节点从这个cache中查看是否包含本次的数据。 * 记录变化情况 ：将哪个库，哪个表，哪个主键三个信息拼装一个key设置到cache里，这条记录的超时时间，设置为“主从同步时延” * 查询时若cache有这个key ： 说明1s内刚发生过写请求，数据库主从同步可能还没有完成，此时就应该去主库查询 * 查询时若cache没有这个key ：说明最近没有发生过写请求，此时就可以去从库查询 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } Redis如何实现定时队列 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } Redis如何实现消息队列 1）基于List的 LPUSH+BRPOP 的实现，使用rpush和lpush操作入队列，lpop和rpop操作出队列，引入阻塞读blpop和brpop，阻塞读在队列没有数据的时候进入休眠状态，一旦数据到来则立刻醒过来，消息延迟几乎为零，这种方案当一直没有消息时会导致连接空闲从而被释放，下次使用连接时报错，而且也没有消费者ACK机制，也不能重复消费，也不能进行广播； 2）PUB/SUB，订阅/发布模式，广播模式，消息可以即时发送，但是若消息发布时消费者不在线会丢失小消息，消息积压时也不好处理； 3）基于Sorted Set，消息id自己实现有序递增，缺点是不能存在重复的消息id； 4）基于stream，redis5.0开始支持，借鉴kafka，采用消息链表，消息持久化，可以记录消费者的消费进度，可以确保消息至少被消费一次，但是消息过多时旧消息会丢失，消费者消费消息但不ack会导致pel列表增大而消耗内存 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } Redis的并发竞争如何解决 1）多个实例更新一个key时通过加锁排队让命令串形化 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } Redis和数据库如何实现双写一致性 1）Cache Aside Pattern ： * 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。 - 更新的时候，先更新数据库，然后再删除缓存，这种方案实际上在高并发的时候可以继续进行优化 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 有哪些基于Redis实现的分布式锁 1）setnx + expire； 2）setIfAbsent； 3）基于zookeeper的有序节点实现分布式锁； 4）redssion ：采用看门狗，定期续期 ； 5）redlock ： 将加锁命令发送到多个节点参与，如果大多数都加锁成功就成功，如果失败就逐个恢复锁； .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } Redis中的key过期了是否立即释放内存，为什么 不是 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 如何保证Redis的高可用和高并发 1）基于一主多从，主节点进行写入，每秒w级别的qps，从节点进行读取，每秒10w级别的qps 2）加上哨兵，当节点出现故障时进行主备切换 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } Redis集群模式下，redis的key如何寻址，分布式寻址都有哪些算法 寻址算法 ： 1）hash 算法（大量缓存重建）：计算hash后取模，访问不同的节点 2）一致性 hash 算法（自动缓存迁移）+ 虚拟节点（自动负载均衡） ：将整个 hash 值空间组织成一个虚拟的圆环 3）redis cluster 的 hash slot 算法 ：对每个 key 计算 CRC16 值，然后对 16384 取模，放入16384个slot中的一个，每个redis节点持有部分slot .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } ##一致性hash算法是什么
.spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } Redis变慢如何排查 1）查看慢命令，分析是否存在复杂命令 2）查看是否存在大key 3）查看是否缓存雪崩 4）查看淘汰策略，查看内存是否打满 5）查看fork进程频率是否合理 6）查看内存分配是否合理 7）查看aof追加策略 8）如果是单机部署了多个redis，定位是否存在aof竞争问题 9）查看是否使用swap 10）查看网卡负载是否正常 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 如何为Redis一次增加大批量数据 1）管道2）手动拼接发送resp命令 .spoiler { color: black; background-color:black; white-space:pre-line; } .spoiler:hover{ color: white; } 优化篇 开发层次有哪些常用的优化建议 key的长度尽量要短，在数据量非常大时，过长的key名会占用更多的内存；
一定避免存储过大的数据（大value），过大的数据在分配内存和释放内存时耗时严重，会阻塞主线程；
Redis 4.0以上建议开启lazy-free机制，释放大value时异步操作，不阻塞主线程；
建议设置过期时间，把Redis当做缓存使用，尤其在数量很大的时，不设置过期时间会导致内存的无限增长；
不使用复杂度过高的命令，例如SORT、SINTER、SINTERSTORE、ZUNIONSTORE、ZINTERSTORE，使用这些命令耗时较久，会阻塞主线程；
查询数据时，一次尽量获取较少的数据，在不确定容器元素个数的情况下，避免使用LRANGE key 0 -1，ZRANGE key 0 -1这类操作，应该设置具体查询的元素个数，推荐一次查询100个以下元素；
写入数据时，一次尽量写入较少的数据，例如HSET key value1 value2 value3…，控制一次写入元素的数量，推荐在100以下，大数据量分多个批次写入；
批量操作数据时，用MGET/MSET替换GET/SET、HMGET/MHSET替换HGET/HSET，减少请求来回的网络IO次数，降低延迟，对于没有批量操作的命令，推荐使用pipeline，一次性发送多个命令到服务端；
禁止使用KEYS命令，需要扫描实例时，建议使用SCAN，线上操作一定要控制扫描的频率，避免对Redis产生性能抖动
避免某个时间点集中过期大量的key，集中过期时推荐增加一个随机时间，把过期时间打散，降低集中过期key时Redis的压力，避免阻塞主线程；
根据业务场景，选择合适的淘汰策略，通常随机过期要比LRU过期淘汰数据更快；
使用连接池访问Redis，并配置合理的连接池参数，避免短连接，TCP三次握手和四次挥手的耗时也很高；
只使用db0，不推荐使用多个db，使用多个db会增加Redis的负担，每次访问不同的db都需要执行SELECT命令，如果业务线不同，建议拆分多个实例，还能提高单个实例的性能；
读的请求量很大时，推荐使用读写分离，前提是可以容忍从节数据更新不及时的问题；
写请求量很大时，推荐使用集群，部署多个实例分摊写压力
运维层次有哪些常用的优化建议 不同业务线部署不同的实例，各自独立，避免混用，推荐不同业务线使用不同的机器，根据业务重要程度划分不同的分组来部署，避免某一个业务线出现问题影响其他业务线；
保证机器有足够的CPU、内存、带宽、磁盘资源，防止负载过高影响Redis性能；
以master-slave集群方式部署实例，并分布在不同机器上，避免单点，slave必须设置为readonly； master和slave节点所在机器，各自独立，不要交叉部署实例，通常备份工作会在slave上做，做备份时会消耗机器资源，交叉部署会影响到master的性能；
推荐部署哨兵节点增加可用性，节点数量至少3个，并分布在不同机器上，实现故障自动故障转移；
提前做好容量规划，一台机器部署实例的内存上限，最好是机器内存的一半，主从全量同步时会占用最多额外一倍的内存空间，防止网络大面积故障引发所有master-slave的全量同步导致机器内存被吃光；
做好机器的CPU、内存、带宽、磁盘监控，在资源不足时及时报警处理，Redis使用Swap后性能急剧下降，网络带宽负载过高访问延迟明显增大，磁盘IO过高时开启AOF会拖慢Redis的性能；
设置最大连接数上限，防止过多的客户端连接导致服务负载过高；
单个实例的使用内存建议控制在10G以下，过大的实例会导致备份时间久、资源消耗多，主从全量同步数据时间阻塞时间更长；
设置合理的slowlog阈值，推荐10毫秒，并对其进行监控，产生过多的慢日志需要及时报警；
设置合理的复制缓冲区repl-backlog大小，适当调大repl-backlog可以降低主从全量复制的概率；
设置合理的slave节点client-output-buffer-limit大小，对于写入量很大的实例，适当调大可以避免主从复制中断问题；
备份时推荐在slave节点上做，不影响master性能；
不开启AOF或开启AOF配置为每秒刷盘，避免磁盘IO消耗降低Redis性能；
当实例设置了内存上限，需要调大内存上限时，先调整slave再调整master，否则会导致主从节点数据不一致；
对Redis增加监控，监控采集info信息时，使用长连接，频繁的短连接也会影响Redis性能；
线上扫描整个实例数时，记得设置休眠时间，避免扫描时QPS突增对Redis产生性能抖动；
做好Redis的运行时监控，尤其是expired_keys、evicted_keys、latest_fork_usec指标，短时间内这些指标值突增可能会阻塞整个实例，引发性能问题</content></entry><entry><title>MySQL排他锁实战</title><url>https://www.zyg-tech.me/post/mysql%E6%8E%92%E4%BB%96%E9%94%81%E5%AE%9E%E6%88%98/</url><categories><category>MySQL</category><category>锁</category></categories><tags><tag>MySQL</tag><tag>分布式锁</tag></tags><content type="html"> 1. 需求背景 ​ 基于MySQL/Oracle数据库实现分布式锁，保证一个项目中的定时任务代码在多台机器中同时执行时最多有一个任务可以成功获取锁，其他任务获取锁失败
2. 排他锁介绍 2.1 概念 ​ 如果事务T对数据A加上排他锁(exclusive lock，即X锁)后，则其他事务不能再对A加任任何类型的锁，将会等待事务T结束。获准排他锁的事务既能读数据，又能修改数据.
​ 在MySQL中，X锁仅适用于InnoDB引擎，而且必须在事务中才能生效，根据where条件是否通过索引命中数据，MySQL中的X锁分为行锁与表锁 ：命中数据时采用行锁，本质是对索引加锁；其他情况下均为表锁（例如没有where条件对应的数据，where后的字段没有索引）；特殊地，如果表数据过少，InnoDB引擎也可能将SQL优化为表锁，这种情况下可以通过force index来强制使用索引。
2.2 用法示例 2.2.1 基本用法 select … for update;
例如：select * from goods where id = 1 for update;
2.2.2 进阶用法 # nowait --&amp;gt; 不再等待事务而是立即返回结果，如果发现where条件的结果集被其他事务锁定则立即返回失败，该语法自MySQL的8.0版本开始支持，Oracle支持 select ... for update no wait; # wait --&amp;gt; 最多等待指定的时间x秒之后返回结果，该语法在Orale中支持 select ... for update wait x; # skip locked --&amp;gt; 如果数据锁定时跳过锁定的数据,该语法自MySQL的8.0版本开始支持，Oracle支持 select ... for update skip locked; 3.准备数据 3.1 准备表 create table t_gdts_sync_flag ( n_id bigint auto_increment comment '流水id' primary key, c_company_id varchar(20) null comment '集团id,对应t_gdts_company_rel的n_id', n_type tinyint(2) null comment '同步标识类型,1集团,2部门,3人员', c_status varchar(10) null comment '同步状态,sync/idle' ) comment '同步标识表'; 3.2 准备数据 INSERT INTO gropt.t_gdts_sync_flag (n_id, c_company_id, n_type, c_status) VALUES (75, '1326009432085127169', 1, 'idle'); INSERT INTO gropt.t_gdts_sync_flag (n_id, c_company_id, n_type, c_status) VALUES (76, '1326009432085127169', 2, 'idle'); INSERT INTO gropt.t_gdts_sync_flag (n_id, c_company_id, n_type, c_status) VALUES (77, '1326009432085127169', 3, 'idle'); 4. 实战 4.1 定义用于获取锁的线程池 4.2 获取锁的SQL语句 4.3 获取锁的Service代码 4.4 定时任务代码</content></entry><entry><title>Hystrix熔断器</title><url>https://www.zyg-tech.me/post/hystrix%E7%86%94%E6%96%AD%E5%99%A8/</url><categories><category>熔断</category></categories><tags><tag>服务高可用</tag><tag>熔断</tag></tags><content type="html"> 熔断器 状态及转换 Hystrix提供的熔断器具有自我反馈，自我恢复的功能，Hystrix会根据调用接口的情况，让熔断器在closed,open,half-open三种状态之间自动切换,三种状态简要说明如下:
closed : 代表关闭熔断,默认状态,在此期间执行远程调用方法 open : 代表打开熔断,在此期间执行本地降级策略,不执行远程调用 half-open : 代表中间状态,在此期间,先执行远程调用,如果成功,下次继续执行远程调用,如果失败,转换为open状态 1)正常状态下为closed状态,若访问接口超过设置阈值且错误请求数比例达到设置值时,转换为open状态,时间段从0开始(打开熔断)
2)保持open状态一个时间段;
3)下个时间段后,状态自动转换为half-open,在此期间,
​ 3.1)如果第一次请求时接口失败,则转换为open状态,时间段从0开始,
​ 3.2)如果请求数量达到设置阈值且错误请求书比例未达到设置值时,转换状态为closed,时间段从0开始(恢复正常),
​ 3.3)如果请求数量没有达到阈值, 一直保持half-open状态
核心流程 将远程服务调用逻辑封装进一个HystrixCommand。 对于每次服务调用可以使用同步或异步机制，对应执行execute()或queue()。 判断熔断器(circuit-breaker)是否打开或者半打开状态，如果打开跳到步骤8，进行回退策略，如果关闭进入步骤4。 判断线程池/队列/信号量（使用了舱壁隔离模式）是否跑满，如果跑满进入回退步骤8，否则继续后续步骤5。 run方法中执行了实际的服务调用。 a. 服务调用发生超时时，进入步骤8。 判断run方法中的代码是否执行成功。 a. 执行成功返回结果。 b. 执行中出现错误则进入步骤8。 所有的运行状态(成功，失败，拒绝，超时)上报给熔断器，用于统计从而影响熔断器状态。 进入getFallback()回退逻辑。 a. 没有实现getFallback()回退逻辑的调用将直接抛出异常。 b. 回退逻辑调用成功直接返回。 c. 回退逻辑调用失败抛出异常。 返回执行成功结果。</content></entry><entry><title>服务压测调优</title><url>https://www.zyg-tech.me/post/%E6%9C%8D%E5%8A%A1%E5%8E%8B%E6%B5%8B%E8%B0%83%E4%BC%98/</url><categories><category>调优</category></categories><tags><tag>服务优化</tag><tag>调优</tag><tag>Linux</tag></tags><content type="html"> 服务压测问题修复 Linux服务器环境优化 调整linux最大线程数 ​ /etc/sysctl.conf 配置文件中，加入 sys.kernel.threads-max = 40960
调整linux全局最大pid ​ /etc/sysctl.conf 配置文件中，加入 sys.kernel.pid_max = 40960
调整linux TCP进程参数 ​ /etc/sysctl.conf 配置文件中，加入 以下内容,执行：sysctl -p ，使设置立即生效：
# 进程可以同时打开的最大文件句柄数，这个参数直接限制最大并发连接数 fs.file-max=999999 ############## TCP数据窗口相关参数 ############## # 默认的TCP数据接收窗口大小/字节,默认229376 net.core.rmem_default = 256960 # 最大的TCP数据接收窗口大小/字节,默认131071 net.core.rmem_max = 513920 # 默认的TCP数据发送窗口大小/字节,默认229376 net.core.wmem_default = 256960 # 最大的TCP数据发送窗口/字节,默认131071 net.core.wmem_max = 513920 ################# TCP队列相关参数 ############### # 当网卡接收数据包的速度大于内核处理数据的时候，会有一个队列保存这些数据包,即接收队列长度。这个参数表示这个队列的最大值,默认1000 net.core.netdev_max_backlog = 2000 # TCP三次握手建立阶段服务器接收SYN请求队列的最大长度,即SYN半连接队列长度,对于超出该队列的请求直接丢弃 net.ipv4.tcp_max_syn_backlog = 262144 # 全局的每一个端口最大的监听队列的长度,默认128 net.core.somaxconn = 2048 ############## TCP缓冲区相关参数 ########### # 全局的所有TCP的SocketBuffer配置,该SocketBuffer用于发送方发送数据/接收方接受数据时存储这些数据,有三个值，单位为内存页(通常为4K):当TCP使用了低于第一个值的内存页面数时，TCP不会考虑释放内存;当TCP使用了超过第二个值的内存页面数量时,TCP试图稳定其内存使用，进入pressure模式;当内存占用超过第三个值，系统拒绝分配socket,报错TCP: too many of orphaned sockets.默认94011 125351 188022 net.ipv4.tcp_mem = 131072 262144 524288 # TCP读缓冲区/字节,三个值分别表示TCP接收缓存（用于TCP接收滑动窗口）的最小值、默认值、最大值,默认4096 87380 4011232 net.ipv4.tcp_rmem = 8760 256960 4088000 # TCP写缓冲区/字节,三个值分别表示TCP发送缓存（用于TCP接收滑动窗口）的最小值、默认值、最大值,默认4096 16384 4011232 net.ipv4.tcp_wmem = 8760 256960 4088000 # 每个套接字所允许的最大缓冲区的大小/字节,默认20480 net.core.optmem_max = 81920 ############### keepalive相关参数 ##################### # CLOSE_WAIT 状态维持的秒数 = tcp_keepalive_time + tcp_keepalive_intvl * tcp_keepalive_probes # 当keepalive启用时，TCP发送keealive消息的频度,默认7200/秒 net.ipv4.tcp_keepalive_time = 1800 # 以该参数指定的秒数为时间间隔/s，向客户端发起对它的探测 net.ipv4.tcp_keepalive_intvl = 30 # 内核发起对客户端探测的次数，如果都没有得到响应，那么就断定客户端不可达或者已关闭，内核就关闭该TCP连接 net.ipv4.tcp_keepalive_probes = 3 ############### Time_wait相关参数 ##################### # 是否开启timstamp校验,该配置项会影响net.ipv4.tcp_tw_reuse、net.ipv4.tcp_tw_recycle,只有发起方和接收方都开启该项才会使得net.ipv4.tcp_tw_reuse、net.ipv4.tcp_tw_recycle生效,该配置项提供以下两个功能:a.更加准确的RTT测量数据，尤其是有丢包时 – RTTM b. 保证了在极端情况下，TCP的可靠性 – PAWS net.ipv4.tcp_timestamps = 1 # 是否允许将TIME—WAIT状态的socket重新用于新的TCP连接,默认0,1开启,开启后将会在Time_wait状态的1s后复用socket net.ipv4.tcp_tw_reuse = 1 # 设置是否对TIME_WAIT状态的TCP进行快速回收,默认0,1开启 net.ipv4.tcp_tw_recycle = 1 # 当服务器主动关闭连接的时候，主动关闭方的socket保持在FIN-WAIT-2状态的最大时间/秒,默认60 net.ipv4.tcp_fin_timeout = 30 ############### 其他参数 ##################### # 是否启用有选择的应答,开启此项后,可以让发送方只发送丢失部分的数据,即支持乱序接收 net.ipv4.tcp_sack = 1 # 是否打开FACK拥塞避免和快速重传功能 net.ipv4.tcp_fack = 1 # 是否支持更大的TCP窗口,如果TCP窗口最大超过65535(64K), 必须设置该数值为1 net.ipv4.tcp_window_scaling = 1 # 是否打开SYN Cookie功能，该功能可以防止部分SYN flood攻击 net.ipv4.tcp_syncookies = 1 # 在UDP和TCP连接本地端口的取值范围 net.ipv4.ip_local_port_range = 1024 65000 调整linux最大文件数量 /etc/security/limits.conf文件尾部添加如下代码：
* soft nofile 65535 * hard nofile 65535 Tmcat参数优化 设置内存参数 tomcat安装目录/bin/catalina.sh 106 行添加以下内容
JAVA_OPTS=&amp;quot;-Xmx8192M -Xms8192M -XX:MaxPermSize=512M -XX:PermSize=512M -XX:+UseG1GC -XX:MaxGCPauseMillis=100 -XX:+ParallelRefProcEnabled -XX:+HeapDumpOnOutOfMemoryError -XX:+PrintGCApplicationStoppedTime -XX:+PrintHeapAtGC&amp;quot; 【注意】不要换行是一行 参数 参考地址为：https://console.perfma.com/ 线程数计算公式： Max memory （除去系统占用和其他应用程序占用后的操作系统总内存大小） = [-Xmx] + [-XX:MaxMetaSpaceSize] + number_of_threads * [-Xss]
修改日志打印 访问日志原始值：
&amp;lt;Valve className=&amp;quot;org.apache.catalina.valves.AccessLogValve&amp;quot; directory=&amp;quot;logs&amp;quot; prefix=&amp;quot;localhost_access_log.&amp;quot; suffix=&amp;quot;.txt&amp;quot; pattern=&amp;quot;%h %l %u %t %s %b&amp;quot; /&amp;gt; 调整后的值:
&amp;lt;Valve className=&amp;quot;org.apache.catalina.valves.AccessLogValve&amp;quot; directory=&amp;quot;logs&amp;quot; prefix=&amp;quot;localhost_access_log.&amp;quot; suffix=&amp;quot;.txt&amp;quot; pattern=&amp;quot;%h %l %u %t %q %s %b %F %D %I &amp;quot; /&amp;gt; pattern属性的值由文字文本字符串和以“％”字符为前缀的模式标识符组合而成，以替换为来自当前请求和响应的相应变量值。支持以下模式代码：(原始地址:http://tomcat.apache.org/tomcat-7.0-doc/config/valve.html)
％ a-远程IP地址 **％A-**本地IP地址 **％b-**发送的字节，不包括HTTP标头，如果为零则为&amp;rsquo;-&amp;rsquo; **％B-**发送的字节，不包括HTTP标头 **％h-**远程主机名（如果enableLookups连接器为false，则为IP地址 ） **％H-**请求协议 ％l -identd的远程逻辑用户名（总是返回“-”） **％m-**请求方法（GET，POST等） **％p-**接收此请求的本地端口。另请参见%{xxx}p下文。 **％q-**查询字符串（如果存在，则以“？”开头） **％r-**请求的第一行（方法和请求URI） **％s-**响应的HTTP状态代码 **％S-**用户会话ID **％t-**日期和时间，采用通用日志格式 **％u-**已验证（如果有）的远程用户，否则为&amp;rsquo;-&amp;rsquo; **％U-**请求的URL路径 **％v-**本地服务器名称 **％D-**以毫秒为单位处理请求所花费的时间。注意：在httpd中，％D是微秒。从Tomcat 10开始，行为将与httpd对齐。 **％T-**处理请求所花费的时间，以秒为单位。注意：此值具有毫秒分辨率，而在httpd中具有第二分辨率。行为将与Tomcat 10及更高版本中的httpd保持一致。 **％F-**提交响应所花费的时间（以毫秒为单位） **％I-**当前请求线程名称（以后可以与堆栈跟踪进行比较） 调整线程数 tomcat安装目录/conf/server.xml 71行
调整前原始值：
&amp;lt;Connector port=&amp;quot;8080&amp;quot; protocol=&amp;quot;HTTP/1.1&amp;quot; connectionTimeout=&amp;quot;20000&amp;quot; redirectPort=&amp;quot;8443&amp;quot; /&amp;gt; 调整后的值：
&amp;lt;Connector port=&amp;quot;8080&amp;quot; protocol=&amp;quot;HTTP/1.1&amp;quot; maxKeepAliveRequests=&amp;quot;200&amp;quot; socketBuffer=&amp;quot;9000&amp;quot; enableLookups=&amp;quot;false&amp;quot; tcpNoDelay=&amp;quot;true&amp;quot; minSpareThreads=&amp;quot;100&amp;quot; maxSpareThreads=&amp;quot;100&amp;quot; maxThreads=&amp;quot;2000&amp;quot; connectionTimeout=&amp;quot;5000&amp;quot; maxHttpHeaderSize=&amp;quot;32768&amp;quot; URIEncoding=&amp;quot;UTF-8&amp;quot; acceptCount=&amp;quot;200&amp;quot; redirectPort=&amp;quot;8443&amp;quot; /&amp;gt; 配置项解释
参数 含义 示例 port 绑定的端口,如果设置为0，tomcat则随机获取一个空闲端口 默认 port=&amp;quot;8080&amp;rdquo; protocol 传输协议和版本 默认 protocol = &amp;ldquo;HTTP/1.1&amp;rdquo; connectionTimeout 连接超时时间，单位毫秒 默认 connectionTimeout=&amp;quot;20000&amp;rdquo; redirectPort 接收到的ssl请求后重定向的端口 默认 redirectPort=&amp;quot;8443&amp;rdquo; maxThreads tomcat能创建来处理请求的最大线程数，也为最大并发数 超过则放入请求队列中进行排队，默认值为200；需要根据业务和系统性能进行调整 maxThreads=&amp;quot;1000&amp;rdquo; URIEncoding url的字符编码，在tomcat8.5版本中，该值默认为UTF-8,除非在org.apache.catalina.STRICT_SERVLET_COMPLIANCE 将system property 设置为true才会使用ISO-8859-1 URIEncoding=&amp;quot;UTF-8&amp;rdquo; minProcessors 启动时创建的线程数（最小线程数） minProcessors=&amp;quot;50&amp;rdquo; acceptCount 指定当所有可以使用的处理请求的线程数都被使用时，可以放到队列中的请求数，就是被排队的请求数，超过这个数的请求将拒绝连接 默认值为100 acceptcount=&amp;quot;500&amp;rdquo; acceptorThreadCount 可以用于接受连接的进程数，默认为1，但是在一些多核的的服务器上，我们会将它的值设置为2或者更大的数，来应对一些不活跃的连接。 minSpareThreads 最小空闲线程数，任何情况都会存活的线程数，即便超过了最大空闲时间，也不会被回收，默认值10; minSpareThreads=&amp;quot;25&amp;rdquo; maxSpareThreads 最大空闲线程数，在最大空闲时间（maxIdleTime）内活跃过，此时空闲，当空闲时间大于maxIdleTime则被回收，小则继续存活，等待被调度，默认值50； enableLookups 调用request、getRemoteHost()执行DNS查询，以返回远程主机的主机名，如果设置为false，则直接返回IP地址 默认是禁用的，在请求过滤中的根据远程主机名过滤，需要将该参数设置为true enableLookups=&amp;quot;false&amp;rdquo; maxIdleTime 最大空闲时间，超过这个空闲时间，且线程数大于minSpareThreads的，都会被回收，默认值1分钟（60000ms) maxPostSize address 对于一些具有多个ip的服务器，我们可以通过该参数指定绑定的ip，默认情况下监听所有的地址 address=&amp;quot;192.168.1.110&amp;rdquo; compressibleMimeType 该值用来指定哪些文件类型的文件可以进行压缩，默认值为：text/html,text/xml,text/plain,text/css,text/javascript,application/javascript compression 开启gzip 压缩，可以接受的值是 &amp;ldquo;off&amp;rdquo;(禁用压缩),&amp;ldquo;on&amp;rdquo;(开启压缩),&amp;ldquo;force(强制压缩)&amp;quot;，&amp;ldquo;1-9&amp;rdquo;(等效于开启压缩，并且设定压缩等级),开启了压缩，也就意味着要占用更多的cpu资源 compression compressionMinSize 在compression 参数指定为on后，该参数用来指定压缩的阈值，只有大于该阈值才会被压缩，默认为 2048 keepAliveTimeout 指connector两个HTTP请求直接的等待时间，超过该时间没有接收到第二个HTTP请求就关闭连接，默认是使用connectionTimeout 的值，单位为毫秒 maxConnections 在一定时间内可以接受和处理的最大连接数，达到限制后，服务器接受但不处理该链接，但可以存放到acceptCount，该默认值因连接器类型而异。对于NIO和NIO2，默认值为10000。对于APR / native，默认为8192。 maxCookieCount 请求允许的最大cookie 数，值小于0表示无限制，默认值为 200 disableUploadTimeout 默认是true ，禁用数据上传超时 connectionUploadTimeout 设定数据上传的超时时间，只有在disableUploadTimeout设置为false才生效，单位毫秒 connectionUploadTimeout=&amp;quot;50000&amp;rdquo; processorCache 进程缓冲器，默认值是maxThreads的值,使用好该值可以提升并发请求。</content></entry><entry><title>Docker 常用命令</title><url>https://www.zyg-tech.me/post/docker-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url><categories><category>Docker</category></categories><tags><tag>容器化</tag><tag>部署运维</tag><tag>Docker</tag><tag>命令</tag></tags><content type="html"> Docker是一个开源的应用容器引擎，让开发者可以打包应用及依赖包到一个可移植的镜像中，然后发布到任何流行的Linux或Windows机器上。使用Docker可以更方便地打包、测试以及部署应用程序。
Docker环境安装 安装yum-utils； yum install -y yum-utils device-mapper-persistent-data lvm2 复制代码 为yum源添加docker仓库位置； yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 复制代码 安装docker服务； yum install docker-ce 复制代码 启动docker服务。 systemctl start docker 复制代码 Docker镜像常用命令 搜索镜像 docker search java 复制代码 下载镜像 docker pull java:8 复制代码 查看镜像版本 由于docker search命令只能查找出是否有该镜像，不能找到该镜像支持的版本，所以我们需要通过Docker Hub来搜索支持的版本。
进入Docker Hub的官网，地址：https://hub.docker.com
然后搜索需要的镜像：
查看镜像支持的版本：
进行镜像的下载操作：
docker pull nginx:1.17.0 列出镜像 docker images 删除镜像 指定名称删除镜像： docker rmi java:8 指定名称删除镜像（强制）： docker rmi -f java:8 删除所有没有引用的镜像： docker rmi `docker images | grep none | awk &amp;#39;{print $3}&amp;#39;` 强制删除所有镜像： docker rmi -f $(docker images) 打包镜像 # -t 表示指定镜像仓库名称/镜像名称:镜像标签 .表示使用当前目录下的Dockerfile文件 docker build -t mall/mall-admin:1.0-SNAPSHOT . Docker容器常用命令 新建并启动容器 docker run -p 80:80 --name nginx \ -e TZ=&amp;#34;Asia/Shanghai&amp;#34; \ -v /mydata/nginx/html:/usr/share/nginx/html \ -d nginx:1.17.0 -p：将宿主机和容器端口进行映射，格式为：宿主机端口:容器端口； &amp;ndash;name：指定容器名称，之后可以通过容器名称来操作容器； -e：设置容器的环境变量，这里设置的是时区； -v：将宿主机上的文件挂载到宿主机上，格式为：宿主机文件目录:容器文件目录； -d：表示容器以后台方式运行。 列出容器 列出运行中的容器： docker ps 列出所有容器： docker ps -a 停止容器 注意：$ContainerName表示容器名称，$ContainerId表示容器ID，可以使用容器名称的命令，基本也支持使用容器ID，比如下面的停止容器命令。
docker stop $ContainerName(or $ContainerId) 例如：
docker stop nginx #或者 docker stop c5f5d5125587 强制停止容器 docker kill $ContainerName 启动容器 docker start $ContainerName 进入容器 先查询出容器的pid： docker inspect --format &amp;#34;{{.State.Pid}}&amp;#34; $ContainerName 根据容器的pid进入容器： nsenter --target &amp;#34;$pid&amp;#34; --mount --uts --ipc --net --pid 删除容器 删除指定容器： docker rm $ContainerName 按名称通配符删除容器，比如删除以名称mall-开头的容器： docker rm `docker ps -a | grep mall-* | awk &amp;#39;{print $1}&amp;#39;` 强制删除所有容器； docker rm -f $(docker ps -a -q) 查看容器的日志 查看容器产生的全部日志： docker logs $ContainerName 动态查看容器产生的日志： docker logs -f $ContainerName 查看容器的IP地址 docker inspect --format &amp;#39;{{ .NetworkSettings.IPAddress }}&amp;#39; $ContainerName 修改容器的启动方式 # 将容器启动方式改为always docker container update --restart=always $ContainerName 同步宿主机时间到容器 docker cp /etc/localtime $ContainerName:/etc/ 指定容器时区 docker run -p 80:80 --name nginx \ -e TZ=&amp;#34;Asia/Shanghai&amp;#34; \ -d nginx:1.17.0 查看容器资源占用状况 查看指定容器资源占用状况，比如cpu、内存、网络、io状态： docker stats $ContainerName 查看所有容器资源占用情况： docker stats -a 查看容器磁盘使用情况 docker system df 执行容器内部命令 docker exec -it $ContainerName /bin/bash 指定账号进入容器内部 # 使用root账号进入容器内部 docker exec -it --user root $ContainerName /bin/bash 查看所有网络 docker network ls ## 结果示例 [root@local-linux ~]# docker network ls NETWORK ID NAME DRIVER SCOPE 59b309a5c12f bridge bridge local ef34fe69992b host host local a65be030c632 none 创建外部网络 docker network create -d bridge my-bridge-network 指定容器网络 docker run -p 80:80 --name nginx \ --network my-bridge-network \ -d nginx:1.17.0 修改镜像的存放位置 查看Docker镜像的存放位置： docker info | grep &amp;#34;Docker Root Dir&amp;#34; 关闭Docker服务： systemctl stop docker 先将原镜像目录移动到目标目录： mv /var/lib/docker /mydata/docker 建立软连接： ln -s /mydata/docker /var/lib/docker 再次查看可以发现镜像存放位置已经更改。 本文 GitHub github.com/macrozheng/… 已经收录，欢迎大家Star！
作者：MacroZheng 链接：https://juejin.cn/post/6895888125886332941 来源：掘金 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</content></entry><entry><title>Spring中Async的使用与源码解析</title><url>https://www.zyg-tech.me/post/spring%E4%B8%ADasync%E7%9A%84%E4%BD%BF%E7%94%A8%E4%B8%8E%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/</url><categories><category>SpringBoot</category><category>线程池</category></categories><tags><tag>线程池</tag><tag>异步</tag><tag>SpringBoot</tag></tags><content type="html"> 背景介绍 对于异步方法调用，从Spring3开始提供了@Async注解，该注解可以被标注在方法上，以便异步地调用该方法。调用者将在调用时立即返回，方法的实际执行将提交给Spring TaskExecutor的任务中，由指定的线程池中的线程执行。
常见的场景 系统日志记录 耗时任务的执行 使用方法 1.启动类增加@EnableAsync注解(since Spring 3.1)
@EnableAsync @SpringBootApplication public class SpringBootDemoAsyncApplication { public static void main(String[] args) { SpringApplication.run(SpringBootDemoAsyncApplication.class, args); } } 2.如有需要，可以自定义线程池
@Configuration public class ExecutorConfiguration { /** * 配置应用访问日志专用线程池 * @return */ @Bean(name = &amp;#34;sodAppLogAsyncExecutor&amp;#34;) public ThreadPoolTaskExecutor asyncExecutor() { ThreadPoolTaskExecutor threadPool = new ThreadPoolTaskExecutor(); threadPool.setThreadNamePrefix(&amp;#34;drs-sodAppLog-&amp;#34;); threadPool.setCorePoolSize(3); threadPool.setMaxPoolSize(4); threadPool.setKeepAliveSeconds(60); threadPool.setQueueCapacity(11); threadPool.setRejectedExecutionHandler(new ThreadPoolExecutor.DiscardPolicy()); //优雅关闭 threadPool.setWaitForTasksToCompleteOnShutdown(true); threadPool.setAwaitTerminationSeconds(60 * 15); return threadPool; } } 3.在需要使用异步的方法上添加@Async注解，可以通过value属性指定线程池,返回值支持void、Future、ListenableFuture、CompletableFuture，如果不指定value，那么采用默认线程池
/** * 模拟5秒的异步任务 */ @Async public Future&amp;lt;Boolean&amp;gt; asyncTask1() throws InterruptedException { doTask(&amp;#34;asyncTask1&amp;#34;, 5); return new AsyncResult&amp;lt;&amp;gt;(Boolean.TRUE); } /** * 模拟业务代码 * @param taskName * @param time */ private void doTask(String taskName, Integer time) { log.info(&amp;#34;{}模拟执行【{}】,线程内存地址:{}&amp;#34;, taskName, Thread.currentThread().getName(), UnsafeUtil.addressOf(Thread.currentThread())); } Spring实现的线程池 SimpleAsyncTaskExecutor：默认线程池，每次调用都启动一个新线程(并不会复用线程池已有线程),支持对并发总数设限（ConcurrencyLimit，默认-1不限制，0不允许），当超过线程并发总数限制时，阻塞新的调用 ThreadPoolTaskExecutor:对JDK的ThreadPoolExecutor的封装，SpringBoot通过TaskExecutionAutoConfiguration自动装配了一个名为applicationTaskExecutor的ThreadPoolTaskExecutor @ConditionalOnClass(ThreadPoolTaskExecutor.class) @Configuration @EnableConfigurationProperties(TaskExecutionProperties.class) public class TaskExecutionAutoConfiguration { @Bean @ConditionalOnMissingBean public TaskExecutorBuilder taskExecutorBuilder() { TaskExecutionProperties.Pool pool = this.properties.getPool(); TaskExecutorBuilder builder = new TaskExecutorBuilder(); builder = builder.queueCapacity(pool.getQueueCapacity()); builder = builder.corePoolSize(pool.getCoreSize()); builder = builder.maxPoolSize(pool.getMaxSize()); builder = builder.allowCoreThreadTimeOut(pool.isAllowCoreThreadTimeout()); builder = builder.keepAlive(pool.getKeepAlive()); builder = builder.threadNamePrefix(this.properties.getThreadNamePrefix()); builder = builder.customizers(this.taskExecutorCustomizers); builder = builder.taskDecorator(this.taskDecorator.getIfUnique()); return builder; } @Lazy @Bean(name = APPLICATION_TASK_EXECUTOR_BEAN_NAME) @ConditionalOnMissingBean(Executor.class) public ThreadPoolTaskExecutor applicationTaskExecutor(TaskExecutorBuilder builder) { return builder.build(); } } SimpleAsyncTaskExecutor 属性列表
Daemon:是否为守护线程，默认false ThreadPriority:线程优先级,默认5 ThreadNamePrefix:线程名前缀，默认&amp;quot;SimpleAsyncTaskExecutor&amp;rdquo; ConcurrencyLimit:并发上限,默认-1不限制，0表示不允许并发？？？？ ThreadPoolTaskExecutor 属性列表
CorePoolSize：线程池创建时候初始化的线程数,默认1 MaxPoolSize：线程池最大的线程数，只有在缓冲队列满了之后才会申请超过核心线程数的线程，默认Integer.MAX QueueCapacity：用来缓冲执行任务的队列的队列大小，默认Integer.MAX KeepAliveSeconds：线程的空闲时间，单位/s，当超过了核心线程出之外的线程在空闲时间到达之后会被销毁,默认60 ThreadNamePrefix：线程池中线程名的前缀，继承自父类ExecutorConfigurationSupport，默认是BeanName/方法名 RejectedExecutionHandler：线程池对拒绝任务的处理策略，自父类ExecutorConfigurationSupport,（策略为JDK ThreadPoolExecutor自带） AbortPolicy：默认策略，直接抛出异常 RejectedExecutionException CallerRunsPolicy：直接在 execute 方法的调用线程中运行被拒绝的任务；如果执行程序已关闭，则会丢弃该任务 DiscardPolicy：该策略直接丢弃 DiscardOldestPolicy：该策略会先将最早入队列的未执行的任务丢弃掉，然后尝试执行新的任务。如果执行程序已关闭，则会丢弃该任务 waitForTasksToCompleteOnShutdown：关闭程序时是否等待任务执行完毕，继承自父类ExecutorConfigurationSupport，默认false表示中断正在执行的任务，清空队列 awaitTerminationSeconds：关闭程序时的等待时间，需配合waitForTasksToCompleteOnShutdown使用，继承自父类ExecutorConfigurationSupport，默认0 线程处理流程 /** * Executes the given task sometime in the future. The task * may execute in a new thread or in an existing pooled thread. * * If the task cannot be submitted for execution, either because this * executor has been shutdown or because its capacity has been reached, * the task is handled by the current {@code RejectedExecutionHandler}. * * @param command the task to execute * @throws RejectedExecutionException at discretion of * {@code RejectedExecutionHandler}, if the task * cannot be accepted for execution * @throws NullPointerException if {@code command} is null */ public void execute(Runnable command) { if (command == null) throw new NullPointerException(); /* * Proceed in 3 steps: * * 1. If fewer than corePoolSize threads are running, try to * start a new thread with the given command as its first * task. The call to addWorker atomically checks runState and * workerCount, and so prevents false alarms that would add * threads when it shouldn&amp;#39;t, by returning false. * * 2. If a task can be successfully queued, then we still need * to double-check whether we should have added a thread * (because existing ones died since last checking) or that * the pool shut down since entry into this method. So we * recheck state and if necessary roll back the enqueuing if * stopped, or start a new thread if there are none. * * 3. If we cannot queue task, then we try to add a new * thread. If it fails, we know we are shut down or saturated * and so reject the task. */ int c = ctl.get(); if (workerCountOf(c) &amp;lt; corePoolSize) { if (addWorker(command, true)) return; c = ctl.get(); } if (isRunning(c) &amp;amp;&amp;amp; workQueue.offer(command)) { int recheck = ctl.get(); if (! isRunning(recheck) &amp;amp;&amp;amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); } else if (!addWorker(command, false)) reject(command); } 如果此时线程池中的数量小于corePoolSize，即使线程池中的线程都处于空闲状态，也要创建新的线程来处理被添加的任务。 如果此时线程池中的数量等于 corePoolSize，但是缓冲队列 workQueue未满，那么任务被放入缓冲队列。 如果此时线程池中的数量大于corePoolSize，缓冲队列workQueue满，并且线程池中的数量小于maxPoolSize，那么建新的线程来处理被添加的任务。 如果此时线程池中的数量大于corePoolSize，缓冲队列workQueue满，并且线程池中的数量等于maxPoolSize，那么通过handler所指定的策略来处理此任务。（也就是：处理任务的优先级为：核心线程corePoolSize、任务队列workQueue、最大线程 maxPoolSize，如果三者都满了，使用handler处理被拒绝的任务） 当线程池中的线程数量大于corePoolSize时，如果某线程空闲时间超过keepAliveTime，线程将被终止。这样，线程池可以动态的调整池中的线程数 自定义线程池 自定义线程池有如下模式：
配置由自定义的TaskExecutor 重新实现接口AsyncConfigurer 继承AsyncConfigurerSupport 方式一：自定义TaskExecutor @Configuration public class ExecutorConfiguration { /** * 配置应用访问日志专用线程池 * @return */ @Bean(name = &amp;#34;sodAppLogAsyncExecutor&amp;#34;) public ThreadPoolTaskExecutor asyncExecutor() { ThreadPoolTaskExecutor threadPool = new ThreadPoolTaskExecutor(); threadPool.setThreadNamePrefix(&amp;#34;drs-sodAppLog-&amp;#34;); threadPool.setCorePoolSize(3); threadPool.setMaxPoolSize(4); threadPool.setKeepAliveSeconds(60); threadPool.setQueueCapacity(11); threadPool.setRejectedExecutionHandler(new ThreadPoolExecutor.DiscardPolicy()); //优雅关闭 threadPool.setWaitForTasksToCompleteOnShutdown(true); threadPool.setAwaitTerminationSeconds(60 * 15); return threadPool; } } 方式二：实现AsyncConfigurer /** * 自定义线程池方法二：自定义类，配置默认Executor与默认异步异常处理器 * @author zyg */ @Configuration public class CusAsyncConfigure implements AsyncConfigurer { /** * 配置默认Executor */ @Override public Executor getAsyncExecutor() { ThreadPoolTaskExecutor threadPool = new ThreadPoolTaskExecutor(); threadPool.setThreadNamePrefix(&amp;#34;cus-async-configure-&amp;#34;); threadPool.setCorePoolSize(2); threadPool.setMaxPoolSize(3); threadPool.setKeepAliveSeconds(60); threadPool.setQueueCapacity(5); threadPool.setRejectedExecutionHandler(new ThreadPoolExecutor.DiscardPolicy()); return threadPool; } /** * 配置默认异步异常处理器 */ @Override public AsyncUncaughtExceptionHandler getAsyncUncaughtExceptionHandler() { return new CusAsyncUncaughtExceptionHandler(); } } （原理是ProxyAsyncConfiguration的父类AbstractAsyncConfiguration的setConfigurers(Collection)中执行了AsyncConfigurer的方法来配置Executor与AsyncUncaughtExceptionHandler）
方式三：继承AsyncConfigurerSupport /** * 自定义线程池方法三:继承AsyncConfigurerSupport,重写getAsyncExecutor与getAsyncUncaughtExceptionHandler * @author zyg */ @Configuration public class CusAsyncConfigurerSupport extends AsyncConfigurerSupport { /** * 配置默认Executor */ @Override public Executor getAsyncExecutor() { ThreadPoolTaskExecutor threadPool = new ThreadPoolTaskExecutor(); threadPool.setThreadNamePrefix(&amp;#34;cus-async-configure-support-&amp;#34;); threadPool.setCorePoolSize(2); threadPool.setMaxPoolSize(3); threadPool.setKeepAliveSeconds(60); threadPool.setQueueCapacity(5); threadPool.setRejectedExecutionHandler(new ThreadPoolExecutor.DiscardPolicy()); return threadPool; } /** * 配置默认异步异常处理器 */ @Override public AsyncUncaughtExceptionHandler getAsyncUncaughtExceptionHandler() { return new CusAsyncUncaughtExceptionHandler(); } } （原理是AsyncConfigurerSupport的父类是AsyncConfigurer）
异常处理 如果任务的返回类型是Future，那么将直接抛出异常，否则异常由AsyncUncaughtExceptionHandler的handleUncaughtException()进行处理，Spring自4.1默认提供了SimpleAsyncUncaughtExceptionHandler，该类处理异常的逻辑是通过日志打印错误，如有需要可以自定义类继承AsyncUncaughtExceptionHandler，复写其handleUncaughtException()方法。
/** * 自定义线程池方法二：自定义默认异步异常处理器 * @author zyg */ @Component public class CusAsyncUncaughtExceptionHandler implements AsyncUncaughtExceptionHandler { private Logger logger = LoggerFactory.getLogger(this.getClass()); @Override public void handleUncaughtException(Throwable ex, Method method, Object... params) { logger.error(&amp;#34;自定义异步异常处理器捕捉到异常，&amp;#34;,ex); } } @EnableAsync加载流程 前置知识点 @Import注解的作用 BeanPostProcessor在Spring中的作用 Aware类接口在Spring中的作用 切面与通知的概念与作用 代码分析： @EnableAsync中Import了AsyncConfigurationSelector； AsyncConfigurationSelector的作用是通过配置确定是调用ProxyAsyncConfiguration还是AspectJ的AspectJAsyncConfiguration； 在ProxyAsyncConfiguration的asyncAdvisor()方法可以看到，其中定义了后置处理器AsyncAnnotationBeanPostProcessor AsyncAnnotationBeanPostProcessor直接或间接实现了BeanFactoryAware、BeanPostProcessor两个接口，既然AsyncAnnotationBeanPostProcessor实现了BeanFactoryAware，那么就会执行setBeanFactory(BeanFactory)方法,该方法中设置了切面AsyncAnnotationAdvisor 切面中定义了切点：类上标注@Async、@Asynchronous注解的切点与在方法上标注@Async、@Asynchronous注解的切点 切面中定义了通知：通知Executor与SimpleAsyncUncaughtExceptionHandler， 通知具体的实现类为AnnotationAsyncExecutionInterceptor，它的父类AsyncExecutionInterceptor进行了实际的通知处理操作 配置默认Executor 在生成切面AsyncAnnotationAdvisor对象时，生成了AnnotationAsyncExecutionInterceptor对象，调用了AnnotationAsyncExecutionInterceptor的configure(Supplier,Supplier)方法,在该方法中，调用了getDefaultExecutor(BeanFactory)来寻找默认Executor，查找Executor的优先级如下：
从BeanFactory中查找类型为TaskExecutor的对象 从BeanFactory中查找类型为Executor、Bean名称为taskExecutor的对象 如果上述步骤中找不到，那么子类AsyncExecutionInterceptor中生成SimpleAsyncTaskExecutor对象 通知的处理 通过determineAsyncExecutor(Method)方法查找AsyncExecutor 包装一下任务，当任务出现异常时调用AsyncUncaughtExceptionHandler的handleUncaughtException()处理异常 调用AsyncExecutor的submit()/submitListenable()/CompletableFuture.supplyAsync()等方法提交任务 查找AsyncExecutor AsyncExecutionAspectSupport的determineAsyncExecutor(Method)中查找了AsyncEexcutor，逻辑如下
首先尝试从成员变量Map&amp;lt;Method, AsyncTaskExecutor&amp;gt; executors查找是否存在，如果存在则返回 然后从AsyncExecutionAspectSupport.getExecutorQualifier()获取专属于该Method的AsyncExecutor的Bean名称，如果存在，则向BeanFactory获取类型为Executor、Bean名称为该名称的Executor并返回 从成员变量SingletonSupplier获取，如果存在则返回 如果经过上述几步查找仍然无法找到那么就返回空 如果经过上述几步找到了Executor，判断Executor的类型 如果是AsyncListenableTaskExecutor，将其强制转换为AsyncListenableTaskExecutor后放入到成员变量executors中 如果不是AsyncListenableTaskExecutor，通过TaskExecutorAdapter包装一个concurrentExecutor然后放入到成员变量executors中 异步事务 在@Async标注的方法，同时也适用了@Transactional进行了标注；在其调用数据库操作时，将无法产生事务管理的控制，原因就在于其是基于异步处理的操作。 那该如何给这些操作添加事务管理呢？可以将需要事务管理操作的方法放置到异步方法内部，在内部被调用的方法上添加@Transactional. 例如： 方法A，同时使用了@Async/@Transactional来标注，但是无法产生事务控制的目的。 方法B，使用了@Async来标注， B中调用了方法C、D，方法C、D分别使用@Transactional做了标注，则可实现事务控制的目的。</content></entry><entry><title>Netty架构简介</title><url>https://www.zyg-tech.me/post/netty%E6%9E%B6%E6%9E%84%E7%AE%80%E4%BB%8B/</url><categories><category>Netty</category></categories><tags><tag>高性能组件</tag><tag>代码研究</tag></tags><content type="html"> Netty功能特性如下
1）传输服务：支持 BIO 和 NIO；
2）容器集成：支持 OSGI、JBossMC、Spring、Guice 容器；
3）协议支持：HTTP、Protobuf、二进制、文本、WebSocket 等一系列常见协议都支持。还支持通过实行编码解码逻辑来实现自定义协议；
4）Core 核心：可扩展事件模型、通用通信 API、支持零拷贝的 ByteBuf 缓冲对象。
高性能设计 Netty 作为异步事件驱动的网络，高性能之处主要来自于其 I/O 模型和线程处理模型，前者决定如何收发数据，后者决定如何处理数据
Netty采用的I/O模型为NIO,如下图
Netty采用的线程处理模型为Reactor模型.Reactor 模型中有 2 个关键组成：
1）Reactor：Reactor 在一个单独的线程中运行，负责监听和分发事件，分发给适当的处理程序来对 IO 事件做出反应。它就像公司的电话接线员，它接听来自客户的电话并将线路转移到适当的联系人；
2）Handlers：处理程序执行 I/O 事件要完成的实际事件，类似于客户想要与之交谈的公司中的实际官员。Reactor 通过调度适当的处理程序来响应 I/O 事件，处理程序执行非阻塞操作。
Reactor模型共有3个变种:单 Reactor 单线程、单 Reactor 多线程、主从 Reactor 多线程.
Netty的线程模型是基于主从 Reactors 多线程模型进行修改.
核心组件 Boostrap:客户端程序的启动引导类,主要作用是配置整个 Netty 程序，串联各个组件
ServerBootstrap:服务端启动引导类
ChannelEvent : 因为Netty是基于事件驱动的，ChannelEvent就相当于某一个事件，比如说连接成功时打印一句话
Channel:网络通信的组件，能够用于执行网络 I/O 操作,下面是一些常用的 Channel 类型：
NioSocketChannel，异步的客户端 TCP Socket 连接。 NioServerSocketChannel，异步的服务器端 TCP Socket 连接。 NioDatagramChannel，异步的 UDP 连接。 NioSctpChannel，异步的客户端 Sctp 连接。 NioSctpServerChannel，异步的 Sctp 服务器端连接，这些通道涵盖了 UDP 和 TCP 网络 IO 以及文件 IO。
Selector:通过 Selector 一个线程可以监听多个连接的 Channel 事件。当向一个 Selector 中注册 Channel 后，Selector 内部的机制就可以自动不断地查询Selector中注册的 Channel 是否有已就绪的 I/O 事件（例如可读，可写，网络连接完成等），这样程序就可以很简单地使用一个线程高效地管理多个 Channel
NioEventLoop:NioEventLoop 中维护了一个线程和任务队列，支持异步提交执行任务，线程启动时会调用 NioEventLoop 的 run 方法，执行 I/O 任务和非 I/O 任务
NioEventLoopGroup : 主要管理 eventLoop 的生命周期，可以理解为一个线程池，内部维护了一组线程，每个线程(NioEventLoop)负责处理多个 Channel 上的事件
ChannelHandler : 一个接口，处理 I/O 事件或拦截 I/O 操作，并将其转发到其 ChannelPipeline(业务处理链)中的下一个处理程序。
ChannelHandler 本身并没有提供很多方法，因为这个接口有许多的方法需要实现，方便使用期间，可以继承它的子类：
ChannelInboundHandler 用于处理入站 I/O 事件。 ChannelOutboundHandler 用于处理出站 I/O 操作。
或者使用以下适配器类：
ChannelInboundHandlerAdapter 用于处理入站 I/O 事件。 ChannelOutboundHandlerAdapter 用于处理出站 I/O 操作。 ChannelDuplexHandler 用于处理入站和出站事件。
ChannelPipline : 保存 ChannelHandler 的 List，用于处理或拦截 Channel 的入站事件和出站操作,可以理解为一种高级形式的拦截过滤器模式
ChannelHandlerContext : 保存 Channel 相关的所有上下文信息
组件间关系 当客户端和服务端连接的时候会建立一个 Channel,这个 Channel 我们可以理解为 Socket 连接，它负责基本的 IO 操作，例如：bind（），connect（），read（），write（） 等等,简单的说，Channel 就是代表连接，实体之间的连接，程序之间的连接，文件之间的连接，设备之间的连接。同时它也是数据入站和出站的载体。
EventLoopGroup、EventLoop、Channel关系如下
在 Netty 中每个 Channel 都有且仅有一个 ChannelPipeline 与之对应，它们的组成关系如下：
一个 Channel 包含了一个 ChannelPipeline，而 ChannelPipeline 中又维护了一个由 ChannelHandlerContext 组成的双向链表，并且每个 ChannelHandlerContext 中又关联着一个 ChannelHandler。
入站事件和出站事件在一个双向链表中，入站事件会从链表 head 往后传递到最后一个入站的 handler，出站事件会从链表 tail 往前传递到最前一个出站的 handler，两种类型的 handler 互不干扰。
这些核心组件的整体关系如下
核心工作流程 典型的初始化并启动 Netty 服务端的过程代码如下：
public final class EchoServer { static final boolean SSL = System.getProperty(&amp;#34;ssl&amp;#34;) != null; static final int PORT = Integer.parseInt(System.getProperty(&amp;#34;port&amp;#34;, &amp;#34;8007&amp;#34;)); public static void main(String[] args) throws Exception { // 配置SSL final SslContext sslCtx; if (SSL) { SelfSignedCertificate ssc = new SelfSignedCertificate(); sslCtx = SslContextBuilder.forServer(ssc.certificate(), ssc.privateKey()).build(); } else { sslCtx = null; } // 配置服务端 EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); final EchoServerHandler serverHandler = new EchoServerHandler(); try { ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 100) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChannelInitializer&amp;lt;SocketChannel&amp;gt;() { @Override public void initChannel(SocketChannel ch) throws Exception { ChannelPipeline p = ch.pipeline(); if (sslCtx != null) { p.addLast(sslCtx.newHandler(ch.alloc())); } //p.addLast(new LoggingHandler(LogLevel.INFO)); p.addLast(serverHandler); } }); // Start the server. ChannelFuture f = b.bind(PORT).sync(); // Wait until the server socket is closed. f.channel().closeFuture().sync(); } finally { // Shut down all event loops to terminate all threads. bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } } 基本过程描述如下：
1）初始化创建 2 个 NioEventLoopGroup：其中 boosGroup 用于 Accetpt 连接建立事件并分发请求，workerGroup 用于处理 I/O 读写事件和业务逻辑。
2）基于 ServerBootstrap(服务端启动引导类)：配置 EventLoopGroup、Channel 类型，连接参数、配置入站、出站事件 handler。
3）绑定端口：开始工作。
Netty启动流程图如下
结合上面介绍的 Netty Reactor 模型，介绍服务端 Netty 的工作架构图：
ps:上图中NioEventGroup有误,应为NioEventLoop</content></entry><entry><title>TopN问题解决</title><url>https://www.zyg-tech.me/post/topn%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/</url><categories><category>数据库</category></categories><tags><tag>MySQL</tag><tag>TopN</tag></tags><content type="html"> 需求 将数据分组,每组内取前n条.最常见的需求是取每组内第一条,例如以imei分组,组内取time最新的一条
表结构 create table com( n_id int auto_increment primary key, c_imei varchar(10) null, c_time bigint null, c_name varchar(10) null ); create index com_c_imei_index on com (c_imei); 表数据 INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (1, 'a', 8, '010101'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (2, 'e', 2, '020202'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (3, 'c', 9, '030303'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (4, 'b', 4, '040404'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (5, 'd', 5, '050505'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (6, 'a', 6, '060606'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (7, 'e', 4, '070707'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (8, 'c', 3, '0808080'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (9, 'b', 5, '090909'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (10, 'd', 8, '101010'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (11, 'a', 5, '111111'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (12, 'e', 7, '121212'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (13, 'c', 2, '131313'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (14, 'b', 6, '141414'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (15, 'd', 9, '151515'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (16, 'a', 2, '161616'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (17, 'e', 1, '171717'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (18, 'c', 5, '181818'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (19, 'b', 8, '191919'); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (20, 'd', 7, '202020'); SQL #方法一，自连接 SELECT a.c_imei, a.n_id, a.c_time FROM com a LEFT JOIN com b ON a.c_imei = b.c_imei AND a.c_time &amp;lt; b.c_time WHERE b.c_time IS NULL ORDER BY a.c_imei; #方法一的另一种形式,如果要取每组内前n条，那么将1改成n即可 SELECT n_id, c_imei, c_time, c_name FROM com a WHERE (SELECT count(*) FROM com b WHERE a.c_imei = b.c_imei AND a.c_time &amp;lt; b.c_time) &amp;lt; 1 order by c_imei; #方法二，派生表排序后分组，注意limit必须加不然没用 select n_id, c_imei, c_time, c_name from (select n_id, c_imei, c_time, c_name from com order by c_time desc limit 999999) a group by a.c_imei; #方法三,相关子查询，注意GROUP_CONCAT结果的长度受限于group_concat_max_len，默认1024 SELECT n_id, c_imei, c_time, c_name FROM com WHERE n_id IN (SELECT SUBSTRING_INDEX(GROUP_CONCAT(n_id ORDER BY c_time DESC), ',', 1) FROM com GROUP BY c_imei) ORDER BY c_imei; #方法四,派生表关联查询 select distinct com.n_id, com.c_imei, com.c_time, com.c_name from com join (select c_imei, max(c_time) as ct from com group by c_imei) tmp on com.c_imei = tmp.c_imei and com.c_time = tmp.ct order by com.c_imei; ##方法四优化 select distinct com.n_id, com.c_imei, com.c_time, com.c_name from com right join (select c_imei, max(c_time) as ct from com group by c_imei) tmp on com.c_imei = tmp.c_imei and com.c_time = tmp.ct order by com.c_imei; 其他方法 MySQL8及以上的row_number、rank、dense_rank、over函数</content></entry><entry><title>参数校验</title><url>https://www.zyg-tech.me/post/%E5%8F%82%E6%95%B0%E6%A0%A1%E9%AA%8C/</url><categories><category>校验</category></categories><tags><tag>校验</tag><tag>Spring</tag><tag>HibernateValidate</tag></tags><content type="html"> 作为后台开发人员,为保证数据的有效性与完整性,避免处理前台传递的无效或不完整的信息,会进行后台的数据校验,常用的是Spring中的SpringValidation, 事实上它是对Hibernate Validator的封装,而Hibernate Validator又是对Bean Validation规范的实现,下面我们来较为全面的了解一下关于校验的那点事儿.
1.Bean Validation规范 Bean Validation规范主要用于对 Bean 中的字段的值进行约束定义、描述和验证,截止目前一共有三个版本 : Bean Validation 1.0/1.1/2.0,分别对应 JSR 303/349/380,有兴趣的同学可以到https://www.jcp.org/en/jsr/overview , 根据JSR编号查找相应的规范提案,关于Bean Validation各版本区别可前往https://beanvalidation.org查看。
2.Bean Validation实现 规范离不开相应的实现,Bean Validation的实现有两个 : Hibernate Validator与Apache BVal,Spring Validation就是基于Hibernate Validator封装的,它们都离不开javax Validation,公司也封装了framework-validation供大家使用。
这里介绍一下规范和实现之间的版本关系 :
Bean Validation 1.0 &amp;ndash;&amp;gt; Hibernate Validator 4.3.1与Apache BVal 0.5 Bean Validation 1.1 &amp;ndash;&amp;gt; Hibernate Validator 5.1.1与Apache BVal 1.1.2 Bean Validation 2.0 &amp;ndash;&amp;gt; Hibernate Validator 6.0.1 Bean Validation 主要提供了以下验证规则(javax.validation.constraints): 1)AssertFalse : 验证 Boolean 对象是否为 true 2)AssertTrue : 验证 Boolean 对象是否为 false 3)DecimalMax : 被标注的值必须不大于约束中指定的最大值(含精度) 4)DecimalMin : 被标注的值必须不小于约束中指定的最小值(含精度) 5)Digits : 验证 Number 和 String 的构成是否合法 6)Future : 验证 Date 和 Calendar 对象是否在当前时间之后 7)Max : 验证 Number 和 String 对象是否小等于指定的值 8)Min : 验证 Number 和 String 对象是否大等于指定的值 9)NotNull : 验证对象是否不为null 10)Null : 验证对象是否为null 11)Past : 验证 Date 和 Calendar 对象是否在当前时间之前 12)Pattern : 验证 Date 和 Calendar 对象是否在当前时间之后 13)Size : 验证CharSequence/Collection/Map/Array对象长度是否在给定的范围之内
Hibernate Validator在javax.validation的基础上增加了以下验证规则(org.hibernate.validator.constraints): 1)CreditCardNumber : 信用卡验证 2)EAN : 验证是否为EAN-13的商品用条码 3)Email : 邮箱地址验证 4)Length : 验证字符串长度 5)LuhnCheck : 验证是否符合模10算法的规则,例如大多数银行卡号编码规则采用了模10算法,前往https://en.wikipedia.org/wiki/Luhn_algorithm#cite_note-0 参考该算法 6)Mod10Check : 验证是否符合Mod10算法 7)Mod11Check : 验证是否符合Mod11算法 8)NotBlank : 检查约束字符串是不是Null还有被Trim的长度是否大于0,只对字符串,且会去掉前后空格 9)NotEmpty : 检查约束元素是否为NULL或者是EMPTY 10)ParameterScriptAssert : 使用脚本进行验证 11)Range : 校验数字或表示数字的字符串的取值范围 12)SafeHtml : 校验是否包含恶意脚本 13)ScriptAssert : 调用静态方法验证 14)URL : 校验是否是合法的URL
Spring Validation没有增加额外的验证规则,而是着重于通过BeanPostProcesser、Interceptor等在接收HTTP请求处理参数时进行参数校验,并封装了验证结果如BindingResult、Errors等,方便开发者使用。
3.Bean Validation实践 3.1 javax Validation原生基础用法 Maven地址
&amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;javax.validation&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;validation-api&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;1.1.0.Final&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; 实体类
public class FlowLearning { @NotNull private Long id; //other properties } 校验方法
Validator validator = Validation.buildDefaultValidatorFactory().getValidator(); Set&amp;lt;ConstraintViolation&amp;lt;Object&amp;gt;&amp;gt; resultSet = validator.validate(flowLEarning,FlowLearning.class); if (!CollectionUtils.isEmpty(resultSet)) { throw new IllegalArgumentException(resultSet.toString()); } javax.validation.Validator为验证对象提供了三个方法 1)Set&amp;lt;ConstraintViolation&amp;gt; validate(T object, Class&amp;lt;?&amp;gt;&amp;hellip; groups) &amp;ndash;&amp;gt;验证一个给定的对象 2)Set&amp;lt;ConstraintViolation&amp;gt; validateProperty(T object, String propertyName, Class&amp;lt;?&amp;gt;&amp;hellip;groups) &amp;ndash;&amp;gt;验证给定对象中的字段或者属性 3)Set&amp;lt;ConstraintViolation&amp;gt; validateValue(ClassbeanType, String propertyName, Object value, Class&amp;lt;?&amp;gt;&amp;hellip; groups) &amp;ndash;&amp;gt;验证给定对象中的属性的具体值
3.2 spring validation 注解校验 略
3.3 @ScriptAssert校验复杂的业务逻辑 实体类
@Getter @Setter // @ScriptAssert的lang指脚本语言,script中的方法名需要完全限定名 @ScriptAssert(lang = &amp;quot;javascript&amp;quot;, script = &amp;quot;com.xdja.oa.nyingchi.admin.User.mockScriptAssert(_this.position,_this.amount)&amp;quot;) public class User { private String position; private Integer amount; public static boolean mockScriptAssert(String position,Integer amount){ if(StringUtils.isEmpty(position) || amount == null || amount &amp;lt;0){ return false; }else { return true; } } } 校验方法
@RequestMapping(value = &amp;quot;script&amp;quot;, method = RequestMethod.POST) public ResponseMsg scripts(@Validated @RequestBody User user, BindingResult bindingResult){ if(bindingResult.hasErrors()){ throw new IllegalArgumentException(&amp;quot;参数不合法&amp;quot;); }else{ //校验成功,处理业务逻辑 } return ResponseMsg.success(); } @ScriptAssert中的lang属性指的是哪种脚本语言,要查看当前jdk版本所支持的脚本语言,可以通过如下代码获取
ScriptEngineManager scriptEngineManager = new ScriptEngineManager(); List&amp;lt;ScriptEngineFactory&amp;gt; engineFactories = scriptEngineManager.getEngineFactories(); if(engineFactories.size() == 0) { System.out.println(&amp;quot;本JVM尚不支持任何脚本引擎&amp;quot;); return; } System.out.println(&amp;quot;本JVM支持的脚本引擎有:&amp;quot;); for(ScriptEngineFactory engineFactory : engineFactories) { System.out.println(&amp;quot;引擎名称:&amp;quot; + engineFactory.getEngineName()); System.out.println(&amp;quot;\t可被ScriptEngineManager识别的名称:&amp;quot; + engineFactory.getNames()); System.out.println(&amp;quot;\t该引擎支持的脚本语言名称:&amp;quot; + engineFactory.getLanguageName()); System.out.println(&amp;quot;\t是否线程安全:&amp;quot; + engineFactory.getParameter(&amp;quot;THREADING&amp;quot;)); } 3.4 原生自定义Validator 自定义注解
@Target( { METHOD, FIELD, ANNOTATION_TYPE }) @Retention(RUNTIME) @Documented @Constraint(validatedBy = CheckStringValidator.class) public @interface CheckString { String message() default &amp;quot;字符串校验失败！请少侠重新来过~&amp;quot;; Class&amp;lt;?&amp;gt;[] groups() default {}; Class&amp;lt;? extends Payload&amp;gt;[] payload() default {}; CheckType checkType() ; } 注解中的枚举
public enum CheckType { EMPTY,NOT_EMPTY } 注解校验器
public class CheckStringValidator implements ConstraintValidator&amp;lt;CheckString,String&amp;gt; { private CheckType checkType; @Override public void initialize(CheckString constraintAnnotation) { this.checkType = constraintAnnotation.checkType(); } @Override public boolean isValid(String string, ConstraintValidatorContext context) { if(string == null || checkType == null){ return false; }else{ boolean result = false; switch(checkType){ case NOT_EMPTY : result = !StringUtils.isEmpty(string); break; case EMPTY: result = StringUtils.isEmpty(string); break; default: break; } return result; } } } 实体类
@Getter @Setter public class User { @CheckString(checkType = CheckType.NOT_EMPTY) private String position; } 校验
@RequestMapping(value = &amp;quot;script&amp;quot;, method = RequestMethod.POST) public ResponseMsg scripts(@Valid @RequestBody User user, BindingResult bindingResult){ if(bindingResult.hasErrors()){ throw new IllegalArgumentException(&amp;quot;参数不合法&amp;quot;); }else{ System.out.println(&amp;quot;校验成功&amp;quot;); } } 3.5 校验模式 日常开发中进行的校验大多只要某字段校验失败就视为校验失败无需继续校验了，为此，可以设置校验模式为FastFail.
HibernateValidatorConfiguration configuration = Validation.byProvider( HibernateValidator.class ).configure(); ValidatorFactory factory = configuration.addProperty( &amp;quot;hibernate.validator.fail_fast&amp;quot;, &amp;quot;true&amp;quot; ).buildValidatorFactory(); Validator validator = factory.getValidator(); 级联验证目前使用较少,不再介绍。</content></entry><entry><title>汇报搜索优化历程</title><url>https://www.zyg-tech.me/post/%E6%B1%87%E6%8A%A5%E6%90%9C%E7%B4%A2%E4%BC%98%E5%8C%96%E5%8E%86%E7%A8%8B/</url><categories><category>实战</category></categories><tags><tag>ES</tag><tag>搜索</tag></tags><content type="html"> 1.背景介绍 OA中存在工作汇报与汇报审批两个应用，前者用于员工填写汇报，如日报、周报、月报、会议纪要等，后者用于领导查阅员工填写的汇报，在查阅汇报时提供搜索功能，可根据关键字对汇报内容进行搜索。
1.1 表关系 搜索汇报相关的数据表表结构如下
t_report(汇报主表,存储员工填写的汇报记录,与t_report_value为一对多关系) 字段名 字段类型 字段说明 n_id bigint(20) 主键 n_account_id bigint(20) 人员id n_modify_time bigint(20) 修改时间 n_report_date bigint(20) 汇报日期 n_status bigint(20) 数据状态,0正常,1已删除 其他字段…. t_report_value(汇报子表,存储员工填写的汇报记录详情) 字段名 字段类型 字段说明 n_id bigint(20) 主键 n_report_id bigint(20) 汇报id，等同t_report的n_id n_moudle_id bigint(20) 模板id n_moudle_widget_id bigint(20) 模板的控件id c_widget_value varchar(12380) 汇报的内容 其他字段…. t_report_moudle(汇报模板表,存储汇报使用的模板,与t_report_widget为一对多关系) n_id bigint(20) 主键 c_name varchar(255) 模板名称 其他字段… t_report_widget(汇报控件表,存储汇报使用的模板中的控件) n_id bigint(20) 主键 n_moudle_id bigint(20) 模板id,等同t_report_moudle的n_id c_title varchar(20) 控件名,如标题、内容、本周总结、本月计划 n_value_limt int(8) 控件值长度限制,如标题最大长度、内容最大长度 其他字段…. 1.2 数据增长速度 模板表与模板控件表的数量增长较慢，数据增长主要为汇报主表与汇报子表，每天两表的数据增长速度大致如下
t_report：1 * 员工数
t_report_value : 1 * 员工数 * 模板数 * 控件数
1.3 搜索流程 搜索功能流程如下：
A接收请求
B查询当前人管辖的人员列表
C查询当前人能够查看的模板id列表
D将前两步的结果、关键词、分页参数等一起作为条件，搜索符合条件的汇报
E包装汇报的其他数据(如汇报的浏览数量、汇报的附件数量)
F返回数据
2.阶段A – MySQL like查询 在应用运行初期，由于汇报数据少，数据增长速度慢，且对搜索接口未提出其他方面的要求，因此采用like模糊查询符合条件的汇报数据，核心SQL如下
SELECT
DISTINCT t1.n_id AS id,
t1.n_create_time AS createTime,
t1.n_modify_time AS modifyTime,
t1.n_account_id AS accountId,
t1.c_coordinate AS coordinate,
t1.c_at_ids AS atIds,
t1.n_report_date AS reportDate
FROM
t_report t1
LEFT JOIN t_report_value brmwv ON t1.n_id = brmwv.n_report_id
WHERE
brmwv.c_widget_value like &amp;lsquo;%:1%&amp;rsquo;
AND brmwv.n_employee_id IN(:2)
AND brmwv.n_moudle_id IN(:3)
AND t1.n_delete_flag = 0
AND t1.n_modify_time &amp;lt; :4
ORDER BY
t1.n_report_date DESC,
t1.n_modify_time DESC LIMIT 0, :5
##:1为关键词,:2为人员列表,:3为模块列表,:4为分页参数,:5为分页条数
方案优点：无需额外改动
方案缺点：数据量多时效率低
3.阶段B - MySQL 全文索引 以公司环境为例，应用运行一年后，汇报主表的数据量大约为33w条(330天* 1000员工),汇报子表的数据量为33w条(330天 * 1000 员工 * 1个模板 * 1个控件),这时候搜索接口的查询汇报SQL平均速度为10S+，like搜索方案的主要瓶颈在于like搜索进行全表扫描，于是考虑在c_widget_value字段中建立索引来提高搜索速度，由于c_widget_value大部分为中文字符,因此需要在该字段建立全文索引并支持对中文的搜索。
经查阅资料，MySQL中的全文索引自v5.6.24开始支持InnoDB引擎，自v5.7开始增加ngram分词器以支持中日韩文，全文索引支持的数据库字段类型为char、varchar、text，于是此方案在MySQL中执行以下语句即可:
create fulltext index vfin on t_ report _value (c_widget_value) with parser ngram;
建立全文索引后SQL需要进行相应的改写，使用match against ，改写后的SQL如下
SELECT
DISTINCT t1.n_id AS id,
t1.n_create_time AS createTime,
t1.n_modify_time AS modifyTime,
t1.n_account_id AS accountId,
t1.c_coordinate AS coordinate,
t1.c_at_ids AS atIds,
t1.n_report_date AS reportDate
FROM
t _report t1
LEFT JOIN t_ report_ value brmwv ON t1.n_id = brmwv.n_report_id
WHERE
match(c_widget_value) against (':1&amp;rsquo;)
AND brmwv.n_employee_id IN(:2)
AND brmwv.n_moudle_id IN(:3)
AND t1.n_delete_flag = 0
AND t1.n_modify_time &amp;lt; :4
ORDER BY
t1.n_report_date DESC,
t1.n_modify_time DESC LIMIT 0, :5
##:1为关键词,:2为人员列表,:3为模块列表,:4为分页参数,:5为分页条数
在使用该方案时发现接口整体速度确实有了提升，但是当输入的关键词为单个字符或两个字符时无法查询到数据，于是继续查阅相关资料，得到以下信息：MySQL中的innodb_ft_min_token_size配置项表示全文索引最小分词长度,该值默认为3。于是将该配置项的值修改为1，重建了全文索引并重启MySQL，再次搜索时输入任意个字符均可搜索到相关数据。
方案时间：SQL平均时间2s，整体接口平均时间8s
方案优点：SQL查询效率提高
方案缺点：建立了索引额外占据了空间、对该表的CRUD都将降低响应速度、ngram分词粒度越细那么占据空间越大、修改MySQL的全文索引配置项后需要重建全文索引并重启MySQL才能生效、输入的关键词长度增加时SQL响应速度呈指数级增长。
4.阶段C - ElasticSearch + MySQL 全文索引方案与like方案相比，的确提升了SQL的响应速度，但是SQL响应速度受关键词影响极大，若输入的关键词长度过长，或输入的关键词几乎匹配了数据库中绝大部分数据，那么该接口的整体响应速度仍然堪忧；建立全文索引后，对t_ report_ value进行操作时响应速度将会有所降低；数据进一步增长时SQL速度将进一步变慢，在百万级以上时表现不佳；ngram分词器的分词规则不够灵活，导致分词后的索引占据空间很大。
一想到大数据量秒级响应，那么ElasticSearch会作为首选项。加上搜索接口对数据实时性要求不高，因此可以将汇报主表与汇报子表的数据存储在ElasticSearch中，对c_widget_value使用ik_smart进行分词存储，并定时更新ES数据，查询时从ES查询数据，然后再进行接口内其他业务操作。
由于ES并不擅长关联操作，于是该方案设计为OA后台执行定时任务，将汇报主表与汇报子表的数据增量整合为一张表t_report_sync_data,再通过LogStash将MySQL中表t_report_sync_data的数据增量同步到ES中。
记表t_ report为表A(汇报主表), t_report_value为表B(汇报子表), t _report_moudle(汇报模板表)为 C，以下是t_report_sync_data中各字段与这些表的对应关系
字段名 原始表 原始字段 说明 reportId report n_id 汇报id createTime report n_create_time 汇报创建时间 modifyTime report n_modify_time 汇报修改时间 accountId report n_account_id 人员id coordinate report c_coordinate 坐标 atds report c_at_ids 艾特的人员id集合 deleteFlag report n_delete_flag 删除标识 companyId report n_company_id 企业id reportDate report n_report_date 汇报日期 moduleId reportValue n_module_widget_id 模块id widgetValue reportValue c_widget_value 控件值 那么查询时的SQL就改变为了ES的查询语句，Java代码如下
// 条件构建
BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();
//widgetValue,模糊查询
BoolQueryBuilder builder = QueryBuilders.boolQuery();
builder.should(QueryBuilders.matchPhraseQuery(&amp;ldquo;widgetValue&amp;rdquo;, queryBean.getWidgetValue()));
boolQueryBuilder.must(builder);
//accountId,in
boolQueryBuilder.filter(inParamBuilder(queryBean.getAccountIds(), &amp;ldquo;accountId&amp;rdquo;));
//moudleId, in
boolQueryBuilder.filter(inParamBuilder(queryBean.getMoudleIds(), &amp;ldquo;moudleId&amp;rdquo;));
//deleteFlag,0
boolQueryBuilder.filter(QueryBuilders.termQuery(&amp;ldquo;deleteFlag&amp;rdquo;, 0));
//modifyTime,&amp;lt;
RangeQueryBuilder rangeQuery = QueryBuilders.rangeQuery(&amp;ldquo;modifyTime&amp;rdquo;);
rangeQuery.lt(queryBean.getModifyTime());
boolQueryBuilder.filter(rangeQuery);
//聚合请求构建
//按reportId分桶,按reportDate降序,按modifyTime降序,取前n桶 TermsBuilder termsBuilder = AggregationBuilders .terms(&amp;ldquo;group_by_reportId&amp;rdquo;) .field(&amp;ldquo;reportId&amp;rdquo;) .subAggregation(AggregationBuilders.max(&amp;ldquo;sortA&amp;rdquo;).field(&amp;ldquo;reportDate&amp;rdquo;)) .subAggregation(AggregationBuilders.max(&amp;ldquo;sortB&amp;rdquo;).field(&amp;ldquo;modifyTime&amp;rdquo;)) . order(Terms.Order.compound(Terms.Order.aggregation(&amp;ldquo;sortA&amp;rdquo;,false),Terms.Order.aggregation(&amp;ldquo;sortB&amp;rdquo;,false))) .size(queryBean.getPageSize());
//设置每组内取一条数据
TopHitsBuilder hitsBuilder = AggregationBuilders.topHits(&amp;ldquo;groupDataDetail&amp;rdquo;).setSize(1);
//每组内, 设置查询的字段
hitsBuilder.setFetchSource(WORK_REPORT_FIELDS, null);
termsBuilder.subAggregation(hitsBuilder);
//将分组挂靠在查询请求内,size设置es hit的原始数据,由于业务系统一般不需要,故设置不返回此项
requestBuilder.addAggregation(termsBuilder).setSize(0);
//设置Query并获取响应
SearchResponse searchResponse = requestBuilder.setQuery(boolQueryBuilder).execute().actionGet();
//处理响应,略
//inParamBuilder方法如下，用于解决同一个字段的terms的参数过多问题
private QueryBuilder inParamBuilder(List list, String field) { int count = 800; int len = list.size(); int size = len % count == 0 ? len / count : (len / count) + 1; BoolQueryBuilder shouldQuery = QueryBuilders.boolQuery(); for (int i = 0; i &amp;lt; size; i++) { int fromIndex = i * count; int toIndex = Math.min(fromIndex + count, len); List subList = list.subList(fromIndex, toIndex); TermsQueryBuilder termsQueryBuilder = QueryBuilders.termsQuery(field, subList); shouldQuery.should(termsQueryBuilder); } return shouldQuery; }
ES的DSL语句如下
{
&amp;ldquo;size&amp;rdquo; : 0,
&amp;ldquo;query&amp;rdquo; : {
&amp;ldquo;bool&amp;rdquo; : {
&amp;ldquo;must&amp;rdquo; : {&amp;ldquo;bool&amp;rdquo; : {&amp;ldquo;should&amp;rdquo; : {&amp;ldquo;match&amp;rdquo; : {&amp;ldquo;widgetValue&amp;rdquo; : {&amp;ldquo;query&amp;rdquo; : &amp;ldquo;工作汇报&amp;rdquo;,&amp;ldquo;type&amp;rdquo; : &amp;ldquo;phrase&amp;rdquo;}}}}},
&amp;ldquo;filter&amp;rdquo; : [
​ {&amp;ldquo;bool&amp;rdquo; : {&amp;ldquo;should&amp;rdquo; : {&amp;ldquo;terms&amp;rdquo; : {&amp;ldquo;moudleId&amp;rdquo; : [ 1, 2, 3, 4, 5 ]}}}},
​ {&amp;ldquo;term&amp;rdquo; : {&amp;ldquo;deleteFlag&amp;rdquo; : 0}},
​ {&amp;ldquo;range&amp;rdquo; : {&amp;ldquo;modifyTime&amp;rdquo; : {&amp;ldquo;from&amp;rdquo; : null,&amp;ldquo;to&amp;rdquo; : 1554180590383,&amp;ldquo;include_lower&amp;rdquo; : true,&amp;ldquo;include_upper&amp;rdquo; : false}} } ]}
},
&amp;ldquo;aggregations&amp;rdquo; : {
&amp;ldquo;group_by_reportId&amp;rdquo; : {
&amp;ldquo;terms&amp;rdquo; : {
​ &amp;ldquo;field&amp;rdquo; : &amp;ldquo;reportId&amp;rdquo;,&amp;ldquo;size&amp;rdquo; : 200,&amp;ldquo;order&amp;rdquo; : [ {&amp;ldquo;sortA&amp;rdquo; : &amp;ldquo;desc&amp;rdquo;}, {&amp;ldquo;sortB&amp;rdquo; : &amp;ldquo;desc&amp;rdquo;}, {&amp;quot;_term&amp;rdquo; : &amp;ldquo;asc&amp;rdquo;} ]},
&amp;ldquo;aggregations&amp;rdquo; : {
​ &amp;ldquo;sortA&amp;rdquo; : {&amp;ldquo;max&amp;rdquo; : {&amp;ldquo;field&amp;rdquo; : &amp;ldquo;reportDate&amp;rdquo;}},
​ &amp;ldquo;sortB&amp;rdquo; : {&amp;ldquo;max&amp;rdquo; : {&amp;ldquo;field&amp;rdquo; : &amp;ldquo;modifyTime&amp;rdquo;}},
​ &amp;ldquo;groupDataDetail&amp;rdquo; : {&amp;ldquo;top_hits&amp;rdquo; : {&amp;ldquo;size&amp;rdquo; : 1, &amp;ldquo;_source&amp;rdquo; : {&amp;ldquo;includes&amp;rdquo; : [ &amp;ldquo;accountId&amp;rdquo;, &amp;ldquo;atIds&amp;rdquo;, &amp;ldquo;companyId&amp;rdquo;, &amp;ldquo;coordinate&amp;rdquo;, &amp;ldquo;createTime&amp;rdquo;, &amp;ldquo;deleteFlag&amp;rdquo;, &amp;ldquo;modifyTime&amp;rdquo;, &amp;ldquo;moudleId&amp;rdquo;, &amp;ldquo;reportDate&amp;rdquo;, &amp;ldquo;widgetValue&amp;rdquo; ],
​ &amp;ldquo;excludes&amp;rdquo; : [ ]} }}}}}}
经测试，该方案中ES环节所需时间稳定在0.8s左右，接口整体速度在1-6s。
优点：速度进一步提升且响应时间比较稳定
缺点：汇报相关的其他数据仍存储在MySQL中，整体接口瓶颈变为查询汇报其他数据时的速度过慢。
5.阶段D - ElasticSearch + Redis + MySQL 对整体接口相关数据进一步分析，根据数据修改频繁程度，可以将数据进行冷热分离，将修改频率较低的数据,如汇报主表与汇报子表，存储在ES中，并通过LogStash定时增量更新；将高频修改数据(如汇报的浏览数量)存储在Redis中，这样将会进一步提升搜索的响应速度。</content></entry><entry><title>MySQL全文索引使用</title><url>https://www.zyg-tech.me/post/mysql%E5%85%A8%E6%96%87%E7%B4%A2%E5%BC%95/</url><categories><category>MySQL</category></categories><tags><tag>MySQL</tag><tag>数据库</tag><tag>全文索引</tag></tags><content type="html"> 1.简介 在Web应用中,经常会遇到按照关键字进行模糊搜索的需求,当参数搜索的数据量较少时,我们一般使用like进行搜索,但是当数据量达到一定程度后,like方式的速度就会很慢很慢,这时候我们可以借助一些全文搜索的组件来实现需求.MySQL就提供了全文索引来支持模糊搜索.
2.限制条件 2.1引擎限制 MySQL 5.6 以前的版本，只有 MyISAM 存储引擎支持全文索引；
MySQL 5.6 及以后的版本，MyISAM 和 InnoDB 存储引擎均支持全文索引
2.2版本号限制 Mysql自v5.6.24版本开始在InnoDB引擎中增加全文索引功能，支持对英文的全文搜索,默认以空格作为分隔符;自v5.7版本开始增加ngram分词器以支持中文
2.3字段类型限制 全文索引支持的字段类型为char、varchar、text等这些基于文本的列
2.4连表限制 全文搜索仅支持在同一张表中进行,不支持对多张表中的关键字进行全文搜索
3.准备索引 我们以report表为例
-- 准备表 create table report ( id int auto_increment primary key, content varchar(1000) null ); -- 在content字段创建普通的全文索引 create fulltext index content_fti on report(content); -- 在content字段创建支持中文的全文索引 create fulltext index content_fti on report(content) WITH PARSER ngram; -- 删除索引,方式一 drop index content_fti on report; -- 删除索引,方式二 alter table report drop index content_fti; 4.准备配置 ​ 使用全文索引搜索时,搜索引擎受全文搜索的单词长度影响,如果关键词长度小于该配置项,那么将无法搜索出相匹配的结果,通过命令可以查看出相关配置项
-- 查看全文搜索配置 show variables like &amp;#39;%ft%&amp;#39;; -- 命令执行结果 // MyISAM:关键词最小长度默认4字符,最大长度84字符 ft_min_word_len = 4; ft_max_word_len = 84; // InnoDB:关键词最小长度默认3字符,最大长度84字符 innodb_ft_min_token_size = 3; innodb_ft_max_token_size = 84; 我们以常用的Innodb引擎为例,在MySQL的配置文件中修改配置项
[mysqld] innodb_ft_min_token_size = 1 ft_min_word_len = 1 修改后需要重启MySQL,然后修复全文索引(可以删除索引然后重新建立索引,如果是MyIsam引擎,也可以执行repair命令修复)
然而对于使用了ngram的全文索引来讲,它的全文搜索单词长度配置会忽略上述四个配置项,真正生效的为配置项ngram_token_size(默认2),可以通过在MySQL的配置文件中修改以下配置项或启动时追加参数&amp;ndash;ngram_token_size=1来实现对该配置项的修改
[mysqld] ngram_token_size=1 同样的,修改此项后需要重建全文索引
5.准备数据 略
6.使用索引 与like不同,全文索引的搜索需要使用match agnist,示例如下
select * from report where match(content) against('测试关键词'); match agnist本身还会返回非负浮点数作为搜索的结果行与关键词的相关度.除了match agnist的基础使用,全文搜索还支持以不同的检索模式进行搜索,常用的全文检索模式有两种： 1、自然语言模式(NATURAL LANGUAGE MODE) ， 自然语言模式是MySQL 默认的全文检索模式。自然语言模式不能使用操作符，不能指定关键词必须出现或者必须不能出现等复杂查询。当sql中指定了IN NATURAL LANGUAGE MODE修饰符或未给出修饰符，则全文搜索是自然语言搜索模式 。 2、BOOLEAN模式(BOOLEAN MODE) BOOLEAN模式可以使用操作符，可以支持指定关键词必须出现或者必须不能出现或者关键词的权重高还是低等复杂查询。
6.1自然语言检索模式 ​ 在该模式下,可以指定IN NATURAL LANGUAGE MOD,也可以不指定修饰符,下面给出一个按照结果行相关度倒序排列的SQL示例
select *,match(content) against(&amp;#39;一切&amp;#39;) as score from report where match(content) against(&amp;#39;一切&amp;#39;) order by score desc; 6.2布尔检索模式 MySQL可以使用IN BOOLEAN MODE修饰符执行布尔型全文本搜索 。在这种模式下,支持通过一些正则来进行高级搜索,布尔模式下支持以下操作符：
“+”表示必须包含 “-”表示必须排除 “&amp;gt;”表示出现该单词时增加相关性 “&amp;lt;”表示出现该单词时降低相关性 “*”表示通配符 “~”允许出现该单词，但是出现时相关性为负 “&amp;quot;&amp;quot;”表示短语 下面给出一些示例 'apple banana' ## 无操作符，表示或，要么包含apple，要么包含banana '+apple +juice' ## 必须同时包含两个词apple和juice '+apple macintosh' ## 必须包含apple，但是如果也包含macintosh的话，相关性会更高。 '+apple -macintosh' ## 必须包含apple，同时不能包含macintosh。 '+apple ~macintosh' ## 必须包含apple，但是如果也包含macintosh的话，相关性要比不包含macintosh的记录低。 '+apple +(&amp;gt;juice &amp;lt;pie)' ## 查询必须包含apple和juice或者apple和pie的记录，但是apple juice的相关性要比apple pie高。 'apple*' ## 查询包含以apple开头的单词的记录，如apple、apples、applet。 '&amp;quot;some words&amp;quot;' ## 使用双引号把要搜素的词括起来，效果类似于like '%some words%'， 例如“some words of wisdom”会被匹配到，而“some noise words”就不会被匹配。 7.InnoDB引擎的相关性 InnoDB引擎的全文索引基于Sphinx,算法基于BM-25和TF-IDF,InnoDB使用“术语频率-逆文档频率” （TF-IDF）加权系统的变体对给定的全文搜索查询对文档的相关性进行排名,单词出现在文档中的频率越高，单词出现在文档集合中的频率越低，文档的排名就越高。
7.1相关性排名的计算方式 术语频率（TF）值是单词在文档中出现的次数。IDF单词的逆文档频率（）值是使用以下公式计算的，其中 total_records是集合中matching_records的记录数，并且是搜索词出现的记录数。
${IDF} = log10( ${total_records} / ${matching_records} ) 当文档多次包含一个单词时，IDF值将乘以TF值：
${TF} * ${IDF} 使用TF和IDF 值，使用以下公式计算文档的相关性等级：
${rank} = ${TF} * ${IDF} * ${IDF} 8.停止词 可以通过配置停止词来禁止某些词语参与全文索引,详细使用见全文停用词
9.InnoDB分词原理 InnoDB 全文索引具有倒排索引设计。倒排索引存储一个单词列表，对于每个单词，存储单词出现的文档列表。为了支持邻近搜索，每个单词的位置信息也作为字节偏移量存储。
创建全文索引时,MySQL将创建一组表用于辅助
## 查看索引表 SELECT table_id, name, space from INFORMATION_SCHEMA.INNODB_SYS_TABLES WHERE name LIKE 'test/%'; ## 命令执行结果 424 test/FTS_000000000000006b_0000000000000388_INDEX_1 423 425 test/FTS_000000000000006b_0000000000000388_INDEX_2 424 426 test/FTS_000000000000006b_0000000000000388_INDEX_3 425 427 test/FTS_000000000000006b_0000000000000388_INDEX_4 426 428 test/FTS_000000000000006b_0000000000000388_INDEX_5 427 429 test/FTS_000000000000006b_0000000000000388_INDEX_6 428 430 test/FTS_000000000000006b_BEING_DELETED 429 431 test/FTS_000000000000006b_BEING_DELETED_CACHE 430 432 test/FTS_000000000000006b_CONFIG 431 433 test/FTS_000000000000006b_DELETED 432 434 test/FTS_000000000000006b_DELETED_CACHE 433 107 test/report 93 前六个表代表反向索引，并称为辅助索引表。对传入文档进行标记时，各个单词（也称为 “标记”）与位置信息和关联的文档ID（DOC_ID）一起插入索引表中。根据单词第一个字符的字符集排序权重，单词在六个索引表中得到完全排序和分区。
倒排索引分为六个辅助索引表，以支持并行索引创建。默认情况下，两个线程对索引表中的单词和相关数据进行标记化，排序和插入。线程数可以使用该innodb_ft_sort_pll_degree 选项配置 。FULLTEXT在大型表上创建索引时，请考虑增加线程数 。
辅助索引表名称以前缀 FTS_和后缀 INDEX_*。每个索引表通过索引表名称中与table_id索引表的匹配的十六进制值与索引表相关联。例如，table_id所述的 test/opening_lines表是 327，为此，十六进制值是0x147。如前面的示例所示，十六进制值“ 147 ”出现在与该test/opening_lines表关联的索引表的名称中。</content></entry><entry><title>Docker MySQL部署</title><url>https://www.zyg-tech.me/post/docker-mysql%E9%83%A8%E7%BD%B2/</url><categories><category>MySQL</category></categories><tags><tag>MySQL</tag><tag>Docker</tag></tags><content type="html"> 前提 安装docker,mac环境下可直接安装docker Desktop
拉取 #拉取5.7版本的mysql镜像 docker push mysql:5.7
运行 docker run -p 13306:3306 \ --name d-mysql-57 \ -e MYSQL_ROOT_PASSWORD=Mo20100528 \ -v /Users/zyg/softs/docker/mysql57/data:/var/lib/mysql \ -v /Users/zyg/softs/docker/mysql57/logs:/var/log/mysql \ -v /Users/zyg/softs/docker/mysql57/conf/my.cnf:/etc/my.cnf \ -d mysql:5.7 参数说明:
run　run 是运行一个容器 -d　表示后台运行 -p　表示容器内部端口和服务器端口映射关联 &amp;ndash;privileged=true　设值MySQL 的root用户权限, 否则外部不能使用root用户登陆 -v 容器内的路径(如/etc/mysql)挂载到宿主机 -e MYSQL_ROOT_PASSWORD=xxx 设置MySQL数据库root用户的密码 &amp;ndash;name 设值容器名称为mysql mysql:5.7 表示从docker镜像mysql:5.7中启动一个容器 &amp;ndash;character-set-server=utf8mb4 &amp;ndash;collation-server=utf8mb4_general_ci 设值数据库默认编码 停止上面启动的容器,容器名字为&amp;quot;d-mysql-57&amp;rdquo;
docker stop d-mysql-57 配置账户 ##进入容器
docker exec -it d-mysql-57 bash ##登录MySQL
``mysql -uroot -p` ##创建用户,名叫test,密码是test123,开启远程访问权限
GRANT ALL PRIVILEGES ON *.* TO 'test'@'%' IDENTIFIED BY 'test123' WITH GRANT OPTION; ##创建数据库,名叫xxx
create database xxx; 之后便可以通过该用户执行业务脚本</content></entry></search>