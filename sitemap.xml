<search><entry><title>Redis常见面试题</title><url>https://www.zyg-tech.me/post/redis%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/</url><categories><category>Redis</category><category>NoSQL</category><category>数据库</category></categories><tags><tag>Redis</tag><tag>中间件</tag><tag>NoSQL</tag><tag>数据库</tag></tags><content type="html"> 原理篇 如何理解Redis的通讯协议resp协议 如何理解Redis的cluster bus的gossip协议 为什么早期版本Redis是单线程的 Redis为什么速度快 Redis的主从复制原理是什么 Redis如何划分内存 Redis的存储细节 Redis如何实现渐进式hash进行扩容 Redis事务的CAS 基础篇 Redis都有哪些基础的数据结构 Redis有哪些高级的数据结构，对应的使用场景是什么 Redis如何做到数据持久化，这些方式各自有什么优缺点 Redis AOF持久化的触发条件有哪些 Redis慢查询如何开启 Redis的默认内存为多大 Redis的淘汰策略有哪些 Redis的过期策略有哪些，这些删除策略各自有什么优缺点 Redis的Pipeline如何理解 Redis如何设置过期时间 Redis支持哪些集群模式 实战篇 Redis有哪些常用场景 如何理解缓存穿透、缓存击穿、缓存雪崩、缓存预热 Redis内存使用满会出现什么现象 Redis如何实现定时队列 Redis如何实现消息队列 Redis如何实现异步队列 Redis的并发竞争如何解决 Redis和数据库如何实现数据一致性 有哪些基于Redis实现的分布式锁 Redis中的key过期了是否立即释放内存，为什么 如何保证Redis的高可用和高并发 Redis集群模式下，redis的key如何寻址，分布式寻址都有哪些算法 一致性hash算法是什么 Redis变慢如何排查 如何从海量key中查找出某一个固定前缀的key 如何为Redis一次增加大批量数据</content></entry><entry><title>MySQL排他锁实战</title><url>https://www.zyg-tech.me/post/mysql%E6%8E%92%E4%BB%96%E9%94%81%E5%AE%9E%E6%88%98/</url><categories><category>MySQL</category><category>锁</category></categories><tags><tag>MySQL</tag><tag>分布式锁</tag></tags><content type="html"> 1. 需求背景 ​ 基于MySQL/Oracle数据库实现分布式锁，保证一个项目中的定时任务代码在多台机器中同时执行时最多有一个任务可以成功获取锁，其他任务获取锁失败
2. 排他锁介绍 2.1 概念 ​ 如果事务T对数据A加上排他锁(exclusive lock，即X锁)后，则其他事务不能再对A加任任何类型的锁，将会等待事务T结束。获准排他锁的事务既能读数据，又能修改数据.
​ 在MySQL中，X锁仅适用于InnoDB引擎，而且必须在事务中才能生效，根据where条件是否通过索引命中数据，MySQL中的X锁分为行锁与表锁 ：命中数据时采用行锁，本质是对索引加锁；其他情况下均为表锁（例如没有where条件对应的数据，where后的字段没有索引）；特殊地，如果表数据过少，InnoDB引擎也可能将SQL优化为表锁，这种情况下可以通过force index来强制使用索引。
2.2 用法示例 2.2.1 基本用法 select … for update;
例如：select * from goods where id = 1 for update;
2.2.2 进阶用法 # nowait --&amp;gt; 不再等待事务而是立即返回结果，如果发现where条件的结果集被其他事务锁定则立即返回失败，该语法自MySQL的8.0版本开始支持，Oracle支持 select ... for update no wait; # wait --&amp;gt; 最多等待指定的时间x秒之后返回结果，该语法在Orale中支持 select ... for update wait x; # skip locked --&amp;gt; 如果数据锁定时跳过锁定的数据,该语法自MySQL的8.0版本开始支持，Oracle支持 select ... for update skip locked; 3.准备数据 3.1 准备表 create table t_gdts_sync_flag ( n_id bigint auto_increment comment &amp;#39;流水id&amp;#39; primary key, c_company_id varchar(20) null comment &amp;#39;集团id,对应t_gdts_company_rel的n_id&amp;#39;, n_type tinyint(2) null comment &amp;#39;同步标识类型,1集团,2部门,3人员&amp;#39;, c_status varchar(10) null comment &amp;#39;同步状态,sync/idle&amp;#39; ) comment &amp;#39;同步标识表&amp;#39;; 3.2 准备数据 INSERT INTO gropt.t_gdts_sync_flag (n_id, c_company_id, n_type, c_status) VALUES (75, &amp;#39;1326009432085127169&amp;#39;, 1, &amp;#39;idle&amp;#39;); INSERT INTO gropt.t_gdts_sync_flag (n_id, c_company_id, n_type, c_status) VALUES (76, &amp;#39;1326009432085127169&amp;#39;, 2, &amp;#39;idle&amp;#39;); INSERT INTO gropt.t_gdts_sync_flag (n_id, c_company_id, n_type, c_status) VALUES (77, &amp;#39;1326009432085127169&amp;#39;, 3, &amp;#39;idle&amp;#39;); 4. 实战 4.1 定义用于获取锁的线程池 4.2 获取锁的SQL语句 4.3 获取锁的Service代码 4.4 定时任务代码</content></entry><entry><title>Hystrix熔断器</title><url>https://www.zyg-tech.me/post/hystrix%E7%86%94%E6%96%AD%E5%99%A8/</url><categories><category>熔断</category></categories><tags><tag>服务高可用</tag><tag>熔断</tag></tags><content type="html"> 熔断器 状态及转换 Hystrix提供的熔断器具有自我反馈，自我恢复的功能，Hystrix会根据调用接口的情况，让熔断器在closed,open,half-open三种状态之间自动切换,三种状态简要说明如下:
closed : 代表关闭熔断,默认状态,在此期间执行远程调用方法 open : 代表打开熔断,在此期间执行本地降级策略,不执行远程调用 half-open : 代表中间状态,在此期间,先执行远程调用,如果成功,下次继续执行远程调用,如果失败,转换为open状态 1)正常状态下为closed状态,若访问接口超过设置阈值且错误请求数比例达到设置值时,转换为open状态,时间段从0开始(打开熔断)
2)保持open状态一个时间段;
3)下个时间段后,状态自动转换为half-open,在此期间,
​ 3.1)如果第一次请求时接口失败,则转换为open状态,时间段从0开始,
​ 3.2)如果请求数量达到设置阈值且错误请求书比例未达到设置值时,转换状态为closed,时间段从0开始(恢复正常),
​ 3.3)如果请求数量没有达到阈值, 一直保持half-open状态
核心流程 将远程服务调用逻辑封装进一个HystrixCommand。 对于每次服务调用可以使用同步或异步机制，对应执行execute()或queue()。 判断熔断器(circuit-breaker)是否打开或者半打开状态，如果打开跳到步骤8，进行回退策略，如果关闭进入步骤4。 判断线程池/队列/信号量（使用了舱壁隔离模式）是否跑满，如果跑满进入回退步骤8，否则继续后续步骤5。 run方法中执行了实际的服务调用。 a. 服务调用发生超时时，进入步骤8。 判断run方法中的代码是否执行成功。 a. 执行成功返回结果。 b. 执行中出现错误则进入步骤8。 所有的运行状态(成功，失败，拒绝，超时)上报给熔断器，用于统计从而影响熔断器状态。 进入getFallback()回退逻辑。 a. 没有实现getFallback()回退逻辑的调用将直接抛出异常。 b. 回退逻辑调用成功直接返回。 c. 回退逻辑调用失败抛出异常。 返回执行成功结果。</content></entry><entry><title>服务压测调优</title><url>https://www.zyg-tech.me/post/%E6%9C%8D%E5%8A%A1%E5%8E%8B%E6%B5%8B%E8%B0%83%E4%BC%98/</url><categories><category>调优</category></categories><tags><tag>服务优化</tag><tag>调优</tag><tag>Linux</tag></tags><content type="html"> 服务压测问题修复 Linux服务器环境优化 调整linux最大线程数 ​ /etc/sysctl.conf 配置文件中，加入 sys.kernel.threads-max = 40960
调整linux全局最大pid ​ /etc/sysctl.conf 配置文件中，加入 sys.kernel.pid_max = 40960
调整linux TCP进程参数 ​ /etc/sysctl.conf 配置文件中，加入 以下内容,执行：sysctl -p ，使设置立即生效：
# 进程可以同时打开的最大文件句柄数，这个参数直接限制最大并发连接数 fs.file-max=999999 ############## TCP数据窗口相关参数 ############## # 默认的TCP数据接收窗口大小/字节,默认229376 net.core.rmem_default = 256960 # 最大的TCP数据接收窗口大小/字节,默认131071 net.core.rmem_max = 513920 # 默认的TCP数据发送窗口大小/字节,默认229376 net.core.wmem_default = 256960 # 最大的TCP数据发送窗口/字节,默认131071 net.core.wmem_max = 513920 ################# TCP队列相关参数 ############### # 当网卡接收数据包的速度大于内核处理数据的时候，会有一个队列保存这些数据包,即接收队列长度。这个参数表示这个队列的最大值,默认1000 net.core.netdev_max_backlog = 2000 # TCP三次握手建立阶段服务器接收SYN请求队列的最大长度,即SYN半连接队列长度,对于超出该队列的请求直接丢弃 net.ipv4.tcp_max_syn_backlog = 262144 # 全局的每一个端口最大的监听队列的长度,默认128 net.core.somaxconn = 2048 ############## TCP缓冲区相关参数 ########### # 全局的所有TCP的SocketBuffer配置,该SocketBuffer用于发送方发送数据/接收方接受数据时存储这些数据,有三个值，单位为内存页(通常为4K):当TCP使用了低于第一个值的内存页面数时，TCP不会考虑释放内存;当TCP使用了超过第二个值的内存页面数量时,TCP试图稳定其内存使用，进入pressure模式;当内存占用超过第三个值，系统拒绝分配socket,报错TCP: too many of orphaned sockets.默认94011 125351 188022 net.ipv4.tcp_mem = 131072 262144 524288 # TCP读缓冲区/字节,三个值分别表示TCP接收缓存（用于TCP接收滑动窗口）的最小值、默认值、最大值,默认4096 87380 4011232 net.ipv4.tcp_rmem = 8760 256960 4088000 # TCP写缓冲区/字节,三个值分别表示TCP发送缓存（用于TCP接收滑动窗口）的最小值、默认值、最大值,默认4096 16384 4011232 net.ipv4.tcp_wmem = 8760 256960 4088000 # 每个套接字所允许的最大缓冲区的大小/字节,默认20480 net.core.optmem_max = 81920 ############### keepalive相关参数 ##################### # CLOSE_WAIT 状态维持的秒数 = tcp_keepalive_time + tcp_keepalive_intvl * tcp_keepalive_probes # 当keepalive启用时，TCP发送keealive消息的频度,默认7200/秒 net.ipv4.tcp_keepalive_time = 1800 # 以该参数指定的秒数为时间间隔/s，向客户端发起对它的探测 net.ipv4.tcp_keepalive_intvl = 30 # 内核发起对客户端探测的次数，如果都没有得到响应，那么就断定客户端不可达或者已关闭，内核就关闭该TCP连接 net.ipv4.tcp_keepalive_probes = 3 ############### Time_wait相关参数 ##################### # 是否开启timstamp校验,该配置项会影响net.ipv4.tcp_tw_reuse、net.ipv4.tcp_tw_recycle,只有发起方和接收方都开启该项才会使得net.ipv4.tcp_tw_reuse、net.ipv4.tcp_tw_recycle生效,该配置项提供以下两个功能:a.更加准确的RTT测量数据，尤其是有丢包时 – RTTM b. 保证了在极端情况下，TCP的可靠性 – PAWS net.ipv4.tcp_timestamps = 1 # 是否允许将TIME—WAIT状态的socket重新用于新的TCP连接,默认0,1开启,开启后将会在Time_wait状态的1s后复用socket net.ipv4.tcp_tw_reuse = 1 # 设置是否对TIME_WAIT状态的TCP进行快速回收,默认0,1开启 net.ipv4.tcp_tw_recycle = 1 # 当服务器主动关闭连接的时候，主动关闭方的socket保持在FIN-WAIT-2状态的最大时间/秒,默认60 net.ipv4.tcp_fin_timeout = 30 ############### 其他参数 ##################### # 是否启用有选择的应答,开启此项后,可以让发送方只发送丢失部分的数据,即支持乱序接收 net.ipv4.tcp_sack = 1 # 是否打开FACK拥塞避免和快速重传功能 net.ipv4.tcp_fack = 1 # 是否支持更大的TCP窗口,如果TCP窗口最大超过65535(64K), 必须设置该数值为1 net.ipv4.tcp_window_scaling = 1 # 是否打开SYN Cookie功能，该功能可以防止部分SYN flood攻击 net.ipv4.tcp_syncookies = 1 # 在UDP和TCP连接本地端口的取值范围 net.ipv4.ip_local_port_range = 1024 65000 调整linux最大文件数量 /etc/security/limits.conf文件尾部添加如下代码：
* soft nofile 65535 * hard nofile 65535 Tmcat参数优化 设置内存参数 tomcat安装目录/bin/catalina.sh 106 行添加以下内容
JAVA_OPTS=&amp;#34;-Xmx8192M -Xms8192M -XX:MaxPermSize=512M -XX:PermSize=512M -XX:+UseG1GC -XX:MaxGCPauseMillis=100 -XX:+ParallelRefProcEnabled -XX:+HeapDumpOnOutOfMemoryError -XX:+PrintGCApplicationStoppedTime -XX:+PrintHeapAtGC&amp;#34; 【注意】不要换行是一行 参数 参考地址为：https://console.perfma.com/ 线程数计算公式： Max memory （除去系统占用和其他应用程序占用后的操作系统总内存大小） = [-Xmx] + [-XX:MaxMetaSpaceSize] + number_of_threads * [-Xss]
修改日志打印 访问日志原始值：
&amp;lt;Valve className=&amp;#34;org.apache.catalina.valves.AccessLogValve&amp;#34; directory=&amp;#34;logs&amp;#34; prefix=&amp;#34;localhost_access_log.&amp;#34; suffix=&amp;#34;.txt&amp;#34; pattern=&amp;#34;%h %l %u %t %s %b&amp;#34; /&amp;gt; 调整后的值:
&amp;lt;Valve className=&amp;#34;org.apache.catalina.valves.AccessLogValve&amp;#34; directory=&amp;#34;logs&amp;#34; prefix=&amp;#34;localhost_access_log.&amp;#34; suffix=&amp;#34;.txt&amp;#34; pattern=&amp;#34;%h %l %u %t %q %s %b %F %D %I &amp;#34; /&amp;gt; pattern属性的值由文字文本字符串和以“％”字符为前缀的模式标识符组合而成，以替换为来自当前请求和响应的相应变量值。支持以下模式代码：(原始地址:http://tomcat.apache.org/tomcat-7.0-doc/config/valve.html)
％ a-远程IP地址 **％A-**本地IP地址 **％b-**发送的字节，不包括HTTP标头，如果为零则为&amp;rsquo;-&amp;rsquo; **％B-**发送的字节，不包括HTTP标头 **％h-**远程主机名（如果enableLookups连接器为false，则为IP地址 ） **％H-**请求协议 ％l -identd的远程逻辑用户名（总是返回“-”） **％m-**请求方法（GET，POST等） **％p-**接收此请求的本地端口。另请参见%{xxx}p下文。 **％q-**查询字符串（如果存在，则以“？”开头） **％r-**请求的第一行（方法和请求URI） **％s-**响应的HTTP状态代码 **％S-**用户会话ID **％t-**日期和时间，采用通用日志格式 **％u-**已验证（如果有）的远程用户，否则为&amp;rsquo;-&amp;rsquo; **％U-**请求的URL路径 **％v-**本地服务器名称 **％D-**以毫秒为单位处理请求所花费的时间。注意：在httpd中，％D是微秒。从Tomcat 10开始，行为将与httpd对齐。 **％T-**处理请求所花费的时间，以秒为单位。注意：此值具有毫秒分辨率，而在httpd中具有第二分辨率。行为将与Tomcat 10及更高版本中的httpd保持一致。 **％F-**提交响应所花费的时间（以毫秒为单位） **％I-**当前请求线程名称（以后可以与堆栈跟踪进行比较） 调整线程数 tomcat安装目录/conf/server.xml 71行
调整前原始值：
&amp;lt;Connector port=&amp;#34;8080&amp;#34; protocol=&amp;#34;HTTP/1.1&amp;#34; connectionTimeout=&amp;#34;20000&amp;#34; redirectPort=&amp;#34;8443&amp;#34; /&amp;gt; 调整后的值：
&amp;lt;Connector port=&amp;#34;8080&amp;#34; protocol=&amp;#34;HTTP/1.1&amp;#34; maxKeepAliveRequests=&amp;#34;200&amp;#34; socketBuffer=&amp;#34;9000&amp;#34; enableLookups=&amp;#34;false&amp;#34; tcpNoDelay=&amp;#34;true&amp;#34; minSpareThreads=&amp;#34;100&amp;#34; maxSpareThreads=&amp;#34;100&amp;#34; maxThreads=&amp;#34;2000&amp;#34; connectionTimeout=&amp;#34;5000&amp;#34; maxHttpHeaderSize=&amp;#34;32768&amp;#34; URIEncoding=&amp;#34;UTF-8&amp;#34; acceptCount=&amp;#34;200&amp;#34; redirectPort=&amp;#34;8443&amp;#34; /&amp;gt; 配置项解释
参数 含义 示例 port 绑定的端口,如果设置为0，tomcat则随机获取一个空闲端口 默认 port=&amp;quot;8080&amp;rdquo; protocol 传输协议和版本 默认 protocol = &amp;ldquo;HTTP/1.1&amp;rdquo; connectionTimeout 连接超时时间，单位毫秒 默认 connectionTimeout=&amp;quot;20000&amp;rdquo; redirectPort 接收到的ssl请求后重定向的端口 默认 redirectPort=&amp;quot;8443&amp;rdquo; maxThreads tomcat能创建来处理请求的最大线程数，也为最大并发数 超过则放入请求队列中进行排队，默认值为200；需要根据业务和系统性能进行调整 maxThreads=&amp;quot;1000&amp;rdquo; URIEncoding url的字符编码，在tomcat8.5版本中，该值默认为UTF-8,除非在org.apache.catalina.STRICT_SERVLET_COMPLIANCE 将system property 设置为true才会使用ISO-8859-1 URIEncoding=&amp;quot;UTF-8&amp;rdquo; minProcessors 启动时创建的线程数（最小线程数） minProcessors=&amp;quot;50&amp;rdquo; acceptCount 指定当所有可以使用的处理请求的线程数都被使用时，可以放到队列中的请求数，就是被排队的请求数，超过这个数的请求将拒绝连接 默认值为100 acceptcount=&amp;quot;500&amp;rdquo; acceptorThreadCount 可以用于接受连接的进程数，默认为1，但是在一些多核的的服务器上，我们会将它的值设置为2或者更大的数，来应对一些不活跃的连接。 minSpareThreads 最小空闲线程数，任何情况都会存活的线程数，即便超过了最大空闲时间，也不会被回收，默认值10; minSpareThreads=&amp;quot;25&amp;rdquo; maxSpareThreads 最大空闲线程数，在最大空闲时间（maxIdleTime）内活跃过，此时空闲，当空闲时间大于maxIdleTime则被回收，小则继续存活，等待被调度，默认值50； enableLookups 调用request、getRemoteHost()执行DNS查询，以返回远程主机的主机名，如果设置为false，则直接返回IP地址 默认是禁用的，在请求过滤中的根据远程主机名过滤，需要将该参数设置为true enableLookups=&amp;quot;false&amp;rdquo; maxIdleTime 最大空闲时间，超过这个空闲时间，且线程数大于minSpareThreads的，都会被回收，默认值1分钟（60000ms) maxPostSize address 对于一些具有多个ip的服务器，我们可以通过该参数指定绑定的ip，默认情况下监听所有的地址 address=&amp;quot;192.168.1.110&amp;rdquo; compressibleMimeType 该值用来指定哪些文件类型的文件可以进行压缩，默认值为：text/html,text/xml,text/plain,text/css,text/javascript,application/javascript compression 开启gzip 压缩，可以接受的值是 &amp;ldquo;off&amp;rdquo;(禁用压缩),&amp;ldquo;on&amp;rdquo;(开启压缩),&amp;ldquo;force(强制压缩)&amp;quot;，&amp;ldquo;1-9&amp;rdquo;(等效于开启压缩，并且设定压缩等级),开启了压缩，也就意味着要占用更多的cpu资源 compression compressionMinSize 在compression 参数指定为on后，该参数用来指定压缩的阈值，只有大于该阈值才会被压缩，默认为 2048 keepAliveTimeout 指connector两个HTTP请求直接的等待时间，超过该时间没有接收到第二个HTTP请求就关闭连接，默认是使用connectionTimeout 的值，单位为毫秒 maxConnections 在一定时间内可以接受和处理的最大连接数，达到限制后，服务器接受但不处理该链接，但可以存放到acceptCount，该默认值因连接器类型而异。对于NIO和NIO2，默认值为10000。对于APR / native，默认为8192。 maxCookieCount 请求允许的最大cookie 数，值小于0表示无限制，默认值为 200 disableUploadTimeout 默认是true ，禁用数据上传超时 connectionUploadTimeout 设定数据上传的超时时间，只有在disableUploadTimeout设置为false才生效，单位毫秒 connectionUploadTimeout=&amp;quot;50000&amp;rdquo; processorCache 进程缓冲器，默认值是maxThreads的值,使用好该值可以提升并发请求。</content></entry><entry><title>Docker 常用命令</title><url>https://www.zyg-tech.me/post/docker-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url><categories><category>Docker</category></categories><tags><tag>容器化</tag><tag>部署运维</tag><tag>Docker</tag><tag>命令</tag></tags><content type="html"> Docker是一个开源的应用容器引擎，让开发者可以打包应用及依赖包到一个可移植的镜像中，然后发布到任何流行的Linux或Windows机器上。使用Docker可以更方便地打包、测试以及部署应用程序。
Docker环境安装 安装yum-utils； yum install -y yum-utils device-mapper-persistent-data lvm2 复制代码 为yum源添加docker仓库位置； yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 复制代码 安装docker服务； yum install docker-ce 复制代码 启动docker服务。 systemctl start docker 复制代码 Docker镜像常用命令 搜索镜像 docker search java 复制代码 下载镜像 docker pull java:8 复制代码 查看镜像版本 由于docker search命令只能查找出是否有该镜像，不能找到该镜像支持的版本，所以我们需要通过Docker Hub来搜索支持的版本。
进入Docker Hub的官网，地址：https://hub.docker.com
然后搜索需要的镜像：
查看镜像支持的版本：
进行镜像的下载操作：
docker pull nginx:1.17.0 列出镜像 docker images 删除镜像 指定名称删除镜像： docker rmi java:8 指定名称删除镜像（强制）： docker rmi -f java:8 删除所有没有引用的镜像： docker rmi `docker images | grep none | awk &amp;#39;{print $3}&amp;#39;` 强制删除所有镜像： docker rmi -f $(docker images) 打包镜像 # -t 表示指定镜像仓库名称/镜像名称:镜像标签 .表示使用当前目录下的Dockerfile文件 docker build -t mall/mall-admin:1.0-SNAPSHOT . Docker容器常用命令 新建并启动容器 docker run -p 80:80 --name nginx \ -e TZ=&amp;#34;Asia/Shanghai&amp;#34; \ -v /mydata/nginx/html:/usr/share/nginx/html \ -d nginx:1.17.0 -p：将宿主机和容器端口进行映射，格式为：宿主机端口:容器端口； &amp;ndash;name：指定容器名称，之后可以通过容器名称来操作容器； -e：设置容器的环境变量，这里设置的是时区； -v：将宿主机上的文件挂载到宿主机上，格式为：宿主机文件目录:容器文件目录； -d：表示容器以后台方式运行。 列出容器 列出运行中的容器： docker ps 列出所有容器： docker ps -a 停止容器 注意：$ContainerName表示容器名称，$ContainerId表示容器ID，可以使用容器名称的命令，基本也支持使用容器ID，比如下面的停止容器命令。
docker stop $ContainerName(or $ContainerId) 例如：
docker stop nginx #或者 docker stop c5f5d5125587 强制停止容器 docker kill $ContainerName 启动容器 docker start $ContainerName 进入容器 先查询出容器的pid： docker inspect --format &amp;#34;{{.State.Pid}}&amp;#34; $ContainerName 根据容器的pid进入容器： nsenter --target &amp;#34;$pid&amp;#34; --mount --uts --ipc --net --pid 删除容器 删除指定容器： docker rm $ContainerName 按名称通配符删除容器，比如删除以名称mall-开头的容器： docker rm `docker ps -a | grep mall-* | awk &amp;#39;{print $1}&amp;#39;` 强制删除所有容器； docker rm -f $(docker ps -a -q) 查看容器的日志 查看容器产生的全部日志： docker logs $ContainerName 动态查看容器产生的日志： docker logs -f $ContainerName 查看容器的IP地址 docker inspect --format &amp;#39;{{ .NetworkSettings.IPAddress }}&amp;#39; $ContainerName 修改容器的启动方式 # 将容器启动方式改为always docker container update --restart=always $ContainerName 同步宿主机时间到容器 docker cp /etc/localtime $ContainerName:/etc/ 指定容器时区 docker run -p 80:80 --name nginx \ -e TZ=&amp;#34;Asia/Shanghai&amp;#34; \ -d nginx:1.17.0 查看容器资源占用状况 查看指定容器资源占用状况，比如cpu、内存、网络、io状态： docker stats $ContainerName 查看所有容器资源占用情况： docker stats -a 查看容器磁盘使用情况 docker system df 执行容器内部命令 docker exec -it $ContainerName /bin/bash 指定账号进入容器内部 # 使用root账号进入容器内部 docker exec -it --user root $ContainerName /bin/bash 查看所有网络 docker network ls ## 结果示例 [root@local-linux ~]# docker network ls NETWORK ID NAME DRIVER SCOPE 59b309a5c12f bridge bridge local ef34fe69992b host host local a65be030c632 none 创建外部网络 docker network create -d bridge my-bridge-network 指定容器网络 docker run -p 80:80 --name nginx \ --network my-bridge-network \ -d nginx:1.17.0 修改镜像的存放位置 查看Docker镜像的存放位置： docker info | grep &amp;#34;Docker Root Dir&amp;#34; 关闭Docker服务： systemctl stop docker 先将原镜像目录移动到目标目录： mv /var/lib/docker /mydata/docker 建立软连接： ln -s /mydata/docker /var/lib/docker 再次查看可以发现镜像存放位置已经更改。 本文 GitHub github.com/macrozheng/… 已经收录，欢迎大家Star！
作者：MacroZheng 链接：https://juejin.cn/post/6895888125886332941 来源：掘金 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</content></entry><entry><title>Spring中Async的使用与源码解析</title><url>https://www.zyg-tech.me/post/spring%E4%B8%ADasync%E7%9A%84%E4%BD%BF%E7%94%A8%E4%B8%8E%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/</url><categories><category>SpringBoot</category><category>线程池</category></categories><tags><tag>线程池</tag><tag>异步</tag><tag>SpringBoot</tag></tags><content type="html"> 背景介绍 对于异步方法调用，从Spring3开始提供了@Async注解，该注解可以被标注在方法上，以便异步地调用该方法。调用者将在调用时立即返回，方法的实际执行将提交给Spring TaskExecutor的任务中，由指定的线程池中的线程执行。
常见的场景 系统日志记录 耗时任务的执行 使用方法 1.启动类增加@EnableAsync注解(since Spring 3.1)
@EnableAsync @SpringBootApplication public class SpringBootDemoAsyncApplication { public static void main(String[] args) { SpringApplication.run(SpringBootDemoAsyncApplication.class, args); } } 2.如有需要，可以自定义线程池
@Configuration public class ExecutorConfiguration { /** * 配置应用访问日志专用线程池 * @return */ @Bean(name = &amp;#34;sodAppLogAsyncExecutor&amp;#34;) public ThreadPoolTaskExecutor asyncExecutor() { ThreadPoolTaskExecutor threadPool = new ThreadPoolTaskExecutor(); threadPool.setThreadNamePrefix(&amp;#34;drs-sodAppLog-&amp;#34;); threadPool.setCorePoolSize(3); threadPool.setMaxPoolSize(4); threadPool.setKeepAliveSeconds(60); threadPool.setQueueCapacity(11); threadPool.setRejectedExecutionHandler(new ThreadPoolExecutor.DiscardPolicy()); //优雅关闭 threadPool.setWaitForTasksToCompleteOnShutdown(true); threadPool.setAwaitTerminationSeconds(60 * 15); return threadPool; } } 3.在需要使用异步的方法上添加@Async注解，可以通过value属性指定线程池,返回值支持void、Future、ListenableFuture、CompletableFuture，如果不指定value，那么采用默认线程池
/** * 模拟5秒的异步任务 */ @Async public Future&amp;lt;Boolean&amp;gt; asyncTask1() throws InterruptedException { doTask(&amp;#34;asyncTask1&amp;#34;, 5); return new AsyncResult&amp;lt;&amp;gt;(Boolean.TRUE); } /** * 模拟业务代码 * @param taskName * @param time */ private void doTask(String taskName, Integer time) { log.info(&amp;#34;{}模拟执行【{}】,线程内存地址:{}&amp;#34;, taskName, Thread.currentThread().getName(), UnsafeUtil.addressOf(Thread.currentThread())); } Spring实现的线程池 SimpleAsyncTaskExecutor：默认线程池，每次调用都启动一个新线程(并不会复用线程池已有线程),支持对并发总数设限（ConcurrencyLimit，默认-1不限制，0不允许），当超过线程并发总数限制时，阻塞新的调用 ThreadPoolTaskExecutor:对JDK的ThreadPoolExecutor的封装，SpringBoot通过TaskExecutionAutoConfiguration自动装配了一个名为applicationTaskExecutor的ThreadPoolTaskExecutor @ConditionalOnClass(ThreadPoolTaskExecutor.class) @Configuration @EnableConfigurationProperties(TaskExecutionProperties.class) public class TaskExecutionAutoConfiguration { @Bean @ConditionalOnMissingBean public TaskExecutorBuilder taskExecutorBuilder() { TaskExecutionProperties.Pool pool = this.properties.getPool(); TaskExecutorBuilder builder = new TaskExecutorBuilder(); builder = builder.queueCapacity(pool.getQueueCapacity()); builder = builder.corePoolSize(pool.getCoreSize()); builder = builder.maxPoolSize(pool.getMaxSize()); builder = builder.allowCoreThreadTimeOut(pool.isAllowCoreThreadTimeout()); builder = builder.keepAlive(pool.getKeepAlive()); builder = builder.threadNamePrefix(this.properties.getThreadNamePrefix()); builder = builder.customizers(this.taskExecutorCustomizers); builder = builder.taskDecorator(this.taskDecorator.getIfUnique()); return builder; } @Lazy @Bean(name = APPLICATION_TASK_EXECUTOR_BEAN_NAME) @ConditionalOnMissingBean(Executor.class) public ThreadPoolTaskExecutor applicationTaskExecutor(TaskExecutorBuilder builder) { return builder.build(); } } SimpleAsyncTaskExecutor 属性列表
Daemon:是否为守护线程，默认false ThreadPriority:线程优先级,默认5 ThreadNamePrefix:线程名前缀，默认&amp;quot;SimpleAsyncTaskExecutor&amp;rdquo; ConcurrencyLimit:并发上限,默认-1不限制，0表示不允许并发？？？？ ThreadPoolTaskExecutor 属性列表
CorePoolSize：线程池创建时候初始化的线程数,默认1 MaxPoolSize：线程池最大的线程数，只有在缓冲队列满了之后才会申请超过核心线程数的线程，默认Integer.MAX QueueCapacity：用来缓冲执行任务的队列的队列大小，默认Integer.MAX KeepAliveSeconds：线程的空闲时间，单位/s，当超过了核心线程出之外的线程在空闲时间到达之后会被销毁,默认60 ThreadNamePrefix：线程池中线程名的前缀，继承自父类ExecutorConfigurationSupport，默认是BeanName/方法名 RejectedExecutionHandler：线程池对拒绝任务的处理策略，自父类ExecutorConfigurationSupport,（策略为JDK ThreadPoolExecutor自带） AbortPolicy：默认策略，直接抛出异常 RejectedExecutionException CallerRunsPolicy：直接在 execute 方法的调用线程中运行被拒绝的任务；如果执行程序已关闭，则会丢弃该任务 DiscardPolicy：该策略直接丢弃 DiscardOldestPolicy：该策略会先将最早入队列的未执行的任务丢弃掉，然后尝试执行新的任务。如果执行程序已关闭，则会丢弃该任务 waitForTasksToCompleteOnShutdown：关闭程序时是否等待任务执行完毕，继承自父类ExecutorConfigurationSupport，默认false表示中断正在执行的任务，清空队列 awaitTerminationSeconds：关闭程序时的等待时间，需配合waitForTasksToCompleteOnShutdown使用，继承自父类ExecutorConfigurationSupport，默认0 线程处理流程 /** * Executes the given task sometime in the future. The task * may execute in a new thread or in an existing pooled thread. * * If the task cannot be submitted for execution, either because this * executor has been shutdown or because its capacity has been reached, * the task is handled by the current {@code RejectedExecutionHandler}. * * @param command the task to execute * @throws RejectedExecutionException at discretion of * {@code RejectedExecutionHandler}, if the task * cannot be accepted for execution * @throws NullPointerException if {@code command} is null */ public void execute(Runnable command) { if (command == null) throw new NullPointerException(); /* * Proceed in 3 steps: * * 1. If fewer than corePoolSize threads are running, try to * start a new thread with the given command as its first * task. The call to addWorker atomically checks runState and * workerCount, and so prevents false alarms that would add * threads when it shouldn&amp;#39;t, by returning false. * * 2. If a task can be successfully queued, then we still need * to double-check whether we should have added a thread * (because existing ones died since last checking) or that * the pool shut down since entry into this method. So we * recheck state and if necessary roll back the enqueuing if * stopped, or start a new thread if there are none. * * 3. If we cannot queue task, then we try to add a new * thread. If it fails, we know we are shut down or saturated * and so reject the task. */ int c = ctl.get(); if (workerCountOf(c) &amp;lt; corePoolSize) { if (addWorker(command, true)) return; c = ctl.get(); } if (isRunning(c) &amp;amp;&amp;amp; workQueue.offer(command)) { int recheck = ctl.get(); if (! isRunning(recheck) &amp;amp;&amp;amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); } else if (!addWorker(command, false)) reject(command); } 如果此时线程池中的数量小于corePoolSize，即使线程池中的线程都处于空闲状态，也要创建新的线程来处理被添加的任务。 如果此时线程池中的数量等于 corePoolSize，但是缓冲队列 workQueue未满，那么任务被放入缓冲队列。 如果此时线程池中的数量大于corePoolSize，缓冲队列workQueue满，并且线程池中的数量小于maxPoolSize，那么建新的线程来处理被添加的任务。 如果此时线程池中的数量大于corePoolSize，缓冲队列workQueue满，并且线程池中的数量等于maxPoolSize，那么通过handler所指定的策略来处理此任务。（也就是：处理任务的优先级为：核心线程corePoolSize、任务队列workQueue、最大线程 maxPoolSize，如果三者都满了，使用handler处理被拒绝的任务） 当线程池中的线程数量大于corePoolSize时，如果某线程空闲时间超过keepAliveTime，线程将被终止。这样，线程池可以动态的调整池中的线程数 自定义线程池 自定义线程池有如下模式：
配置由自定义的TaskExecutor 重新实现接口AsyncConfigurer 继承AsyncConfigurerSupport 方式一：自定义TaskExecutor @Configuration public class ExecutorConfiguration { /** * 配置应用访问日志专用线程池 * @return */ @Bean(name = &amp;#34;sodAppLogAsyncExecutor&amp;#34;) public ThreadPoolTaskExecutor asyncExecutor() { ThreadPoolTaskExecutor threadPool = new ThreadPoolTaskExecutor(); threadPool.setThreadNamePrefix(&amp;#34;drs-sodAppLog-&amp;#34;); threadPool.setCorePoolSize(3); threadPool.setMaxPoolSize(4); threadPool.setKeepAliveSeconds(60); threadPool.setQueueCapacity(11); threadPool.setRejectedExecutionHandler(new ThreadPoolExecutor.DiscardPolicy()); //优雅关闭 threadPool.setWaitForTasksToCompleteOnShutdown(true); threadPool.setAwaitTerminationSeconds(60 * 15); return threadPool; } } 方式二：实现AsyncConfigurer /** * 自定义线程池方法二：自定义类，配置默认Executor与默认异步异常处理器 * @author zyg */ @Configuration public class CusAsyncConfigure implements AsyncConfigurer { /** * 配置默认Executor */ @Override public Executor getAsyncExecutor() { ThreadPoolTaskExecutor threadPool = new ThreadPoolTaskExecutor(); threadPool.setThreadNamePrefix(&amp;#34;cus-async-configure-&amp;#34;); threadPool.setCorePoolSize(2); threadPool.setMaxPoolSize(3); threadPool.setKeepAliveSeconds(60); threadPool.setQueueCapacity(5); threadPool.setRejectedExecutionHandler(new ThreadPoolExecutor.DiscardPolicy()); return threadPool; } /** * 配置默认异步异常处理器 */ @Override public AsyncUncaughtExceptionHandler getAsyncUncaughtExceptionHandler() { return new CusAsyncUncaughtExceptionHandler(); } } （原理是ProxyAsyncConfiguration的父类AbstractAsyncConfiguration的setConfigurers(Collection)中执行了AsyncConfigurer的方法来配置Executor与AsyncUncaughtExceptionHandler）
方式三：继承AsyncConfigurerSupport /** * 自定义线程池方法三:继承AsyncConfigurerSupport,重写getAsyncExecutor与getAsyncUncaughtExceptionHandler * @author zyg */ @Configuration public class CusAsyncConfigurerSupport extends AsyncConfigurerSupport { /** * 配置默认Executor */ @Override public Executor getAsyncExecutor() { ThreadPoolTaskExecutor threadPool = new ThreadPoolTaskExecutor(); threadPool.setThreadNamePrefix(&amp;#34;cus-async-configure-support-&amp;#34;); threadPool.setCorePoolSize(2); threadPool.setMaxPoolSize(3); threadPool.setKeepAliveSeconds(60); threadPool.setQueueCapacity(5); threadPool.setRejectedExecutionHandler(new ThreadPoolExecutor.DiscardPolicy()); return threadPool; } /** * 配置默认异步异常处理器 */ @Override public AsyncUncaughtExceptionHandler getAsyncUncaughtExceptionHandler() { return new CusAsyncUncaughtExceptionHandler(); } } （原理是AsyncConfigurerSupport的父类是AsyncConfigurer）
异常处理 如果任务的返回类型是Future，那么将直接抛出异常，否则异常由AsyncUncaughtExceptionHandler的handleUncaughtException()进行处理，Spring自4.1默认提供了SimpleAsyncUncaughtExceptionHandler，该类处理异常的逻辑是通过日志打印错误，如有需要可以自定义类继承AsyncUncaughtExceptionHandler，复写其handleUncaughtException()方法。
/** * 自定义线程池方法二：自定义默认异步异常处理器 * @author zyg */ @Component public class CusAsyncUncaughtExceptionHandler implements AsyncUncaughtExceptionHandler { private Logger logger = LoggerFactory.getLogger(this.getClass()); @Override public void handleUncaughtException(Throwable ex, Method method, Object... params) { logger.error(&amp;#34;自定义异步异常处理器捕捉到异常，&amp;#34;,ex); } } @EnableAsync加载流程 前置知识点 @Import注解的作用 BeanPostProcessor在Spring中的作用 Aware类接口在Spring中的作用 切面与通知的概念与作用 代码分析： @EnableAsync中Import了AsyncConfigurationSelector； AsyncConfigurationSelector的作用是通过配置确定是调用ProxyAsyncConfiguration还是AspectJ的AspectJAsyncConfiguration； 在ProxyAsyncConfiguration的asyncAdvisor()方法可以看到，其中定义了后置处理器AsyncAnnotationBeanPostProcessor AsyncAnnotationBeanPostProcessor直接或间接实现了BeanFactoryAware、BeanPostProcessor两个接口，既然AsyncAnnotationBeanPostProcessor实现了BeanFactoryAware，那么就会执行setBeanFactory(BeanFactory)方法,该方法中设置了切面AsyncAnnotationAdvisor 切面中定义了切点：类上标注@Async、@Asynchronous注解的切点与在方法上标注@Async、@Asynchronous注解的切点 切面中定义了通知：通知Executor与SimpleAsyncUncaughtExceptionHandler， 通知具体的实现类为AnnotationAsyncExecutionInterceptor，它的父类AsyncExecutionInterceptor进行了实际的通知处理操作 配置默认Executor 在生成切面AsyncAnnotationAdvisor对象时，生成了AnnotationAsyncExecutionInterceptor对象，调用了AnnotationAsyncExecutionInterceptor的configure(Supplier,Supplier)方法,在该方法中，调用了getDefaultExecutor(BeanFactory)来寻找默认Executor，查找Executor的优先级如下：
从BeanFactory中查找类型为TaskExecutor的对象 从BeanFactory中查找类型为Executor、Bean名称为taskExecutor的对象 如果上述步骤中找不到，那么子类AsyncExecutionInterceptor中生成SimpleAsyncTaskExecutor对象 通知的处理 通过determineAsyncExecutor(Method)方法查找AsyncExecutor 包装一下任务，当任务出现异常时调用AsyncUncaughtExceptionHandler的handleUncaughtException()处理异常 调用AsyncExecutor的submit()/submitListenable()/CompletableFuture.supplyAsync()等方法提交任务 查找AsyncExecutor AsyncExecutionAspectSupport的determineAsyncExecutor(Method)中查找了AsyncEexcutor，逻辑如下
首先尝试从成员变量Map&amp;lt;Method, AsyncTaskExecutor&amp;gt; executors查找是否存在，如果存在则返回 然后从AsyncExecutionAspectSupport.getExecutorQualifier()获取专属于该Method的AsyncExecutor的Bean名称，如果存在，则向BeanFactory获取类型为Executor、Bean名称为该名称的Executor并返回 从成员变量SingletonSupplier获取，如果存在则返回 如果经过上述几步查找仍然无法找到那么就返回空 如果经过上述几步找到了Executor，判断Executor的类型 如果是AsyncListenableTaskExecutor，将其强制转换为AsyncListenableTaskExecutor后放入到成员变量executors中 如果不是AsyncListenableTaskExecutor，通过TaskExecutorAdapter包装一个concurrentExecutor然后放入到成员变量executors中 异步事务 在@Async标注的方法，同时也适用了@Transactional进行了标注；在其调用数据库操作时，将无法产生事务管理的控制，原因就在于其是基于异步处理的操作。 那该如何给这些操作添加事务管理呢？可以将需要事务管理操作的方法放置到异步方法内部，在内部被调用的方法上添加@Transactional. 例如： 方法A，同时使用了@Async/@Transactional来标注，但是无法产生事务控制的目的。 方法B，使用了@Async来标注， B中调用了方法C、D，方法C、D分别使用@Transactional做了标注，则可实现事务控制的目的。</content></entry><entry><title>Netty架构简介</title><url>https://www.zyg-tech.me/post/netty%E6%9E%B6%E6%9E%84%E7%AE%80%E4%BB%8B/</url><categories><category>Netty</category></categories><tags><tag>高性能组件</tag><tag>代码研究</tag></tags><content type="html"> Netty功能特性如下
1）传输服务：支持 BIO 和 NIO；
2）容器集成：支持 OSGI、JBossMC、Spring、Guice 容器；
3）协议支持：HTTP、Protobuf、二进制、文本、WebSocket 等一系列常见协议都支持。还支持通过实行编码解码逻辑来实现自定义协议；
4）Core 核心：可扩展事件模型、通用通信 API、支持零拷贝的 ByteBuf 缓冲对象。
高性能设计 Netty 作为异步事件驱动的网络，高性能之处主要来自于其 I/O 模型和线程处理模型，前者决定如何收发数据，后者决定如何处理数据
Netty采用的I/O模型为NIO,如下图
Netty采用的线程处理模型为Reactor模型.Reactor 模型中有 2 个关键组成：
1）Reactor：Reactor 在一个单独的线程中运行，负责监听和分发事件，分发给适当的处理程序来对 IO 事件做出反应。它就像公司的电话接线员，它接听来自客户的电话并将线路转移到适当的联系人；
2）Handlers：处理程序执行 I/O 事件要完成的实际事件，类似于客户想要与之交谈的公司中的实际官员。Reactor 通过调度适当的处理程序来响应 I/O 事件，处理程序执行非阻塞操作。
Reactor模型共有3个变种:单 Reactor 单线程、单 Reactor 多线程、主从 Reactor 多线程.
Netty的线程模型是基于主从 Reactors 多线程模型进行修改.
核心组件 Boostrap:客户端程序的启动引导类,主要作用是配置整个 Netty 程序，串联各个组件
ServerBootstrap:服务端启动引导类
ChannelEvent : 因为Netty是基于事件驱动的，ChannelEvent就相当于某一个事件，比如说连接成功时打印一句话
Channel:网络通信的组件，能够用于执行网络 I/O 操作,下面是一些常用的 Channel 类型：
NioSocketChannel，异步的客户端 TCP Socket 连接。 NioServerSocketChannel，异步的服务器端 TCP Socket 连接。 NioDatagramChannel，异步的 UDP 连接。 NioSctpChannel，异步的客户端 Sctp 连接。 NioSctpServerChannel，异步的 Sctp 服务器端连接，这些通道涵盖了 UDP 和 TCP 网络 IO 以及文件 IO。
Selector:通过 Selector 一个线程可以监听多个连接的 Channel 事件。当向一个 Selector 中注册 Channel 后，Selector 内部的机制就可以自动不断地查询Selector中注册的 Channel 是否有已就绪的 I/O 事件（例如可读，可写，网络连接完成等），这样程序就可以很简单地使用一个线程高效地管理多个 Channel
NioEventLoop:NioEventLoop 中维护了一个线程和任务队列，支持异步提交执行任务，线程启动时会调用 NioEventLoop 的 run 方法，执行 I/O 任务和非 I/O 任务
NioEventLoopGroup : 主要管理 eventLoop 的生命周期，可以理解为一个线程池，内部维护了一组线程，每个线程(NioEventLoop)负责处理多个 Channel 上的事件
ChannelHandler : 一个接口，处理 I/O 事件或拦截 I/O 操作，并将其转发到其 ChannelPipeline(业务处理链)中的下一个处理程序。
ChannelHandler 本身并没有提供很多方法，因为这个接口有许多的方法需要实现，方便使用期间，可以继承它的子类：
ChannelInboundHandler 用于处理入站 I/O 事件。 ChannelOutboundHandler 用于处理出站 I/O 操作。
或者使用以下适配器类：
ChannelInboundHandlerAdapter 用于处理入站 I/O 事件。 ChannelOutboundHandlerAdapter 用于处理出站 I/O 操作。 ChannelDuplexHandler 用于处理入站和出站事件。
ChannelPipline : 保存 ChannelHandler 的 List，用于处理或拦截 Channel 的入站事件和出站操作,可以理解为一种高级形式的拦截过滤器模式
ChannelHandlerContext : 保存 Channel 相关的所有上下文信息
组件间关系 当客户端和服务端连接的时候会建立一个 Channel,这个 Channel 我们可以理解为 Socket 连接，它负责基本的 IO 操作，例如：bind（），connect（），read（），write（） 等等,简单的说，Channel 就是代表连接，实体之间的连接，程序之间的连接，文件之间的连接，设备之间的连接。同时它也是数据入站和出站的载体。
EventLoopGroup、EventLoop、Channel关系如下
在 Netty 中每个 Channel 都有且仅有一个 ChannelPipeline 与之对应，它们的组成关系如下：
一个 Channel 包含了一个 ChannelPipeline，而 ChannelPipeline 中又维护了一个由 ChannelHandlerContext 组成的双向链表，并且每个 ChannelHandlerContext 中又关联着一个 ChannelHandler。
入站事件和出站事件在一个双向链表中，入站事件会从链表 head 往后传递到最后一个入站的 handler，出站事件会从链表 tail 往前传递到最前一个出站的 handler，两种类型的 handler 互不干扰。
这些核心组件的整体关系如下
核心工作流程 典型的初始化并启动 Netty 服务端的过程代码如下：
public final class EchoServer { static final boolean SSL = System.getProperty(&amp;#34;ssl&amp;#34;) != null; static final int PORT = Integer.parseInt(System.getProperty(&amp;#34;port&amp;#34;, &amp;#34;8007&amp;#34;)); public static void main(String[] args) throws Exception { // 配置SSL final SslContext sslCtx; if (SSL) { SelfSignedCertificate ssc = new SelfSignedCertificate(); sslCtx = SslContextBuilder.forServer(ssc.certificate(), ssc.privateKey()).build(); } else { sslCtx = null; } // 配置服务端 EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); final EchoServerHandler serverHandler = new EchoServerHandler(); try { ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 100) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChannelInitializer&amp;lt;SocketChannel&amp;gt;() { @Override public void initChannel(SocketChannel ch) throws Exception { ChannelPipeline p = ch.pipeline(); if (sslCtx != null) { p.addLast(sslCtx.newHandler(ch.alloc())); } //p.addLast(new LoggingHandler(LogLevel.INFO)); p.addLast(serverHandler); } }); // Start the server. ChannelFuture f = b.bind(PORT).sync(); // Wait until the server socket is closed. f.channel().closeFuture().sync(); } finally { // Shut down all event loops to terminate all threads. bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } } 基本过程描述如下：
1）初始化创建 2 个 NioEventLoopGroup：其中 boosGroup 用于 Accetpt 连接建立事件并分发请求，workerGroup 用于处理 I/O 读写事件和业务逻辑。
2）基于 ServerBootstrap(服务端启动引导类)：配置 EventLoopGroup、Channel 类型，连接参数、配置入站、出站事件 handler。
3）绑定端口：开始工作。
Netty启动流程图如下
结合上面介绍的 Netty Reactor 模型，介绍服务端 Netty 的工作架构图：
ps:上图中NioEventGroup有误,应为NioEventLoop</content></entry><entry><title>TopN问题解决</title><url>https://www.zyg-tech.me/post/topn%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/</url><categories><category>数据库</category></categories><tags><tag>MySQL</tag><tag>TopN</tag></tags><content type="html"> 需求 将数据分组,每组内取前n条.最常见的需求是取每组内第一条,例如以imei分组,组内取time最新的一条
表结构 create table com( n_id int auto_increment primary key, c_imei varchar(10) null, c_time bigint null, c_name varchar(10) null ); create index com_c_imei_index on com (c_imei); 表数据 INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (1, &amp;#39;a&amp;#39;, 8, &amp;#39;010101&amp;#39;); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (2, &amp;#39;e&amp;#39;, 2, &amp;#39;020202&amp;#39;); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (3, &amp;#39;c&amp;#39;, 9, &amp;#39;030303&amp;#39;); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (4, &amp;#39;b&amp;#39;, 4, &amp;#39;040404&amp;#39;); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (5, &amp;#39;d&amp;#39;, 5, &amp;#39;050505&amp;#39;); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (6, &amp;#39;a&amp;#39;, 6, &amp;#39;060606&amp;#39;); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (7, &amp;#39;e&amp;#39;, 4, &amp;#39;070707&amp;#39;); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (8, &amp;#39;c&amp;#39;, 3, &amp;#39;0808080&amp;#39;); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (9, &amp;#39;b&amp;#39;, 5, &amp;#39;090909&amp;#39;); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (10, &amp;#39;d&amp;#39;, 8, &amp;#39;101010&amp;#39;); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (11, &amp;#39;a&amp;#39;, 5, &amp;#39;111111&amp;#39;); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (12, &amp;#39;e&amp;#39;, 7, &amp;#39;121212&amp;#39;); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (13, &amp;#39;c&amp;#39;, 2, &amp;#39;131313&amp;#39;); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (14, &amp;#39;b&amp;#39;, 6, &amp;#39;141414&amp;#39;); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (15, &amp;#39;d&amp;#39;, 9, &amp;#39;151515&amp;#39;); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (16, &amp;#39;a&amp;#39;, 2, &amp;#39;161616&amp;#39;); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (17, &amp;#39;e&amp;#39;, 1, &amp;#39;171717&amp;#39;); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (18, &amp;#39;c&amp;#39;, 5, &amp;#39;181818&amp;#39;); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (19, &amp;#39;b&amp;#39;, 8, &amp;#39;191919&amp;#39;); INSERT INTO com (n_id, c_imei, c_time, c_name) VALUES (20, &amp;#39;d&amp;#39;, 7, &amp;#39;202020&amp;#39;); SQL #方法一，自连接 SELECT a.c_imei, a.n_id, a.c_time FROM com a LEFT JOIN com b ON a.c_imei = b.c_imei AND a.c_time &amp;lt; b.c_time WHERE b.c_time IS NULL ORDER BY a.c_imei; #方法一的另一种形式,如果要取每组内前n条，那么将1改成n即可 SELECT n_id, c_imei, c_time, c_name FROM com a WHERE (SELECT count(*) FROM com b WHERE a.c_imei = b.c_imei AND a.c_time &amp;lt; b.c_time) &amp;lt; 1 order by c_imei; #方法二，派生表排序后分组，注意limit必须加不然没用 select n_id, c_imei, c_time, c_name from (select n_id, c_imei, c_time, c_name from com order by c_time desc limit 999999) a group by a.c_imei; #方法三,相关子查询，注意GROUP_CONCAT结果的长度受限于group_concat_max_len，默认1024 SELECT n_id, c_imei, c_time, c_name FROM com WHERE n_id IN (SELECT SUBSTRING_INDEX(GROUP_CONCAT(n_id ORDER BY c_time DESC), &amp;#39;,&amp;#39;, 1) FROM com GROUP BY c_imei) ORDER BY c_imei; #方法四,派生表关联查询 select distinct com.n_id, com.c_imei, com.c_time, com.c_name from com join (select c_imei, max(c_time) as ct from com group by c_imei) tmp on com.c_imei = tmp.c_imei and com.c_time = tmp.ct order by com.c_imei; ##方法四优化 select distinct com.n_id, com.c_imei, com.c_time, com.c_name from com right join (select c_imei, max(c_time) as ct from com group by c_imei) tmp on com.c_imei = tmp.c_imei and com.c_time = tmp.ct order by com.c_imei; 其他方法 MySQL8及以上的row_number、rank、dense_rank、over函数</content></entry><entry><title>参数校验</title><url>https://www.zyg-tech.me/post/%E5%8F%82%E6%95%B0%E6%A0%A1%E9%AA%8C/</url><categories><category>校验</category></categories><tags><tag>校验</tag><tag>Spring</tag><tag>HibernateValidate</tag></tags><content type="html"> 作为后台开发人员,为保证数据的有效性与完整性,避免处理前台传递的无效或不完整的信息,会进行后台的数据校验,常用的是Spring中的SpringValidation, 事实上它是对Hibernate Validator的封装,而Hibernate Validator又是对Bean Validation规范的实现,下面我们来较为全面的了解一下关于校验的那点事儿.
1.Bean Validation规范 Bean Validation规范主要用于对 Bean 中的字段的值进行约束定义、描述和验证,截止目前一共有三个版本 : Bean Validation 1.0/1.1/2.0,分别对应 JSR 303/349/380,有兴趣的同学可以到https://www.jcp.org/en/jsr/overview , 根据JSR编号查找相应的规范提案,关于Bean Validation各版本区别可前往https://beanvalidation.org查看。
2.Bean Validation实现 规范离不开相应的实现,Bean Validation的实现有两个 : Hibernate Validator与Apache BVal,Spring Validation就是基于Hibernate Validator封装的,它们都离不开javax Validation,公司也封装了framework-validation供大家使用。
这里介绍一下规范和实现之间的版本关系 :
Bean Validation 1.0 &amp;ndash;&amp;gt; Hibernate Validator 4.3.1与Apache BVal 0.5 Bean Validation 1.1 &amp;ndash;&amp;gt; Hibernate Validator 5.1.1与Apache BVal 1.1.2 Bean Validation 2.0 &amp;ndash;&amp;gt; Hibernate Validator 6.0.1 Bean Validation 主要提供了以下验证规则(javax.validation.constraints): 1)AssertFalse : 验证 Boolean 对象是否为 true 2)AssertTrue : 验证 Boolean 对象是否为 false 3)DecimalMax : 被标注的值必须不大于约束中指定的最大值(含精度) 4)DecimalMin : 被标注的值必须不小于约束中指定的最小值(含精度) 5)Digits : 验证 Number 和 String 的构成是否合法 6)Future : 验证 Date 和 Calendar 对象是否在当前时间之后 7)Max : 验证 Number 和 String 对象是否小等于指定的值 8)Min : 验证 Number 和 String 对象是否大等于指定的值 9)NotNull : 验证对象是否不为null 10)Null : 验证对象是否为null 11)Past : 验证 Date 和 Calendar 对象是否在当前时间之前 12)Pattern : 验证 Date 和 Calendar 对象是否在当前时间之后 13)Size : 验证CharSequence/Collection/Map/Array对象长度是否在给定的范围之内
Hibernate Validator在javax.validation的基础上增加了以下验证规则(org.hibernate.validator.constraints): 1)CreditCardNumber : 信用卡验证 2)EAN : 验证是否为EAN-13的商品用条码 3)Email : 邮箱地址验证 4)Length : 验证字符串长度 5)LuhnCheck : 验证是否符合模10算法的规则,例如大多数银行卡号编码规则采用了模10算法,前往https://en.wikipedia.org/wiki/Luhn_algorithm#cite_note-0 参考该算法 6)Mod10Check : 验证是否符合Mod10算法 7)Mod11Check : 验证是否符合Mod11算法 8)NotBlank : 检查约束字符串是不是Null还有被Trim的长度是否大于0,只对字符串,且会去掉前后空格 9)NotEmpty : 检查约束元素是否为NULL或者是EMPTY 10)ParameterScriptAssert : 使用脚本进行验证 11)Range : 校验数字或表示数字的字符串的取值范围 12)SafeHtml : 校验是否包含恶意脚本 13)ScriptAssert : 调用静态方法验证 14)URL : 校验是否是合法的URL
Spring Validation没有增加额外的验证规则,而是着重于通过BeanPostProcesser、Interceptor等在接收HTTP请求处理参数时进行参数校验,并封装了验证结果如BindingResult、Errors等,方便开发者使用。
3.Bean Validation实践 3.1 javax Validation原生基础用法 Maven地址
&amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;javax.validation&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;validation-api&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;1.1.0.Final&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; 实体类
public class FlowLearning { @NotNull private Long id; //other properties } 校验方法
Validator validator = Validation.buildDefaultValidatorFactory().getValidator(); Set&amp;lt;ConstraintViolation&amp;lt;Object&amp;gt;&amp;gt; resultSet = validator.validate(flowLEarning,FlowLearning.class); if (!CollectionUtils.isEmpty(resultSet)) { throw new IllegalArgumentException(resultSet.toString()); } javax.validation.Validator为验证对象提供了三个方法 1)Set&amp;lt;ConstraintViolation&amp;gt; validate(T object, Class&amp;lt;?&amp;gt;&amp;hellip; groups) &amp;ndash;&amp;gt;验证一个给定的对象 2)Set&amp;lt;ConstraintViolation&amp;gt; validateProperty(T object, String propertyName, Class&amp;lt;?&amp;gt;&amp;hellip;groups) &amp;ndash;&amp;gt;验证给定对象中的字段或者属性 3)Set&amp;lt;ConstraintViolation&amp;gt; validateValue(ClassbeanType, String propertyName, Object value, Class&amp;lt;?&amp;gt;&amp;hellip; groups) &amp;ndash;&amp;gt;验证给定对象中的属性的具体值
3.2 spring validation 注解校验 略
3.3 @ScriptAssert校验复杂的业务逻辑 实体类
@Getter @Setter // @ScriptAssert的lang指脚本语言,script中的方法名需要完全限定名 @ScriptAssert(lang = &amp;#34;javascript&amp;#34;, script = &amp;#34;com.xdja.oa.nyingchi.admin.User.mockScriptAssert(_this.position,_this.amount)&amp;#34;) public class User { private String position; private Integer amount; public static boolean mockScriptAssert(String position,Integer amount){ if(StringUtils.isEmpty(position) || amount == null || amount &amp;lt;0){ return false; }else { return true; } } } 校验方法
@RequestMapping(value = &amp;#34;script&amp;#34;, method = RequestMethod.POST) public ResponseMsg scripts(@Validated @RequestBody User user, BindingResult bindingResult){ if(bindingResult.hasErrors()){ throw new IllegalArgumentException(&amp;#34;参数不合法&amp;#34;); }else{ //校验成功,处理业务逻辑 } return ResponseMsg.success(); } @ScriptAssert中的lang属性指的是哪种脚本语言,要查看当前jdk版本所支持的脚本语言,可以通过如下代码获取
ScriptEngineManager scriptEngineManager = new ScriptEngineManager(); List&amp;lt;ScriptEngineFactory&amp;gt; engineFactories = scriptEngineManager.getEngineFactories(); if(engineFactories.size() == 0) { System.out.println(&amp;#34;本JVM尚不支持任何脚本引擎&amp;#34;); return; } System.out.println(&amp;#34;本JVM支持的脚本引擎有:&amp;#34;); for(ScriptEngineFactory engineFactory : engineFactories) { System.out.println(&amp;#34;引擎名称:&amp;#34; + engineFactory.getEngineName()); System.out.println(&amp;#34;\t可被ScriptEngineManager识别的名称:&amp;#34; + engineFactory.getNames()); System.out.println(&amp;#34;\t该引擎支持的脚本语言名称:&amp;#34; + engineFactory.getLanguageName()); System.out.println(&amp;#34;\t是否线程安全:&amp;#34; + engineFactory.getParameter(&amp;#34;THREADING&amp;#34;)); } 3.4 原生自定义Validator 自定义注解
@Target( { METHOD, FIELD, ANNOTATION_TYPE }) @Retention(RUNTIME) @Documented @Constraint(validatedBy = CheckStringValidator.class) public @interface CheckString { String message() default &amp;#34;字符串校验失败！请少侠重新来过~&amp;#34;; Class&amp;lt;?&amp;gt;[] groups() default {}; Class&amp;lt;? extends Payload&amp;gt;[] payload() default {}; CheckType checkType() ; } 注解中的枚举
public enum CheckType { EMPTY,NOT_EMPTY } 注解校验器
public class CheckStringValidator implements ConstraintValidator&amp;lt;CheckString,String&amp;gt; { private CheckType checkType; @Override public void initialize(CheckString constraintAnnotation) { this.checkType = constraintAnnotation.checkType(); } @Override public boolean isValid(String string, ConstraintValidatorContext context) { if(string == null || checkType == null){ return false; }else{ boolean result = false; switch(checkType){ case NOT_EMPTY : result = !StringUtils.isEmpty(string); break; case EMPTY: result = StringUtils.isEmpty(string); break; default: break; } return result; } } } 实体类
@Getter @Setter public class User { @CheckString(checkType = CheckType.NOT_EMPTY) private String position; } 校验
@RequestMapping(value = &amp;#34;script&amp;#34;, method = RequestMethod.POST) public ResponseMsg scripts(@Valid @RequestBody User user, BindingResult bindingResult){ if(bindingResult.hasErrors()){ throw new IllegalArgumentException(&amp;#34;参数不合法&amp;#34;); }else{ System.out.println(&amp;#34;校验成功&amp;#34;); } } 3.5 校验模式 日常开发中进行的校验大多只要某字段校验失败就视为校验失败无需继续校验了，为此，可以设置校验模式为FastFail.
HibernateValidatorConfiguration configuration = Validation.byProvider( HibernateValidator.class ).configure(); ValidatorFactory factory = configuration.addProperty( &amp;#34;hibernate.validator.fail_fast&amp;#34;, &amp;#34;true&amp;#34; ).buildValidatorFactory(); Validator validator = factory.getValidator(); 级联验证目前使用较少,不再介绍。</content></entry><entry><title>汇报搜索优化历程</title><url>https://www.zyg-tech.me/post/%E6%B1%87%E6%8A%A5%E6%90%9C%E7%B4%A2%E4%BC%98%E5%8C%96%E5%8E%86%E7%A8%8B/</url><categories><category>实战</category></categories><tags><tag>ES</tag><tag>搜索</tag></tags><content type="html"> 1.背景介绍 OA中存在工作汇报与汇报审批两个应用，前者用于员工填写汇报，如日报、周报、月报、会议纪要等，后者用于领导查阅员工填写的汇报，在查阅汇报时提供搜索功能，可根据关键字对汇报内容进行搜索。
1.1 表关系 搜索汇报相关的数据表表结构如下
t_report(汇报主表,存储员工填写的汇报记录,与t_report_value为一对多关系) 字段名 字段类型 字段说明 n_id bigint(20) 主键 n_account_id bigint(20) 人员id n_modify_time bigint(20) 修改时间 n_report_date bigint(20) 汇报日期 n_status bigint(20) 数据状态,0正常,1已删除 其他字段…. t_report_value(汇报子表,存储员工填写的汇报记录详情) 字段名 字段类型 字段说明 n_id bigint(20) 主键 n_report_id bigint(20) 汇报id，等同t_report的n_id n_moudle_id bigint(20) 模板id n_moudle_widget_id bigint(20) 模板的控件id c_widget_value varchar(12380) 汇报的内容 其他字段…. t_report_moudle(汇报模板表,存储汇报使用的模板,与t_report_widget为一对多关系) n_id bigint(20) 主键 c_name varchar(255) 模板名称 其他字段… t_report_widget(汇报控件表,存储汇报使用的模板中的控件) n_id bigint(20) 主键 n_moudle_id bigint(20) 模板id,等同t_report_moudle的n_id c_title varchar(20) 控件名,如标题、内容、本周总结、本月计划 n_value_limt int(8) 控件值长度限制,如标题最大长度、内容最大长度 其他字段…. 1.2 数据增长速度 模板表与模板控件表的数量增长较慢，数据增长主要为汇报主表与汇报子表，每天两表的数据增长速度大致如下
t_report：1 * 员工数
t_report_value : 1 * 员工数 * 模板数 * 控件数
1.3 搜索流程 搜索功能流程如下：
A接收请求
B查询当前人管辖的人员列表
C查询当前人能够查看的模板id列表
D将前两步的结果、关键词、分页参数等一起作为条件，搜索符合条件的汇报
E包装汇报的其他数据(如汇报的浏览数量、汇报的附件数量)
F返回数据
2.阶段A – MySQL like查询 在应用运行初期，由于汇报数据少，数据增长速度慢，且对搜索接口未提出其他方面的要求，因此采用like模糊查询符合条件的汇报数据，核心SQL如下
SELECT
DISTINCT t1.n_id AS id,
t1.n_create_time AS createTime,
t1.n_modify_time AS modifyTime,
t1.n_account_id AS accountId,
t1.c_coordinate AS coordinate,
t1.c_at_ids AS atIds,
t1.n_report_date AS reportDate
FROM
t_report t1
LEFT JOIN t_report_value brmwv ON t1.n_id = brmwv.n_report_id
WHERE
brmwv.c_widget_value like &amp;lsquo;%:1%&amp;rsquo;
AND brmwv.n_employee_id IN(:2)
AND brmwv.n_moudle_id IN(:3)
AND t1.n_delete_flag = 0
AND t1.n_modify_time &amp;lt; :4
ORDER BY
t1.n_report_date DESC,
t1.n_modify_time DESC LIMIT 0, :5
##:1为关键词,:2为人员列表,:3为模块列表,:4为分页参数,:5为分页条数
方案优点：无需额外改动
方案缺点：数据量多时效率低
3.阶段B - MySQL 全文索引 以公司环境为例，应用运行一年后，汇报主表的数据量大约为33w条(330天* 1000员工),汇报子表的数据量为33w条(330天 * 1000 员工 * 1个模板 * 1个控件),这时候搜索接口的查询汇报SQL平均速度为10S+，like搜索方案的主要瓶颈在于like搜索进行全表扫描，于是考虑在c_widget_value字段中建立索引来提高搜索速度，由于c_widget_value大部分为中文字符,因此需要在该字段建立全文索引并支持对中文的搜索。
经查阅资料，MySQL中的全文索引自v5.6.24开始支持InnoDB引擎，自v5.7开始增加ngram分词器以支持中日韩文，全文索引支持的数据库字段类型为char、varchar、text，于是此方案在MySQL中执行以下语句即可:
create fulltext index vfin on t_ report _value (c_widget_value) with parser ngram;
建立全文索引后SQL需要进行相应的改写，使用match against ，改写后的SQL如下
SELECT
DISTINCT t1.n_id AS id,
t1.n_create_time AS createTime,
t1.n_modify_time AS modifyTime,
t1.n_account_id AS accountId,
t1.c_coordinate AS coordinate,
t1.c_at_ids AS atIds,
t1.n_report_date AS reportDate
FROM
t _report t1
LEFT JOIN t_ report_ value brmwv ON t1.n_id = brmwv.n_report_id
WHERE
match(c_widget_value) against (':1&amp;rsquo;)
AND brmwv.n_employee_id IN(:2)
AND brmwv.n_moudle_id IN(:3)
AND t1.n_delete_flag = 0
AND t1.n_modify_time &amp;lt; :4
ORDER BY
t1.n_report_date DESC,
t1.n_modify_time DESC LIMIT 0, :5
##:1为关键词,:2为人员列表,:3为模块列表,:4为分页参数,:5为分页条数
在使用该方案时发现接口整体速度确实有了提升，但是当输入的关键词为单个字符或两个字符时无法查询到数据，于是继续查阅相关资料，得到以下信息：MySQL中的innodb_ft_min_token_size配置项表示全文索引最小分词长度,该值默认为3。于是将该配置项的值修改为1，重建了全文索引并重启MySQL，再次搜索时输入任意个字符均可搜索到相关数据。
方案时间：SQL平均时间2s，整体接口平均时间8s
方案优点：SQL查询效率提高
方案缺点：建立了索引额外占据了空间、对该表的CRUD都将降低响应速度、ngram分词粒度越细那么占据空间越大、修改MySQL的全文索引配置项后需要重建全文索引并重启MySQL才能生效、输入的关键词长度增加时SQL响应速度呈指数级增长。
4.阶段C - ElasticSearch + MySQL 全文索引方案与like方案相比，的确提升了SQL的响应速度，但是SQL响应速度受关键词影响极大，若输入的关键词长度过长，或输入的关键词几乎匹配了数据库中绝大部分数据，那么该接口的整体响应速度仍然堪忧；建立全文索引后，对t_ report_ value进行操作时响应速度将会有所降低；数据进一步增长时SQL速度将进一步变慢，在百万级以上时表现不佳；ngram分词器的分词规则不够灵活，导致分词后的索引占据空间很大。
一想到大数据量秒级响应，那么ElasticSearch会作为首选项。加上搜索接口对数据实时性要求不高，因此可以将汇报主表与汇报子表的数据存储在ElasticSearch中，对c_widget_value使用ik_smart进行分词存储，并定时更新ES数据，查询时从ES查询数据，然后再进行接口内其他业务操作。
由于ES并不擅长关联操作，于是该方案设计为OA后台执行定时任务，将汇报主表与汇报子表的数据增量整合为一张表t_report_sync_data,再通过LogStash将MySQL中表t_report_sync_data的数据增量同步到ES中。
记表t_ report为表A(汇报主表), t_report_value为表B(汇报子表), t _report_moudle(汇报模板表)为 C，以下是t_report_sync_data中各字段与这些表的对应关系
字段名 原始表 原始字段 说明 reportId report n_id 汇报id createTime report n_create_time 汇报创建时间 modifyTime report n_modify_time 汇报修改时间 accountId report n_account_id 人员id coordinate report c_coordinate 坐标 atds report c_at_ids 艾特的人员id集合 deleteFlag report n_delete_flag 删除标识 companyId report n_company_id 企业id reportDate report n_report_date 汇报日期 moduleId reportValue n_module_widget_id 模块id widgetValue reportValue c_widget_value 控件值 那么查询时的SQL就改变为了ES的查询语句，Java代码如下
// 条件构建
BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();
//widgetValue,模糊查询
BoolQueryBuilder builder = QueryBuilders.boolQuery();
builder.should(QueryBuilders.matchPhraseQuery(&amp;ldquo;widgetValue&amp;rdquo;, queryBean.getWidgetValue()));
boolQueryBuilder.must(builder);
//accountId,in
boolQueryBuilder.filter(inParamBuilder(queryBean.getAccountIds(), &amp;ldquo;accountId&amp;rdquo;));
//moudleId, in
boolQueryBuilder.filter(inParamBuilder(queryBean.getMoudleIds(), &amp;ldquo;moudleId&amp;rdquo;));
//deleteFlag,0
boolQueryBuilder.filter(QueryBuilders.termQuery(&amp;ldquo;deleteFlag&amp;rdquo;, 0));
//modifyTime,&amp;lt;
RangeQueryBuilder rangeQuery = QueryBuilders.rangeQuery(&amp;ldquo;modifyTime&amp;rdquo;);
rangeQuery.lt(queryBean.getModifyTime());
boolQueryBuilder.filter(rangeQuery);
//聚合请求构建
//按reportId分桶,按reportDate降序,按modifyTime降序,取前n桶 TermsBuilder termsBuilder = AggregationBuilders .terms(&amp;ldquo;group_by_reportId&amp;rdquo;) .field(&amp;ldquo;reportId&amp;rdquo;) .subAggregation(AggregationBuilders.max(&amp;ldquo;sortA&amp;rdquo;).field(&amp;ldquo;reportDate&amp;rdquo;)) .subAggregation(AggregationBuilders.max(&amp;ldquo;sortB&amp;rdquo;).field(&amp;ldquo;modifyTime&amp;rdquo;)) . order(Terms.Order.compound(Terms.Order.aggregation(&amp;ldquo;sortA&amp;rdquo;,false),Terms.Order.aggregation(&amp;ldquo;sortB&amp;rdquo;,false))) .size(queryBean.getPageSize());
//设置每组内取一条数据
TopHitsBuilder hitsBuilder = AggregationBuilders.topHits(&amp;ldquo;groupDataDetail&amp;rdquo;).setSize(1);
//每组内, 设置查询的字段
hitsBuilder.setFetchSource(WORK_REPORT_FIELDS, null);
termsBuilder.subAggregation(hitsBuilder);
//将分组挂靠在查询请求内,size设置es hit的原始数据,由于业务系统一般不需要,故设置不返回此项
requestBuilder.addAggregation(termsBuilder).setSize(0);
//设置Query并获取响应
SearchResponse searchResponse = requestBuilder.setQuery(boolQueryBuilder).execute().actionGet();
//处理响应,略
//inParamBuilder方法如下，用于解决同一个字段的terms的参数过多问题
private QueryBuilder inParamBuilder(List list, String field) { int count = 800; int len = list.size(); int size = len % count == 0 ? len / count : (len / count) + 1; BoolQueryBuilder shouldQuery = QueryBuilders.boolQuery(); for (int i = 0; i &amp;lt; size; i++) { int fromIndex = i * count; int toIndex = Math.min(fromIndex + count, len); List subList = list.subList(fromIndex, toIndex); TermsQueryBuilder termsQueryBuilder = QueryBuilders.termsQuery(field, subList); shouldQuery.should(termsQueryBuilder); } return shouldQuery; }
ES的DSL语句如下
{
&amp;ldquo;size&amp;rdquo; : 0,
&amp;ldquo;query&amp;rdquo; : {
&amp;ldquo;bool&amp;rdquo; : {
&amp;ldquo;must&amp;rdquo; : {&amp;ldquo;bool&amp;rdquo; : {&amp;ldquo;should&amp;rdquo; : {&amp;ldquo;match&amp;rdquo; : {&amp;ldquo;widgetValue&amp;rdquo; : {&amp;ldquo;query&amp;rdquo; : &amp;ldquo;工作汇报&amp;rdquo;,&amp;ldquo;type&amp;rdquo; : &amp;ldquo;phrase&amp;rdquo;}}}}},
&amp;ldquo;filter&amp;rdquo; : [
​ {&amp;ldquo;bool&amp;rdquo; : {&amp;ldquo;should&amp;rdquo; : {&amp;ldquo;terms&amp;rdquo; : {&amp;ldquo;moudleId&amp;rdquo; : [ 1, 2, 3, 4, 5 ]}}}},
​ {&amp;ldquo;term&amp;rdquo; : {&amp;ldquo;deleteFlag&amp;rdquo; : 0}},
​ {&amp;ldquo;range&amp;rdquo; : {&amp;ldquo;modifyTime&amp;rdquo; : {&amp;ldquo;from&amp;rdquo; : null,&amp;ldquo;to&amp;rdquo; : 1554180590383,&amp;ldquo;include_lower&amp;rdquo; : true,&amp;ldquo;include_upper&amp;rdquo; : false}} } ]}
},
&amp;ldquo;aggregations&amp;rdquo; : {
&amp;ldquo;group_by_reportId&amp;rdquo; : {
&amp;ldquo;terms&amp;rdquo; : {
​ &amp;ldquo;field&amp;rdquo; : &amp;ldquo;reportId&amp;rdquo;,&amp;ldquo;size&amp;rdquo; : 200,&amp;ldquo;order&amp;rdquo; : [ {&amp;ldquo;sortA&amp;rdquo; : &amp;ldquo;desc&amp;rdquo;}, {&amp;ldquo;sortB&amp;rdquo; : &amp;ldquo;desc&amp;rdquo;}, {&amp;quot;_term&amp;rdquo; : &amp;ldquo;asc&amp;rdquo;} ]},
&amp;ldquo;aggregations&amp;rdquo; : {
​ &amp;ldquo;sortA&amp;rdquo; : {&amp;ldquo;max&amp;rdquo; : {&amp;ldquo;field&amp;rdquo; : &amp;ldquo;reportDate&amp;rdquo;}},
​ &amp;ldquo;sortB&amp;rdquo; : {&amp;ldquo;max&amp;rdquo; : {&amp;ldquo;field&amp;rdquo; : &amp;ldquo;modifyTime&amp;rdquo;}},
​ &amp;ldquo;groupDataDetail&amp;rdquo; : {&amp;ldquo;top_hits&amp;rdquo; : {&amp;ldquo;size&amp;rdquo; : 1, &amp;ldquo;_source&amp;rdquo; : {&amp;ldquo;includes&amp;rdquo; : [ &amp;ldquo;accountId&amp;rdquo;, &amp;ldquo;atIds&amp;rdquo;, &amp;ldquo;companyId&amp;rdquo;, &amp;ldquo;coordinate&amp;rdquo;, &amp;ldquo;createTime&amp;rdquo;, &amp;ldquo;deleteFlag&amp;rdquo;, &amp;ldquo;modifyTime&amp;rdquo;, &amp;ldquo;moudleId&amp;rdquo;, &amp;ldquo;reportDate&amp;rdquo;, &amp;ldquo;widgetValue&amp;rdquo; ],
​ &amp;ldquo;excludes&amp;rdquo; : [ ]} }}}}}}
经测试，该方案中ES环节所需时间稳定在0.8s左右，接口整体速度在1-6s。
优点：速度进一步提升且响应时间比较稳定
缺点：汇报相关的其他数据仍存储在MySQL中，整体接口瓶颈变为查询汇报其他数据时的速度过慢。
5.阶段D - ElasticSearch + Redis + MySQL 对整体接口相关数据进一步分析，根据数据修改频繁程度，可以将数据进行冷热分离，将修改频率较低的数据,如汇报主表与汇报子表，存储在ES中，并通过LogStash定时增量更新；将高频修改数据(如汇报的浏览数量)存储在Redis中，这样将会进一步提升搜索的响应速度。</content></entry><entry><title>MySQL全文索引使用</title><url>https://www.zyg-tech.me/post/mysql%E5%85%A8%E6%96%87%E7%B4%A2%E5%BC%95/</url><categories><category>MySQL</category></categories><tags><tag>MySQL</tag><tag>数据库</tag><tag>全文索引</tag></tags><content type="html"> 1.简介 在Web应用中,经常会遇到按照关键字进行模糊搜索的需求,当参数搜索的数据量较少时,我们一般使用like进行搜索,但是当数据量达到一定程度后,like方式的速度就会很慢很慢,这时候我们可以借助一些全文搜索的组件来实现需求.MySQL就提供了全文索引来支持模糊搜索.
2.限制条件 2.1引擎限制 MySQL 5.6 以前的版本，只有 MyISAM 存储引擎支持全文索引；
MySQL 5.6 及以后的版本，MyISAM 和 InnoDB 存储引擎均支持全文索引
2.2版本号限制 Mysql自v5.6.24版本开始在InnoDB引擎中增加全文索引功能，支持对英文的全文搜索,默认以空格作为分隔符;自v5.7版本开始增加ngram分词器以支持中文
2.3字段类型限制 全文索引支持的字段类型为char、varchar、text等这些基于文本的列
2.4连表限制 全文搜索仅支持在同一张表中进行,不支持对多张表中的关键字进行全文搜索
3.准备索引 我们以report表为例
-- 准备表 create table report ( id int auto_increment primary key, content varchar(1000) null ); -- 在content字段创建普通的全文索引 create fulltext index content_fti on report(content); -- 在content字段创建支持中文的全文索引 create fulltext index content_fti on report(content) WITH PARSER ngram; -- 删除索引,方式一 drop index content_fti on report; -- 删除索引,方式二 alter table report drop index content_fti; 4.准备配置 ​ 使用全文索引搜索时,搜索引擎受全文搜索的单词长度影响,如果关键词长度小于该配置项,那么将无法搜索出相匹配的结果,通过命令可以查看出相关配置项
-- 查看全文搜索配置 show variables like &amp;#39;%ft%&amp;#39;; -- 命令执行结果 // MyISAM:关键词最小长度默认4字符,最大长度84字符 ft_min_word_len = 4; ft_max_word_len = 84; // InnoDB:关键词最小长度默认3字符,最大长度84字符 innodb_ft_min_token_size = 3; innodb_ft_max_token_size = 84; 我们以常用的Innodb引擎为例,在MySQL的配置文件中修改配置项
[mysqld] innodb_ft_min_token_size = 1 ft_min_word_len = 1 修改后需要重启MySQL,然后修复全文索引(可以删除索引然后重新建立索引,如果是MyIsam引擎,也可以执行repair命令修复)
然而对于使用了ngram的全文索引来讲,它的全文搜索单词长度配置会忽略上述四个配置项,真正生效的为配置项ngram_token_size(默认2),可以通过在MySQL的配置文件中修改以下配置项或启动时追加参数&amp;ndash;ngram_token_size=1来实现对该配置项的修改
[mysqld] ngram_token_size=1 同样的,修改此项后需要重建全文索引
5.准备数据 略
6.使用索引 与like不同,全文索引的搜索需要使用match agnist,示例如下
select * from report where match(content) against(&amp;#39;测试关键词&amp;#39;); match agnist本身还会返回非负浮点数作为搜索的结果行与关键词的相关度.除了match agnist的基础使用,全文搜索还支持以不同的检索模式进行搜索,常用的全文检索模式有两种： 1、自然语言模式(NATURAL LANGUAGE MODE) ， 自然语言模式是MySQL 默认的全文检索模式。自然语言模式不能使用操作符，不能指定关键词必须出现或者必须不能出现等复杂查询。当sql中指定了IN NATURAL LANGUAGE MODE修饰符或未给出修饰符，则全文搜索是自然语言搜索模式 。 2、BOOLEAN模式(BOOLEAN MODE) BOOLEAN模式可以使用操作符，可以支持指定关键词必须出现或者必须不能出现或者关键词的权重高还是低等复杂查询。
6.1自然语言检索模式 ​ 在该模式下,可以指定IN NATURAL LANGUAGE MOD,也可以不指定修饰符,下面给出一个按照结果行相关度倒序排列的SQL示例
select *,match(content) against(&amp;#39;一切&amp;#39;) as score from report where match(content) against(&amp;#39;一切&amp;#39;) order by score desc; 6.2布尔检索模式 MySQL可以使用IN BOOLEAN MODE修饰符执行布尔型全文本搜索 。在这种模式下,支持通过一些正则来进行高级搜索,布尔模式下支持以下操作符：
“+”表示必须包含 “-”表示必须排除 “&amp;gt;”表示出现该单词时增加相关性 “&amp;lt;”表示出现该单词时降低相关性 “*”表示通配符 “~”允许出现该单词，但是出现时相关性为负 “&amp;quot;&amp;quot;”表示短语 下面给出一些示例 &amp;#39;apple banana&amp;#39; ## 无操作符，表示或，要么包含apple，要么包含banana &amp;#39;+apple +juice&amp;#39; ## 必须同时包含两个词apple和juice &amp;#39;+apple macintosh&amp;#39; ## 必须包含apple，但是如果也包含macintosh的话，相关性会更高。 &amp;#39;+apple -macintosh&amp;#39; ## 必须包含apple，同时不能包含macintosh。 &amp;#39;+apple ~macintosh&amp;#39; ## 必须包含apple，但是如果也包含macintosh的话，相关性要比不包含macintosh的记录低。 &amp;#39;+apple +(&amp;gt;juice &amp;lt;pie)&amp;#39; ## 查询必须包含apple和juice或者apple和pie的记录，但是apple juice的相关性要比apple pie高。 &amp;#39;apple*&amp;#39; ## 查询包含以apple开头的单词的记录，如apple、apples、applet。 &amp;#39;&amp;#34;some words&amp;#34;&amp;#39; ## 使用双引号把要搜素的词括起来，效果类似于like &amp;#39;%some words%&amp;#39;， 例如“some words of wisdom”会被匹配到，而“some noise words”就不会被匹配。 7.InnoDB引擎的相关性 InnoDB引擎的全文索引基于Sphinx,算法基于BM-25和TF-IDF,InnoDB使用“术语频率-逆文档频率” （TF-IDF）加权系统的变体对给定的全文搜索查询对文档的相关性进行排名,单词出现在文档中的频率越高，单词出现在文档集合中的频率越低，文档的排名就越高。
7.1相关性排名的计算方式 术语频率（TF）值是单词在文档中出现的次数。IDF单词的逆文档频率（）值是使用以下公式计算的，其中 total_records是集合中matching_records的记录数，并且是搜索词出现的记录数。
${IDF} = log10( ${total_records} / ${matching_records} ) 当文档多次包含一个单词时，IDF值将乘以TF值：
${TF} * ${IDF} 使用TF和IDF 值，使用以下公式计算文档的相关性等级：
${rank} = ${TF} * ${IDF} * ${IDF} 8.停止词 可以通过配置停止词来禁止某些词语参与全文索引,详细使用见全文停用词
9.InnoDB分词原理 InnoDB 全文索引具有倒排索引设计。倒排索引存储一个单词列表，对于每个单词，存储单词出现的文档列表。为了支持邻近搜索，每个单词的位置信息也作为字节偏移量存储。
创建全文索引时,MySQL将创建一组表用于辅助
## 查看索引表 SELECT table_id, name, space from INFORMATION_SCHEMA.INNODB_SYS_TABLES WHERE name LIKE &amp;#39;test/%&amp;#39;; ## 命令执行结果 424 test/FTS_000000000000006b_0000000000000388_INDEX_1 423 425 test/FTS_000000000000006b_0000000000000388_INDEX_2 424 426 test/FTS_000000000000006b_0000000000000388_INDEX_3 425 427 test/FTS_000000000000006b_0000000000000388_INDEX_4 426 428 test/FTS_000000000000006b_0000000000000388_INDEX_5 427 429 test/FTS_000000000000006b_0000000000000388_INDEX_6 428 430 test/FTS_000000000000006b_BEING_DELETED 429 431 test/FTS_000000000000006b_BEING_DELETED_CACHE 430 432 test/FTS_000000000000006b_CONFIG 431 433 test/FTS_000000000000006b_DELETED 432 434 test/FTS_000000000000006b_DELETED_CACHE 433 107 test/report 93 前六个表代表反向索引，并称为辅助索引表。对传入文档进行标记时，各个单词（也称为 “标记”）与位置信息和关联的文档ID（DOC_ID）一起插入索引表中。根据单词第一个字符的字符集排序权重，单词在六个索引表中得到完全排序和分区。
倒排索引分为六个辅助索引表，以支持并行索引创建。默认情况下，两个线程对索引表中的单词和相关数据进行标记化，排序和插入。线程数可以使用该innodb_ft_sort_pll_degree 选项配置 。FULLTEXT在大型表上创建索引时，请考虑增加线程数 。
辅助索引表名称以前缀 FTS_和后缀 INDEX_*。每个索引表通过索引表名称中与table_id索引表的匹配的十六进制值与索引表相关联。例如，table_id所述的 test/opening_lines表是 327，为此，十六进制值是0x147。如前面的示例所示，十六进制值“ 147 ”出现在与该test/opening_lines表关联的索引表的名称中。</content></entry><entry><title>Docker MySQL部署</title><url>https://www.zyg-tech.me/post/docker-mysql%E9%83%A8%E7%BD%B2/</url><categories><category>MySQL</category></categories><tags><tag>MySQL</tag><tag>Docker</tag></tags><content type="html"> 前提 安装docker,mac环境下可直接安装docker Desktop
拉取 #拉取5.7版本的mysql镜像 docker push mysql:5.7
运行 docker run -p 13306:3306 \ --name d-mysql-57 \ -e MYSQL_ROOT_PASSWORD=Mo20100528 \ -v /Users/zyg/softs/docker/mysql57/data:/var/lib/mysql \ -v /Users/zyg/softs/docker/mysql57/logs:/var/log/mysql \ -v /Users/zyg/softs/docker/mysql57/conf/my.cnf:/etc/my.cnf \ -d mysql:5.7 参数说明:
run　run 是运行一个容器 -d　表示后台运行 -p　表示容器内部端口和服务器端口映射关联 &amp;ndash;privileged=true　设值MySQL 的root用户权限, 否则外部不能使用root用户登陆 -v 容器内的路径(如/etc/mysql)挂载到宿主机 -e MYSQL_ROOT_PASSWORD=xxx 设置MySQL数据库root用户的密码 &amp;ndash;name 设值容器名称为mysql mysql:5.7 表示从docker镜像mysql:5.7中启动一个容器 &amp;ndash;character-set-server=utf8mb4 &amp;ndash;collation-server=utf8mb4_general_ci 设值数据库默认编码 停止上面启动的容器,容器名字为&amp;quot;d-mysql-57&amp;rdquo;
docker stop d-mysql-57 配置账户 ##进入容器
docker exec -it d-mysql-57 bash ##登录MySQL
``mysql -uroot -p` ##创建用户,名叫test,密码是test123,开启远程访问权限
GRANT ALL PRIVILEGES ON *.* TO &amp;#39;test&amp;#39;@&amp;#39;%&amp;#39; IDENTIFIED BY &amp;#39;test123&amp;#39; WITH GRANT OPTION; ##创建数据库,名叫xxx
create database xxx; 之后便可以通过该用户执行业务脚本</content></entry></search>